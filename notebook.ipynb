{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## Dimension Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "### Customers Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "### Days Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6be3ec4-16ac-450b-87c0-0a90b0968184",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:05:28.9267409Z",
       "execution_start_time": "2025-06-02T14:05:28.574285Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "11aebc0e-8297-4504-a3ba-b8f4a52da3b3",
       "queued_time": "2025-06-02T14:05:28.5729868Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 6, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# ‚ú® Parameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "num_customers = 100  # rows in customer dimension\n",
    "num_products = 10  # rows in product dimension\n",
    "num_facts = 100_000_000  # total rows across all years (will be split evenly among months for the chosen year)\n",
    "start_ts = \"2013-01-01 00:00:00\"  # baseline start (used to infer full range but overridden by load_year)\n",
    "load_year = 2017  # year to generate data for (must be between 2013 and 2022)\n",
    "drop_tables = False  # set to True to drop fact and agg tables before loading\n",
    "months = list(range(1, 13))\n",
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a082b2d6-269c-403b-994a-b9cfbd6e486f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:01:15.5971649Z",
       "execution_start_time": "2025-06-02T14:01:15.2589378Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "34dcebcb-4e48-4a86-8abc-817d11542ecd",
       "queued_time": "2025-06-02T14:01:05.1832091Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 4, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    concat_ws,\n",
    "    dayofmonth,\n",
    "    expr,\n",
    "    from_unixtime,\n",
    "    lit,\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Fact & Aggregate Table Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e93f6d4a-336a-4e0e-b71b-222bdfa04efe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T09:55:20.0108111Z",
       "execution_start_time": "2025-06-02T09:54:53.749252Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "2f6f6d35-ee2f-46fc-9600-b6cd563b391b",
       "queued_time": "2025-06-02T09:54:53.7478365Z",
       "session_id": "51afabbe-d8f0-45de-92e6-64767a52e1b3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 23,
       "statement_ids": [
        23
       ]
      },
      "text/plain": "StatementMeta(, 51afabbe-d8f0-45de-92e6-64767a52e1b3, 23, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _bucket(col_name: str, num_buckets: int, labels):\n",
    "    \"\"\"Return a Spark SQL expression that maps modulus buckets to text labels.\"\"\"\n",
    "    assert len(labels) == num_buckets, \"labels must match num_buckets\"\n",
    "    cases = (\n",
    "        \"CASE \"\n",
    "        + \" \".join(\n",
    "            [\n",
    "                f\"WHEN {col_name} % {num_buckets} = {i} THEN '{labels[i]}'\"\n",
    "                for i in range(num_buckets)\n",
    "            ]\n",
    "        )\n",
    "        + \" END\"\n",
    "    )\n",
    "    return expr(cases)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "# üè∑Ô∏è  Dimension Table 1 ‚Äì Customers\n",
    "\n",
    "df_customers = (\n",
    "    spark.range(1, num_customers + 1)\n",
    "    .withColumnRenamed(\"id\", \"customer_id\")\n",
    "    .withColumn(\"customer_name\", concat_ws(\" \", lit(\"Customer\"), expr(\"customer_id\")))\n",
    "    .withColumn(\"region\", _bucket(\"customer_id\", 4, [\"North\", \"South\", \"East\", \"West\"]))\n",
    ")\n",
    "\n",
    "(df_customers.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_customer\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "# üè∑Ô∏è  Dimension Table 2 ‚Äì Days\n",
    "\n",
    "\n",
    "days = list(range(1, 32))\n",
    "df_day = spark.createDataFrame([(d,) for d in days], [\"day\"]).withColumn(\n",
    "    \"day_label\", concat_ws(\"\", lit(\"Day \"), col(\"day\"))\n",
    ")\n",
    "\n",
    "(df_day.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_day\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "# üè∑Ô∏è  Dimension Table 3 ‚Äì Months\n",
    "\n",
    "\n",
    "month_names = [\n",
    "    \"Jan\",\n",
    "    \"Feb\",\n",
    "    \"Mar\",\n",
    "    \"Apr\",\n",
    "    \"May\",\n",
    "    \"Jun\",\n",
    "    \"Jul\",\n",
    "    \"Aug\",\n",
    "    \"Sep\",\n",
    "    \"Oct\",\n",
    "    \"Nov\",\n",
    "    \"Dec\",\n",
    "]\n",
    "df_month = spark.createDataFrame(\n",
    "    [(m, month_names[m - 1]) for m in months], [\"month\", \"month_name\"]\n",
    ").withColumn(\"month_label\", concat_ws(\" \", lit(\"Month\"), col(\"month_name\")))\n",
    "\n",
    "(df_month.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_month\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "# üè∑Ô∏è  Dimension Table 4 ‚Äì Years\n",
    "\n",
    "years_range = list(range(2013, 2023))  # 10 years\n",
    "df_year = spark.createDataFrame([(y,) for y in years_range], [\"year\"]).withColumn(\n",
    "    \"year_label\", concat_ws(\"\", lit(\"Year \"), col(\"year\"))\n",
    ")\n",
    "\n",
    "(df_year.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_year\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "# üè∑Ô∏è  Dimension Table 5 ‚Äì Products\n",
    "\n",
    "df_products = (\n",
    "    spark.range(1, num_products + 1)\n",
    "    .withColumnRenamed(\"id\", \"product_id\")\n",
    "    .withColumn(\"product_name\", concat_ws(\" \", lit(\"Product\"), expr(\"product_id\")))\n",
    "    .withColumn(\n",
    "        \"category\",\n",
    "        _bucket(\n",
    "            \"product_id\",\n",
    "            5,\n",
    "            [\"Accessories\", \"Hardware\", \"Software\", \"Services\", \"Other\"],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "(df_products.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_product\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f10d03b-a551-41eb-a4e9-2cb48a79e65c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:10:45.6504686Z",
       "execution_start_time": "2025-06-02T14:06:05.0990887Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "518786c2-aa93-4d58-8e8b-6e9baa749495",
       "queued_time": "2025-06-02T14:06:05.0977699Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        8
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 8, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping drop of existing tables.\nLoaded fact partition year=2017, month=1 with 8333333 rows\nLoaded fact partition year=2017, month=2 with 8333333 rows\nLoaded fact partition year=2017, month=3 with 8333333 rows\nLoaded fact partition year=2017, month=4 with 8333333 rows\nLoaded fact partition year=2017, month=5 with 8333333 rows\nLoaded fact partition year=2017, month=6 with 8333333 rows\nLoaded fact partition year=2017, month=7 with 8333333 rows\nLoaded fact partition year=2017, month=8 with 8333333 rows\nLoaded fact partition year=2017, month=9 with 8333333 rows\nLoaded fact partition year=2017, month=10 with 8333333 rows\nLoaded fact partition year=2017, month=11 with 8333333 rows\nLoaded fact partition year=2017, month=12 with 8333333 rows\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# üìä  Fact & Aggregate Tables Loading\n",
    "\n",
    "# Optionally drop existing tables\n",
    "def drop_existing_tables():\n",
    "    spark.sql(\"DROP TABLE IF EXISTS fact_transactions\")\n",
    "    spark.sql(\"DROP TABLE IF EXISTS agg_transactions\")\n",
    "\n",
    "\n",
    "if drop_tables:\n",
    "    drop_existing_tables()\n",
    "    print(\"Dropped existing fact_transactions and agg_transactions tables.\")\n",
    "else:\n",
    "    print(\"Skipping drop of existing tables.\")\n",
    "\n",
    "# Determine facts per month only for load_year\n",
    "total_months = 12  # months in selected year\n",
    "facts_per_month = num_facts // total_months\n",
    "\n",
    "# Generate and write partitions month-by-month for load_year\n",
    "for m in months:\n",
    "    # Calculate epoch range for this month\n",
    "    month_start = datetime(load_year, m, 1, 0, 0, 0)\n",
    "    if m < 12:\n",
    "        month_end = datetime(load_year, m + 1, 1, 0, 0, 0)\n",
    "    else:\n",
    "        month_end = datetime(load_year + 1, 1, 1, 0, 0, 0)\n",
    "    epoch_start = int(month_start.timestamp())\n",
    "    epoch_end = int(month_end.timestamp())\n",
    "    seconds_in_month = epoch_end - epoch_start\n",
    "\n",
    "    # Generate DataFrame for this month‚Äôs facts\n",
    "    df_month_batch = (\n",
    "        spark.range(1, facts_per_month + 1)\n",
    "        .withColumnRenamed(\"id\", \"transaction_id\")\n",
    "        .withColumn(\n",
    "            \"txn_timestamp\",\n",
    "            from_unixtime(\n",
    "                expr(f\"CAST(rand() * {seconds_in_month} AS BIGINT) + {epoch_start}\")\n",
    "            ).cast(\"timestamp\"),\n",
    "        )\n",
    "        .withColumn(\"year\", lit(load_year))\n",
    "        .withColumn(\"month\", lit(m))\n",
    "        .withColumn(\"day\", dayofmonth(col(\"txn_timestamp\")))\n",
    "        .withColumn(\"customer_id\", expr(f\"floor(rand() * {num_customers}) + 1\"))\n",
    "        .withColumn(\"product_id\", expr(f\"floor(rand() * {num_products}) + 1\"))\n",
    "        .withColumn(\"quantity\", expr(\"floor(rand()*10) + 1\"))\n",
    "        .withColumn(\"unit_price\", expr(\"round(rand()*99 + 1, 2)\"))\n",
    "        .withColumn(\"amount\", expr(\"round(quantity * unit_price, 2)\"))\n",
    "    )\n",
    "\n",
    "    # Write or replace partition in fact_transactions\n",
    "    (\n",
    "        df_month_batch.orderBy(\"year\", \"month\", \"product_id\", \"customer_id\")\n",
    "        .write.format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"replaceWhere\", f\"year = {load_year} AND month = {m}\")\n",
    "        .partitionBy(\"year\", \"month\")\n",
    "        .saveAsTable(\"fact_transactions\")\n",
    "    )\n",
    "    print(\n",
    "        f\"Loaded fact partition year={load_year}, month={m} with {facts_per_month} rows\"\n",
    "    )\n",
    "\n",
    "    # üìà  Aggregate for this month only\n",
    "    # df_agg_month = (\n",
    "    #    df_month_batch\n",
    "    #      .groupBy(\"product_id\", \"customer_id\", \"year\", \"month\")\n",
    "    #      .agg(\n",
    "    #          spark_sum(\"quantity\").alias(\"total_quantity\"),\n",
    "    #          spark_sum(\"amount\").alias(\"total_amount\")\n",
    "    #      )\n",
    "    # )\n",
    "\n",
    "    # Write or replace partition in agg_transactions\n",
    "    # (df_agg_month\n",
    "    #   .write\n",
    "    #   .format(\"delta\")\n",
    "    #   .mode(\"overwrite\")\n",
    "    #   # .option(\"replaceWhere\", f\"year = {load_year} AND month = {m}\")\n",
    "    #   # .partitionBy(\"year\", \"month\")\n",
    "    #   .saveAsTable(\"agg_transactions\")\n",
    "    # )\n",
    "    # print(f\"Loaded agg partition year={load_year}, month={m}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cb9d93-a5df-47ea-be7c-cabe9e6d72cc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:16:20.328815Z",
       "execution_start_time": "2025-06-02T14:15:57.5679301Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "6505190c-868c-4892-ac41-535a7ace9acf",
       "queued_time": "2025-06-02T14:15:57.5668133Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 9,
       "statement_ids": [
        9
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 9, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_agg = spark.sql(\n",
    "    \"Select year, month, product_id, customer_id, sum(quantity) as total_quantity, sum(amount) as total_amount  from fact_transactions group by  year, month, product_id, customer_id\"\n",
    ")\n",
    "(\n",
    "    df_agg.orderBy(\"year\", \"month\", \"product_id\", \"customer_id\")\n",
    "    .write.mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    # .partitionBy(\"year\", \"month\")\n",
    "    .option(\"parquet.vorder.enabled\", \"force_true\")\n",
    "    .saveAsTable(\"agg_transactions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5525cc18-146d-49df-8c77-ec0c4f311d51",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T10:23:05.4312525Z",
       "execution_start_time": "2025-06-02T10:23:01.250027Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "629b75dd-5b68-4971-9e1e-6028a7df2727",
       "queued_time": "2025-06-02T10:23:01.2488506Z",
       "session_id": "51afabbe-d8f0-45de-92e6-64767a52e1b3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 33,
       "statement_ids": [
        33
       ]
      },
      "text/plain": "StatementMeta(, 51afabbe-d8f0-45de-92e6-64767a52e1b3, 33, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in dim_customer     : 100\nRows in dim_day          : 31\nRows in dim_month        : 12\nRows in dim_year         : 10\nRows in dim_product      : 10\nRows in fact 2016     : 99999996\nRows in agg 2016     : 12000\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# üîç  Quick sanity checks (optional)\n",
    "print(\"Rows in dim_customer     :\", df_customers.count())\n",
    "print(\"Rows in dim_day          :\", df_day.count())\n",
    "print(\"Rows in dim_month        :\", df_month.count())\n",
    "print(\"Rows in dim_year         :\", df_year.count())\n",
    "print(\"Rows in dim_product      :\", df_products.count())\n",
    "# Example: count a specific partition (e.g., load_year-Jan)\n",
    "count_jan = spark.table(\"fact_transactions\").where(f\"year={load_year}\").count()\n",
    "print(f\"Rows in fact {load_year}     :\", count_jan)\n",
    "count_jan = spark.table(\"agg_transactions\").where(f\"year={load_year}\").count()\n",
    "print(f\"Rows in agg {load_year}     :\", count_jan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099000fb-b0a1-4902-be30-cb871180c5f5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:18:59.7054326Z",
       "execution_start_time": "2025-06-02T14:16:23.5958729Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "38de4a14-1eb1-4133-8f96-629e033028d1",
       "queued_time": "2025-06-02T14:16:23.5947266Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 10,
       "statement_ids": [
        10
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 10, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_batch = spark.sql(\"select * from fact_transactions\")\n",
    "(\n",
    "    df_batch.orderBy(\"year\", \"month\", \"product_id\", \"customer_id\")\n",
    "    .write.mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .partitionBy(\"year\", \"month\")\n",
    "    .option(\"parquet.vorder.enabled\", \"force_true\")\n",
    "    .saveAsTable(\"fact_transactions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965735cb-15d5-45a8-a747-c22f1c109171",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:19:09.7676844Z",
       "execution_start_time": "2025-06-02T14:19:06.2118906Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "63367209-00b6-4d46-9b3d-cbaf326736f2",
       "queued_time": "2025-06-02T14:19:06.2107759Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 11,
       "statement_ids": [
        11
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 11, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,numFilesUpdatedWithoutRewrite:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesUpdatedWithoutRewrite:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemovedBreakdown:array<struct<reason:string,metrics:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>>>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint>]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"Tables/fact_transactions\")\n",
    "delta_table.optimize().executeCompaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a87e27-1add-46a9-bd92-5ce382f6cb9c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-02T14:19:15.4779775Z",
       "execution_start_time": "2025-06-02T14:19:13.0965495Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "25e01cb4-0b2a-4551-bfea-a0762dad961a",
       "queued_time": "2025-06-02T14:19:13.0953765Z",
       "session_id": "88c09812-4909-4bfc-bb57-9cb8fb8d592e",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 12,
       "statement_ids": [
        12
       ]
      },
      "text/plain": "StatementMeta(, 88c09812-4909-4bfc-bb57-9cb8fb8d592e, 12, Finished, Available, Finished)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,numFilesUpdatedWithoutRewrite:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesUpdatedWithoutRewrite:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemovedBreakdown:array<struct<reason:string,metrics:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>>>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint>]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"Tables/agg_transactions\")\n",
    "delta_table.optimize().executeCompaction()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "3e1f047f-aacd-4e96-abc1-ccfea6904893",
    "default_lakehouse_name": "lake",
    "default_lakehouse_workspace_id": "38a497a3-0c63-4595-94a7-31e22e0249b0",
    "known_lakehouses": [
     {
      "id": "3e1f047f-aacd-4e96-abc1-ccfea6904893"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
