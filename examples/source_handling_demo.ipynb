{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBT Source Handling Demo\n",
    "\n",
    "This notebook demonstrates that the DAG execution logic now correctly handles sources.\n",
    "\n",
    "## Problem Fixed\n",
    "\n",
    "Previously, nodes that depended on sources would never execute because:\n",
    "1. Sources were not marked as \"completed\"\n",
    "2. The DAG executor would wait forever for source dependencies to complete\n",
    "3. This blocked the entire execution chain\n",
    "\n",
    "## Solution\n",
    "\n",
    "1. **Sources are pre-marked as completed** - They are assumed to exist\n",
    "2. **Sources are included in dependency graph** - But with empty dependencies\n",
    "3. **Sources are not executed** - They are skipped during execution\n",
    "4. **Nodes dependent on sources can now execute** - Their dependencies are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from ingen_fab.packages.dbt.runtime.dynamic import (\n",
    "    DynamicModelLoader,\n",
    "    DynamicDAGExecutor,\n",
    "    DAGAnalyzer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project setup\n",
    "project_path = Path(\"./sample_project/dbt_project\")\n",
    "print(f\"Using project: {project_path}\")\n",
    "print(f\"Project exists: {project_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Examine Sources in Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manifest and examine sources\n",
    "loader = DynamicModelLoader(project_path)\n",
    "manifest = loader.manifest\n",
    "\n",
    "sources = manifest.get(\"sources\", {})\n",
    "nodes = manifest.get(\"nodes\", {})\n",
    "\n",
    "print(f\"Total sources: {len(sources)}\")\n",
    "print(f\"Total nodes: {len(nodes)}\")\n",
    "\n",
    "print(\"\\nSource examples:\")\n",
    "for i, (source_id, source_data) in enumerate(list(sources.items())[:3], 1):\n",
    "    print(f\"{i}. {source_id}\")\n",
    "    print(f\"   Database: {source_data.get('database')}\")\n",
    "    print(f\"   Schema: {source_data.get('schema')}\")\n",
    "    print(f\"   Name: {source_data.get('name')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demonstrate Source Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find models that depend on sources\n",
    "models = loader.get_nodes_by_type(\"model\")\n",
    "source_dependent_models = []\n",
    "\n",
    "for model_id in models:\n",
    "    deps = loader.get_dependencies(model_id)\n",
    "    source_deps = [dep for dep in deps if dep in sources]\n",
    "    if source_deps:\n",
    "        source_dependent_models.append((model_id, source_deps))\n",
    "\n",
    "print(f\"Models that depend on sources: {len(source_dependent_models)}\")\n",
    "print(\"\\nExamples:\")\n",
    "for i, (model, deps) in enumerate(source_dependent_models[:5], 1):\n",
    "    print(f\"{i}. {model}\")\n",
    "    print(f\"   Source dependencies: {len(deps)}\")\n",
    "    for dep in deps[:2]:\n",
    "        print(f\"     - {dep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test DAG Executor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock Spark session for testing\n",
    "class MockSparkSession:\n",
    "    def sql(self, query):\n",
    "        print(f\"Would execute: {query[:50]}...\")\n",
    "        return None\n",
    "\n",
    "mock_spark = MockSparkSession()\n",
    "\n",
    "# Create DAG executor\n",
    "executor = DynamicDAGExecutor(mock_spark, project_path)\n",
    "\n",
    "print(f\"Total nodes in execution tracking: {len(executor.execution_status)}\")\n",
    "\n",
    "# Check status of sources\n",
    "source_statuses = {\n",
    "    source_id: executor.execution_status.get(source_id, \"NOT_FOUND\")\n",
    "    for source_id in list(sources.keys())[:5]\n",
    "}\n",
    "\n",
    "print(\"\\nSource execution status:\")\n",
    "for source_id, status in source_statuses.items():\n",
    "    print(f\"  {source_id}: {status}\")\n",
    "\n",
    "# Verify all sources are marked as completed\n",
    "all_sources_completed = all(\n",
    "    executor.execution_status.get(source_id) == \"completed\"\n",
    "    for source_id in sources\n",
    ")\n",
    "print(f\"\\n‚úÖ All sources marked as completed: {all_sources_completed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Ready Nodes Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes ready for execution\n",
    "ready_nodes = executor.get_ready_nodes()\n",
    "print(f\"Nodes ready to execute: {len(ready_nodes)}\")\n",
    "\n",
    "# Analyze ready nodes\n",
    "ready_by_type = {}\n",
    "source_only_deps = []\n",
    "no_deps = []\n",
    "\n",
    "for node_id in ready_nodes:\n",
    "    node = loader.get_node(node_id)\n",
    "    if node:\n",
    "        resource_type = node.get(\"resource_type\", \"unknown\")\n",
    "        ready_by_type[resource_type] = ready_by_type.get(resource_type, 0) + 1\n",
    "        \n",
    "        # Check dependencies\n",
    "        deps = loader.get_dependencies(node_id)\n",
    "        source_deps = [dep for dep in deps if dep in sources]\n",
    "        other_deps = [dep for dep in deps if dep not in sources]\n",
    "        \n",
    "        if source_deps and not other_deps:\n",
    "            source_only_deps.append(node_id)\n",
    "        elif not deps:\n",
    "            no_deps.append(node_id)\n",
    "\n",
    "print(\"\\nReady nodes by type:\")\n",
    "for rtype, count in ready_by_type.items():\n",
    "    print(f\"  {rtype}: {count}\")\n",
    "\n",
    "print(f\"\\nNodes with only source dependencies: {len(source_only_deps)}\")\n",
    "print(f\"Nodes with no dependencies: {len(no_deps)}\")\n",
    "\n",
    "print(\"\\nExample nodes ready to execute (depend only on sources):\")\n",
    "for i, node_id in enumerate(source_only_deps[:3], 1):\n",
    "    deps = loader.get_dependencies(node_id)\n",
    "    source_deps = [dep for dep in deps if dep in sources]\n",
    "    print(f\"{i}. {node_id}\")\n",
    "    print(f\"   Source dependencies: {len(source_deps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Source Skipping During Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that sources are skipped during execution\n",
    "sample_source = list(sources.keys())[0]\n",
    "print(f\"Testing execution of source: {sample_source}\")\n",
    "\n",
    "try:\n",
    "    result = executor.execute_node(sample_source)\n",
    "    print(f\"‚úÖ Source execution handled correctly\")\n",
    "    print(f\"   Result: {result}\")\n",
    "    print(f\"   Status: {executor.execution_status[sample_source]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing source: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demonstrate Working Dependency Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the dependency chain now works\n",
    "if source_only_deps:\n",
    "    sample_model = source_only_deps[0]\n",
    "    print(f\"Testing model that depends on sources: {sample_model}\")\n",
    "    \n",
    "    # Check dependencies\n",
    "    deps = loader.get_dependencies(sample_model)\n",
    "    print(f\"Dependencies: {deps}\")\n",
    "    \n",
    "    # Check if all dependencies are satisfied\n",
    "    deps_satisfied = all(\n",
    "        executor.execution_status.get(dep) == \"completed\"\n",
    "        for dep in deps\n",
    "    )\n",
    "    print(f\"All dependencies satisfied: {deps_satisfied}\")\n",
    "    \n",
    "    # Check if model is ready\n",
    "    is_ready = sample_model in executor.get_ready_nodes()\n",
    "    print(f\"Model is ready to execute: {is_ready}\")\n",
    "    \n",
    "    if is_ready:\n",
    "        print(\"\\n‚úÖ SUCCESS: Models dependent on sources can now execute!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå ISSUE: Model still not ready despite sources being completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive validation\n",
    "validation_results = []\n",
    "\n",
    "# Test 1: Sources in dependency graph\n",
    "deps = loader.build_dependency_graph()\n",
    "sources_in_graph = sum(1 for node in deps if node in sources)\n",
    "validation_results.append((\n",
    "    \"Sources included in dependency graph\",\n",
    "    sources_in_graph == len(sources),\n",
    "    f\"{sources_in_graph}/{len(sources)}\"\n",
    "))\n",
    "\n",
    "# Test 2: Sources marked as completed\n",
    "sources_completed = sum(\n",
    "    1 for source_id in sources\n",
    "    if executor.execution_status.get(source_id) == \"completed\"\n",
    ")\n",
    "validation_results.append((\n",
    "    \"Sources marked as completed\",\n",
    "    sources_completed == len(sources),\n",
    "    f\"{sources_completed}/{len(sources)}\"\n",
    "))\n",
    "\n",
    "# Test 3: Models dependent on sources are ready\n",
    "ready_source_models = sum(\n",
    "    1 for model_id, _ in source_dependent_models\n",
    "    if model_id in ready_nodes\n",
    ")\n",
    "validation_results.append((\n",
    "    \"Source-dependent models ready\",\n",
    "    ready_source_models > 0,\n",
    "    f\"{ready_source_models}/{len(source_dependent_models)}\"\n",
    "))\n",
    "\n",
    "# Test 4: Source execution is handled\n",
    "sample_source = list(sources.keys())[0]\n",
    "try:\n",
    "    executor.execute_node(sample_source)\n",
    "    source_exec_handled = executor.execution_status[sample_source] == \"completed\"\n",
    "except:\n",
    "    source_exec_handled = False\n",
    "\n",
    "validation_results.append((\n",
    "    \"Source execution handled correctly\",\n",
    "    source_exec_handled,\n",
    "    \"skipped as expected\" if source_exec_handled else \"failed\"\n",
    "))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_passed = True\n",
    "for test_name, passed, details in validation_results:\n",
    "    status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "    print(f\"{status} {test_name}: {details}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_passed:\n",
    "    print(\"üéâ ALL TESTS PASSED! Source handling is working correctly.\")\n",
    "    print(\"\\nNodes that depend on sources can now execute properly!\")\n",
    "else:\n",
    "    print(\"‚ùå Some validations failed. Source handling needs more work.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}