{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBT DAG Utilities Demo\n",
    "\n",
    "This notebook demonstrates the comprehensive DAG analysis and visualization utilities\n",
    "available in the dynamic runtime package.\n",
    "\n",
    "## Features\n",
    "\n",
    "- DAG structure analysis\n",
    "- Node information retrieval\n",
    "- Dependency and lineage tracking\n",
    "- Impact analysis\n",
    "- Visualization tools\n",
    "- Execution planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Import DAG utilities\n",
    "from ingen_fab.packages.dbt.runtime.dynamic import (\n",
    "    DAGAnalyzer,\n",
    "    DAGVisualizer,\n",
    "    get_dag_info,\n",
    "    get_node_details,\n",
    "    find_nodes,\n",
    "    analyze_impact,\n",
    "    create_dag_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your dbt project path\n",
    "dbt_project_path = Path(\"./sample_project\")\n",
    "\n",
    "# Verify the path exists\n",
    "if not dbt_project_path.exists():\n",
    "    print(f\"Project path {dbt_project_path} does not exist!\")\n",
    "else:\n",
    "    print(f\"Using dbt project at: {dbt_project_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick DAG Information\n",
    "\n",
    "Use the convenience functions for quick access to DAG information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overall DAG summary\n",
    "dag_summary = get_dag_info(dbt_project_path)\n",
    "\n",
    "print(\"DAG Summary:\")\n",
    "print(f\"Total Nodes: {dag_summary['total_nodes']}\")\n",
    "print(f\"Node Types: {dag_summary['node_types']}\")\n",
    "print(f\"DAG Depth: {dag_summary['dag_depth']}\")\n",
    "print(f\"Has Cycles: {dag_summary['has_cycles']}\")\n",
    "print(f\"Root Nodes: {dag_summary['root_nodes']}\")\n",
    "print(f\"Leaf Nodes: {dag_summary['leaf_nodes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nodes by pattern\n",
    "pattern = \"dim\"  # Search for dimension tables\n",
    "matching_nodes = find_nodes(dbt_project_path, pattern)\n",
    "\n",
    "print(f\"\\nNodes matching '{pattern}':\")\n",
    "for node in matching_nodes[:10]:\n",
    "    print(f\"  - {node}\")\n",
    "    \n",
    "if len(matching_nodes) > 10:\n",
    "    print(f\"  ... and {len(matching_nodes) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detailed Node Analysis\n",
    "\n",
    "Get comprehensive information about specific nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analyzer instance for more detailed work\n",
    "analyzer = DAGAnalyzer(dbt_project_path)\n",
    "\n",
    "# Get all nodes and select one for analysis\n",
    "all_nodes = analyzer.loader.get_all_nodes()\n",
    "models = analyzer.loader.get_nodes_by_type(\"model\")\n",
    "\n",
    "if models:\n",
    "    sample_node = models[0]\n",
    "    node_info = analyzer.get_node_info(sample_node)\n",
    "    \n",
    "    print(f\"Detailed information for node: {sample_node}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Name: {node_info['name']}\")\n",
    "    print(f\"Type: {node_info['resource_type']}\")\n",
    "    print(f\"Database: {node_info['database']}\")\n",
    "    print(f\"Schema: {node_info['schema']}\")\n",
    "    print(f\"Path: {node_info['path']}\")\n",
    "    print(f\"\\nDependencies:\")\n",
    "    print(f\"  Direct upstream: {len(node_info['direct_dependencies'])} nodes\")\n",
    "    print(f\"  Direct downstream: {len(node_info['direct_dependents'])} nodes\")\n",
    "    print(f\"  Total upstream: {node_info['total_upstream']} nodes\")\n",
    "    print(f\"  Total downstream: {node_info['total_downstream']} nodes\")\n",
    "    print(f\"\\nNode Properties:\")\n",
    "    print(f\"  Is Root: {node_info['is_root']}\")\n",
    "    print(f\"  Is Leaf: {node_info['is_leaf']}\")\n",
    "    print(f\"  SQL Statements: {node_info['sql_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lineage Analysis\n",
    "\n",
    "Trace the complete lineage of data through the DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models:\n",
    "    # Get lineage for a sample model\n",
    "    lineage = analyzer.get_node_lineage(models[0])\n",
    "    \n",
    "    print(f\"Lineage for {models[0]}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nUpstream (dependencies):\")\n",
    "    print(f\"  Total: {lineage['upstream']['total']} nodes\")\n",
    "    print(\"  By type:\")\n",
    "    for node_type, nodes in lineage['upstream']['by_type'].items():\n",
    "        print(f\"    - {node_type}: {len(nodes)} nodes\")\n",
    "    \n",
    "    print(\"\\nDownstream (dependents):\")\n",
    "    print(f\"  Total: {lineage['downstream']['total']} nodes\")\n",
    "    print(\"  By type:\")\n",
    "    for node_type, nodes in lineage['downstream']['by_type'].items():\n",
    "        print(f\"    - {node_type}: {len(nodes)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Impact Analysis\n",
    "\n",
    "Understand the impact of changes to specific nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models:\n",
    "    # Analyze impact of changes to a model\n",
    "    impact = analyzer.get_impact_analysis(models[0])\n",
    "    \n",
    "    print(f\"Impact Analysis for {models[0]}:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total nodes impacted: {impact['total_impact']}\")\n",
    "    print(f\"Immediate impact: {impact['immediate_impact']} nodes\")\n",
    "    \n",
    "    print(\"\\nImpact by resource type:\")\n",
    "    for node_type, nodes in impact['impacted_by_type'].items():\n",
    "        print(f\"  - {node_type}: {len(nodes)} nodes\")\n",
    "    \n",
    "    if impact['critical_downstream']:\n",
    "        print(\"\\nCritical downstream nodes (high further impact):\")\n",
    "        for critical in impact['critical_downstream'][:5]:\n",
    "            print(f\"  - {critical['node_id']}: impacts {critical['further_impact']} more nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execution Planning\n",
    "\n",
    "Understand the execution order and parallelization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get execution order\n",
    "execution_order = analyzer.get_execution_order()\n",
    "\n",
    "print(f\"Execution Plan: {len(execution_order)} stages\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, stage in enumerate(execution_order[:5], 1):  # Show first 5 stages\n",
    "    print(f\"\\nStage {i}: {len(stage)} nodes can run in parallel\")\n",
    "    \n",
    "    # Show node types in this stage\n",
    "    stage_types = {}\n",
    "    for node_id in stage:\n",
    "        node = analyzer.loader.get_node(node_id)\n",
    "        if node:\n",
    "            rtype = node.get('resource_type', 'unknown')\n",
    "            stage_types[rtype] = stage_types.get(rtype, 0) + 1\n",
    "    \n",
    "    print(\"  Node types:\")\n",
    "    for node_type, count in stage_types.items():\n",
    "        print(f\"    - {node_type}: {count}\")\n",
    "    \n",
    "    # Show sample nodes\n",
    "    print(\"  Sample nodes:\")\n",
    "    for node_id in stage[:3]:\n",
    "        node = analyzer.loader.get_node(node_id)\n",
    "        if node:\n",
    "            print(f\"    - {node.get('name', node_id)}\")\n",
    "\n",
    "if len(execution_order) > 5:\n",
    "    print(f\"\\n... and {len(execution_order) - 5} more stages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the critical path\n",
    "critical_path = analyzer.get_critical_path()\n",
    "\n",
    "print(f\"Critical Path: {len(critical_path)} nodes\")\n",
    "print(\"=\" * 60)\n",
    "print(\"The longest path through the DAG:\")\n",
    "\n",
    "for i, node_id in enumerate(critical_path[:10], 1):\n",
    "    node = analyzer.loader.get_node(node_id)\n",
    "    if node:\n",
    "        name = node.get('name', node_id)\n",
    "        rtype = node.get('resource_type', 'unknown')\n",
    "        print(f\"{i}. {name} ({rtype})\")\n",
    "\n",
    "if len(critical_path) > 10:\n",
    "    print(f\"... and {len(critical_path) - 10} more nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DAG Visualization\n",
    "\n",
    "Generate various visualizations of the DAG structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "visualizer = DAGVisualizer(dbt_project_path)\n",
    "\n",
    "# Print DAG statistics\n",
    "visualizer.print_dag_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ASCII tree for a node\n",
    "if models:\n",
    "    print(f\"\\nDownstream tree for {models[0]}:\")\n",
    "    print(\"=\" * 60)\n",
    "    tree = visualizer.generate_ascii_tree(models[0], direction=\"downstream\", max_depth=3)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate upstream tree\n",
    "if models and len(models) > 1:\n",
    "    print(f\"\\nUpstream tree for {models[1]}:\")\n",
    "    print(\"=\" * 60)\n",
    "    tree = visualizer.generate_ascii_tree(models[1], direction=\"upstream\", max_depth=3)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Mermaid diagram (for use in documentation)\n",
    "if models:\n",
    "    # Generate diagram for a subset of nodes\n",
    "    mermaid = visualizer.generate_mermaid_diagram(\n",
    "        target_nodes=models[:3],  # Focus on first 3 models\n",
    "        max_nodes=20,\n",
    "        include_tests=False\n",
    "    )\n",
    "    \n",
    "    print(\"Mermaid Diagram (copy to Mermaid Live Editor):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(mermaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dependency matrix\n",
    "if models:\n",
    "    print(\"\\nDependency Matrix:\")\n",
    "    print(\"=\" * 60)\n",
    "    matrix = visualizer.generate_dependency_matrix(models[:5])\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cycle Detection\n",
    "\n",
    "Check for and identify cycles in the DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect cycles\n",
    "has_cycles, cycles = analyzer.detect_cycles()\n",
    "\n",
    "print(\"Cycle Detection:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if has_cycles:\n",
    "    print(f\"⚠️ Found {len(cycles)} cycle(s) in the DAG!\")\n",
    "    for i, cycle in enumerate(cycles, 1):\n",
    "        print(f\"\\nCycle {i}:\")\n",
    "        for node in cycle:\n",
    "            print(f\"  → {node}\")\n",
    "else:\n",
    "    print(\"✅ No cycles detected - DAG is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export and Reporting\n",
    "\n",
    "Export DAG information for further analysis or documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DAG to JSON\n",
    "output_path = Path(\"dag_export.json\")\n",
    "dag_json = analyzer.export_dag_to_json(output_path)\n",
    "\n",
    "print(f\"DAG exported to {output_path}\")\n",
    "print(f\"File size: {len(dag_json)} characters\")\n",
    "\n",
    "# Show sample of exported data\n",
    "dag_data = json.loads(dag_json)\n",
    "print(f\"\\nExported {len(dag_data['nodes'])} nodes\")\n",
    "print(f\"Exported {len(dag_data['edges'])} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "report_path = Path(\"dag_report.md\")\n",
    "report = create_dag_report(dbt_project_path, report_path)\n",
    "\n",
    "print(f\"Report generated and saved to {report_path}\")\n",
    "print(\"\\nReport Preview:\")\n",
    "print(\"=\" * 60)\n",
    "print(report[:1000])  # Show first 1000 characters\n",
    "print(\"\\n... (truncated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Queries\n",
    "\n",
    "Examples of more complex DAG queries and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all test nodes that depend on a specific model\n",
    "if models:\n",
    "    target_model = models[0]\n",
    "    all_tests = analyzer.loader.get_nodes_by_type(\"test\")\n",
    "    \n",
    "    dependent_tests = []\n",
    "    for test_node in all_tests:\n",
    "        dependencies = analyzer.loader.get_dependencies(test_node)\n",
    "        if target_model in dependencies:\n",
    "            dependent_tests.append(test_node)\n",
    "    \n",
    "    print(f\"Tests that depend on {target_model}:\")\n",
    "    for test in dependent_tests:\n",
    "        test_info = analyzer.loader.get_node(test)\n",
    "        if test_info:\n",
    "            print(f\"  - {test_info.get('name', test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find models with no tests\n",
    "models_with_tests = set()\n",
    "all_tests = analyzer.loader.get_nodes_by_type(\"test\")\n",
    "\n",
    "for test_node in all_tests:\n",
    "    dependencies = analyzer.loader.get_dependencies(test_node)\n",
    "    for dep in dependencies:\n",
    "        if dep.startswith(\"model.\"):\n",
    "            models_with_tests.add(dep)\n",
    "\n",
    "all_models = set(analyzer.loader.get_nodes_by_type(\"model\"))\n",
    "models_without_tests = all_models - models_with_tests\n",
    "\n",
    "print(f\"Models without tests: {len(models_without_tests)} of {len(all_models)}\")\n",
    "if models_without_tests:\n",
    "    print(\"\\nSample models without tests:\")\n",
    "    for model in list(models_without_tests)[:10]:\n",
    "        model_info = analyzer.loader.get_node(model)\n",
    "        if model_info:\n",
    "            print(f\"  - {model_info.get('name', model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find isolated nodes (no dependencies and no dependents)\n",
    "isolated_nodes = []\n",
    "for node_id in analyzer.loader.get_all_nodes():\n",
    "    deps = analyzer.loader.get_dependencies(node_id)\n",
    "    dependents = analyzer.loader.get_dependents(node_id)\n",
    "    \n",
    "    if not deps and not dependents:\n",
    "        isolated_nodes.append(node_id)\n",
    "\n",
    "if isolated_nodes:\n",
    "    print(f\"Found {len(isolated_nodes)} isolated nodes:\")\n",
    "    for node in isolated_nodes[:10]:\n",
    "        node_info = analyzer.loader.get_node(node)\n",
    "        if node_info:\n",
    "            rtype = node_info.get('resource_type', 'unknown')\n",
    "            name = node_info.get('name', node)\n",
    "            print(f\"  - {name} ({rtype})\")\n",
    "else:\n",
    "    print(\"No isolated nodes found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis\n",
    "\n",
    "Analyze DAG characteristics that might impact performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential bottlenecks (nodes with many dependents)\n",
    "bottlenecks = []\n",
    "for node_id in analyzer.loader.get_all_nodes():\n",
    "    dependents = analyzer.loader.get_dependents(node_id)\n",
    "    if len(dependents) > 3:  # Threshold for bottleneck\n",
    "        bottlenecks.append((node_id, len(dependents)))\n",
    "\n",
    "bottlenecks.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Potential Bottlenecks (nodes with many direct dependents):\")\n",
    "print(\"=\" * 60)\n",
    "for node_id, dep_count in bottlenecks[:10]:\n",
    "    node_info = analyzer.loader.get_node(node_id)\n",
    "    if node_info:\n",
    "        name = node_info.get('name', node_id)\n",
    "        rtype = node_info.get('resource_type', 'unknown')\n",
    "        print(f\"{name} ({rtype}): {dep_count} direct dependents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parallelization efficiency\n",
    "execution_order = analyzer.get_execution_order()\n",
    "total_nodes = sum(len(stage) for stage in execution_order)\n",
    "stages = len(execution_order)\n",
    "\n",
    "if stages > 0:\n",
    "    avg_parallelism = total_nodes / stages\n",
    "    max_parallelism = max(len(stage) for stage in execution_order)\n",
    "    \n",
    "    print(\"Parallelization Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total execution stages: {stages}\")\n",
    "    print(f\"Average nodes per stage: {avg_parallelism:.2f}\")\n",
    "    print(f\"Maximum parallel nodes: {max_parallelism}\")\n",
    "    print(f\"\\nParallelization efficiency: {(avg_parallelism / max_parallelism * 100):.1f}%\")\n",
    "    \n",
    "    # Show stage distribution\n",
    "    print(\"\\nStage size distribution:\")\n",
    "    for i, stage in enumerate(execution_order[:10], 1):\n",
    "        bar = \"█\" * min(len(stage), 50)\n",
    "        print(f\"  Stage {i:2d}: {bar} ({len(stage)} nodes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the comprehensive DAG utilities available for:\n",
    "\n",
    "1. **Analysis**: Understanding DAG structure, dependencies, and characteristics\n",
    "2. **Navigation**: Finding nodes, tracing lineage, and exploring relationships\n",
    "3. **Impact Assessment**: Understanding the effects of changes\n",
    "4. **Visualization**: Multiple ways to visualize DAG structure\n",
    "5. **Optimization**: Identifying bottlenecks and parallelization opportunities\n",
    "6. **Validation**: Detecting cycles and structural issues\n",
    "7. **Reporting**: Generating comprehensive reports and exports\n",
    "\n",
    "These utilities make it easy to understand and work with complex dbt DAGs dynamically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}