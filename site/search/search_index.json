{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ingenious Fabric Accelerator","text":"<p>Ingenious for Fabric is a comprehensive command line tool built with Typer that helps create and manage Microsoft Fabric assets. It provides a complete development workflow for Fabric workspaces, including project initialization, DDL notebook generation, environment management, and deployment automation.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Project Initialization: Create new Fabric workspace projects with proper structure and templates</li> <li>DDL Notebook Generation: Generate DDL notebooks from Jinja templates for both lakehouses and warehouses</li> <li>Environment Management: Deploy and manage artifacts across multiple environments (development, test, production)</li> <li>Orchestrator Notebooks: Create orchestrator notebooks to run generated notebooks in sequence</li> <li>Notebook Utilities: Scan and analyze existing notebook code and content</li> <li>Testing Framework: Test notebooks both locally and on the Fabric platform</li> <li>Python Libraries: Reusable Python and PySpark libraries for common Fabric operations</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#initialize-a-new-project","title":"Initialize a New Project","text":"<pre><code># Create a new Fabric workspace project\ningen_fab init solution --project-name \"My Fabric Project\"\n</code></pre>"},{"location":"#generate-ddl-notebooks","title":"Generate DDL Notebooks","text":"<pre><code># Generate DDL notebooks for warehouses\ningen_fab ddl compile-notebooks \\\n    --output-mode fabric \\\n    --generation-mode warehouse\n\n# Generate DDL notebooks for lakehouses  \ningen_fab ddl compile-notebooks \\\n    --output-mode fabric \\\n    --generation-mode lakehouse\n</code></pre>"},{"location":"#deploy-to-environment","title":"Deploy to Environment","text":"<pre><code># Deploy to development environment\ningen_fab deploy to-environment \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<p>New to Ingenious Fabric Accelerator?</p> <p>Start with our Installation Guide to get up and running quickly.</p> <p>Ready to dive in?</p> <p>Check out our Sample Project for a complete walkthrough.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The tool is organized into several key components:</p> <pre><code>ingen_fab/\n\u251c\u2500\u2500 cli_utils/            # CLI command implementations\n\u251c\u2500\u2500 ddl_scripts/          # Jinja templates for DDL notebook generation\n\u251c\u2500\u2500 notebook_utils/       # Notebook scanning and injection helpers\n\u251c\u2500\u2500 python_libs/          # Shared Python and PySpark libraries\n\u251c\u2500\u2500 python_libs_tests/    # Test suites for Python libraries\nsample_project/           # Example workspace demonstrating project layout\nproject_templates/        # Templates for new project initialization\n</code></pre>"},{"location":"#command-groups","title":"Command Groups","text":"<ul> <li><code>init</code> - Initialize solutions and projects</li> <li><code>ddl</code> - Compile DDL notebooks from templates</li> <li><code>deploy</code> - Deploy to environments and manage workspace items</li> <li><code>notebook</code> - Manage and scan notebook content</li> <li><code>test</code> - Test notebooks and Python blocks (local and platform)</li> </ul>"},{"location":"#core-concepts","title":"Core Concepts","text":""},{"location":"#environment-management","title":"Environment Management","text":"<p>Manage multiple environments (development, test, production) with environment-specific configurations and variable libraries.</p>"},{"location":"#ddl-script-management","title":"DDL Script Management","text":"<p>Organize DDL scripts in numbered sequence for controlled execution, supporting both SQL and Python scripts with idempotent execution.</p>"},{"location":"#notebook-generation","title":"Notebook Generation","text":"<p>Automatically generate notebooks from templates with proper error handling, logging, and orchestration capabilities.</p>"},{"location":"#testing-framework","title":"Testing Framework","text":"<p>Comprehensive testing framework supporting both local development and Fabric platform testing.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Get Started</p> <p>Install and configure Ingenious Fabric Accelerator</p> <p> Installation Guide</p> </li> <li> <p> User Guide</p> <p>Learn how to use all features and commands</p> <p> User Guide</p> </li> <li> <p> Developer Guide</p> <p>Understand the architecture and extend functionality</p> <p> Developer Guide</p> </li> <li> <p> Examples</p> <p>See real-world examples and best practices</p> <p> Examples</p> </li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>Issues: Report bugs and request features on GitHub Issues</li> <li>Discussions: Join community discussions on GitHub Discussions</li> <li>Documentation: Browse the complete documentation on this site</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#overview","title":"Overview","text":"<p>The Ingenious Fabric Accelerator provides comprehensive APIs for building, deploying, and managing Microsoft Fabric applications. This reference covers all available APIs, including CLI commands and Python interfaces.</p>"},{"location":"api/#api-categories","title":"API Categories","text":""},{"location":"api/#cli-commands","title":"CLI Commands","text":"<p>Command-line interface for interacting with the accelerator tools.</p>"},{"location":"api/#python-apis","title":"Python APIs","text":"<p>Python libraries and modules for programmatic access.</p>"},{"location":"api/#quick-start","title":"Quick Start","text":""},{"location":"api/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Install the CLI\npip install insight-ingenious-for-fabric\n\n# Get help\ningen_fab --help\n\n# Initialize new project\ningen_fab init --template basic --name my_project\n\n# Compile DDL scripts\ningen_fab ddl compile --environment production\n</code></pre>"},{"location":"api/#python-api","title":"Python API","text":"<pre><code>from ingen_fab.python_libs import get_notebook_utils\nfrom ingen_fab.ddl_scripts import DDLScriptGenerator\n\n# Get utilities\nutils = get_notebook_utils()\n\n# Generate DDL scripts\ngenerator = DDLScriptGenerator()\nscripts = generator.generate_all()\n</code></pre>"},{"location":"api/#authentication","title":"Authentication","text":""},{"location":"api/#cli-authentication","title":"CLI Authentication","text":"<pre><code># Login to Azure\naz login\n\n# Set Fabric workspace\nexport FABRIC_WORKSPACE_ID=your-workspace-id\n</code></pre>"},{"location":"api/#python-authentication","title":"Python Authentication","text":"<pre><code>from azure.identity import DefaultAzureCredential\nfrom ingen_fab.fabric_api import FabricClient\n\n# Authenticate\ncredential = DefaultAzureCredential()\nclient = FabricClient(credential)\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#cli-errors","title":"CLI Errors","text":"<pre><code># Verbose output for debugging\ningen_fab --verbose ddl compile\n\n# Check logs\ntail -f ~/.ingen_fab/logs/cli.log\n</code></pre>"},{"location":"api/#python-errors","title":"Python Errors","text":"<pre><code>from ingen_fab.exceptions import IngenFabError\n\ntry:\n    result = utils.execute_query(sql)\nexcept IngenFabError as e:\n    print(f\"Operation failed: {e}\")\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":""},{"location":"api/#global-configuration","title":"Global Configuration","text":"<pre><code>{\n  \"default_environment\": \"development\",\n  \"logging\": {\n    \"level\": \"INFO\",\n    \"file\": \"~/.ingen_fab/logs/api.log\"\n  },\n  \"fabric\": {\n    \"workspace_id\": \"default-workspace-id\",\n    \"timeout\": 30\n  }\n}\n</code></pre>"},{"location":"api/#environment-variables","title":"Environment Variables","text":"<pre><code># Core settings\nexport INGEN_FAB_ENVIRONMENT=production\nexport FABRIC_WORKSPACE_ID=your-workspace-id\n\n# Logging\nexport INGEN_FAB_LOG_LEVEL=DEBUG\nexport INGEN_FAB_LOG_FILE=/path/to/log/file\n\n# Database connections\nexport DATABASE_CONNECTION_STRING=your-connection-string\n</code></pre>"},{"location":"api/#api-versioning","title":"API Versioning","text":"<p>The API follows semantic versioning:</p> <ul> <li>Major version: Breaking changes</li> <li>Minor version: New features, backward compatible</li> <li>Patch version: Bug fixes</li> </ul> <p>Current version: <code>0.1.0</code></p>"},{"location":"api/#version-compatibility","title":"Version Compatibility","text":"<pre><code>import ingen_fab\n\n# Check version\nprint(ingen_fab.__version__)\n\n# Check compatibility\nif ingen_fab.version_info &gt;= (0, 1, 0):\n    # Use new features\n    pass\n</code></pre>"},{"location":"api/#rate-limiting","title":"Rate Limiting","text":""},{"location":"api/#fabric-api-limits","title":"Fabric API Limits","text":"<ul> <li>Requests per minute: 1000</li> <li>Concurrent requests: 10</li> <li>Data transfer: 100MB per request</li> </ul>"},{"location":"api/#best-practices","title":"Best Practices","text":"<pre><code>import time\nfrom ingen_fab.fabric_api import FabricClient\n\nclient = FabricClient()\n\n# Rate limiting\nfor item in large_dataset:\n    client.process_item(item)\n    time.sleep(0.1)  # Throttle requests\n</code></pre>"},{"location":"api/#common-patterns","title":"Common Patterns","text":""},{"location":"api/#batch-operations","title":"Batch Operations","text":"<pre><code>from ingen_fab.python_libs import BatchProcessor\n\nprocessor = BatchProcessor(batch_size=100)\n\n# Process items in batches\nfor batch in processor.process(items):\n    results = client.process_batch(batch)\n</code></pre>"},{"location":"api/#error-recovery","title":"Error Recovery","text":"<pre><code>from ingen_fab.utils import RetryHandler\n\nretry_handler = RetryHandler(max_retries=3, backoff_factor=2)\n\n@retry_handler.retry\ndef unreliable_operation():\n    return client.execute_query(sql)\n</code></pre>"},{"location":"api/#context-management","title":"Context Management","text":"<pre><code>from ingen_fab.notebook_utils import get_notebook_utils\n\nwith get_notebook_utils() as utils:\n    # Resources are automatically managed\n    result = utils.execute_query(sql)\n</code></pre>"},{"location":"api/#testing","title":"Testing","text":""},{"location":"api/#unit-testing","title":"Unit Testing","text":"<pre><code>import unittest\nfrom unittest.mock import patch\nfrom ingen_fab.python_libs import NotebookUtils\n\nclass TestNotebookUtils(unittest.TestCase):\n    @patch('ingen_fab.python_libs.get_connection')\n    def test_execute_query(self, mock_connection):\n        utils = NotebookUtils()\n        result = utils.execute_query(\"SELECT 1\")\n        self.assertIsNotNone(result)\n</code></pre>"},{"location":"api/#integration-testing","title":"Integration Testing","text":"<pre><code>import pytest\nfrom ingen_fab.fabric_api import FabricClient\n\n@pytest.mark.integration\ndef test_fabric_integration():\n    client = FabricClient()\n    workspaces = client.list_workspaces()\n    assert len(workspaces) &gt; 0\n</code></pre>"},{"location":"api/#performance","title":"Performance","text":""},{"location":"api/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Use batch operations for multiple items</li> <li>Enable connection pooling for database operations</li> <li>Cache frequently accessed data</li> <li>Use async operations where available</li> </ol>"},{"location":"api/#monitoring","title":"Monitoring","text":"<pre><code>from ingen_fab.monitoring import MetricsCollector\n\ncollector = MetricsCollector()\n\n# Track operation performance\nwith collector.timer('query_execution'):\n    result = utils.execute_query(sql)\n\n# View metrics\nprint(collector.get_metrics())\n</code></pre>"},{"location":"api/#examples","title":"Examples","text":""},{"location":"api/#complete-workflow","title":"Complete Workflow","text":"<pre><code>from ingen_fab.python_libs import get_notebook_utils\nfrom ingen_fab.ddl_scripts import DDLScriptGenerator\nfrom ingen_fab.fabric_api import FabricClient\n\n# Initialize components\nutils = get_notebook_utils()\ngenerator = DDLScriptGenerator()\nclient = FabricClient()\n\n# Generate DDL scripts\nscripts = generator.generate_all()\n\n# Deploy to Fabric\nfor script in scripts:\n    notebook = client.create_notebook(script)\n    client.execute_notebook(notebook.id)\n\n# Verify deployment\ntables = utils.list_tables()\nprint(f\"Created {len(tables)} tables\")\n</code></pre>"},{"location":"api/#custom-extensions","title":"Custom Extensions","text":"<pre><code>from ingen_fab.python_libs import NotebookUtils\n\nclass CustomNotebookUtils(NotebookUtils):\n    def custom_operation(self, data):\n        \"\"\"Custom business logic\"\"\"\n        processed_data = self.process_data(data)\n        return self.save_results(processed_data)\n\n# Register custom implementation\nutils = CustomNotebookUtils()\n</code></pre>"},{"location":"api/#support","title":"Support","text":""},{"location":"api/#documentation","title":"Documentation","text":"<ul> <li>User Guide: Step-by-step instructions</li> <li>Developer Guide: Architecture and development</li> <li>Examples: Real-world usage patterns</li> </ul>"},{"location":"api/#community","title":"Community","text":"<ul> <li>GitHub Issues: Bug reports and feature requests</li> <li>Discussions: Community questions and answers</li> <li>Contributions: How to contribute to the project</li> </ul>"},{"location":"api/#getting-help","title":"Getting Help","text":"<pre><code># CLI help\ningen_fab --help\ningen_fab &lt;command&gt; --help\n\n# Python help\npython -c \"import ingen_fab; help(ingen_fab)\"\n</code></pre>"},{"location":"api/#changelog","title":"Changelog","text":""},{"location":"api/#version-010","title":"Version 0.1.0","text":"<ul> <li>Initial release</li> <li>Basic CLI commands</li> <li>Core Python libraries</li> <li>Fabric integration</li> <li>Template system</li> </ul>"},{"location":"api/#upcoming-features","title":"Upcoming Features","text":"<ul> <li>Advanced error handling</li> <li>Performance optimizations</li> <li>Extended template library</li> <li>Enhanced monitoring</li> </ul>"},{"location":"api/#security","title":"Security","text":""},{"location":"api/#authentication_1","title":"Authentication","text":"<ul> <li>Azure AD integration</li> <li>Service principal support</li> <li>Token-based authentication</li> <li>Role-based access control</li> </ul>"},{"location":"api/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption at rest</li> <li>Secure connections</li> <li>Audit logging</li> <li>Privacy compliance</li> </ul>"},{"location":"api/#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE file for details.</p>"},{"location":"api/#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see our contributing guidelines for details on how to submit pull requests, report issues, and suggest improvements.</p>"},{"location":"api/cli_commands/","title":"CLI Commands","text":""},{"location":"api/cli_commands/#overview","title":"Overview","text":"<p>The Ingenious Fabric Accelerator CLI provides a comprehensive set of commands for managing Microsoft Fabric projects, from initialization to deployment.</p>"},{"location":"api/cli_commands/#global-options","title":"Global Options","text":"<p>All commands support these global options:</p> <pre><code>--help                Show help message\n--version             Show version information\n--verbose             Enable verbose output\n--quiet               Suppress output\n--config FILE         Use custom configuration file\n--log-level LEVEL     Set logging level (DEBUG, INFO, WARNING, ERROR)\n</code></pre>"},{"location":"api/cli_commands/#command-categories","title":"Command Categories","text":""},{"location":"api/cli_commands/#project-management","title":"Project Management","text":""},{"location":"api/cli_commands/#init","title":"<code>init</code>","text":"<p>Initialize a new Fabric project.</p> <pre><code>ingen_fab init [OPTIONS] PROJECT_NAME\n</code></pre> <p>Options: - <code>--template TEXT</code>: Template to use (default: basic) - <code>--workspace-id TEXT</code>: Fabric workspace ID - <code>--force</code>: Overwrite existing project - <code>--interactive</code>: Interactive setup mode</p> <p>Examples: <pre><code># Basic project initialization\ningen_fab init my_project\n\n# Initialize with specific template\ningen_fab init analytics_project --template data-warehouse\n\n# Interactive setup\ningen_fab init --interactive\n</code></pre></p>"},{"location":"api/cli_commands/#config","title":"<code>config</code>","text":"<p>Manage project configuration.</p> <pre><code>ingen_fab config [COMMAND] [OPTIONS]\n</code></pre> <p>Subcommands: - <code>show</code>: Display current configuration - <code>set KEY VALUE</code>: Set configuration value - <code>get KEY</code>: Get configuration value - <code>reset</code>: Reset to default configuration</p> <p>Examples: <pre><code># Show current configuration\ningen_fab config show\n\n# Set workspace ID\ningen_fab config set workspace_id abc-123-def\n\n# Get environment setting\ningen_fab config get environment\n</code></pre></p>"},{"location":"api/cli_commands/#ddl-management","title":"DDL Management","text":""},{"location":"api/cli_commands/#ddl-compile","title":"<code>ddl compile</code>","text":"<p>Compile DDL scripts from templates.</p> <pre><code>ingen_fab ddl compile [OPTIONS]\n</code></pre> <p>Options: - <code>--environment TEXT</code>: Target environment (default: development) - <code>--output-dir PATH</code>: Output directory for compiled scripts - <code>--template-dir PATH</code>: Template directory - <code>--variables FILE</code>: Variables file (JSON/YAML) - <code>--dry-run</code>: Show what would be compiled without executing</p> <p>Examples: <pre><code># Compile for development environment\ningen_fab ddl compile\n\n# Compile for production\ningen_fab ddl compile --environment production\n\n# Dry run to see what would be compiled\ningen_fab ddl compile --dry-run\n</code></pre></p>"},{"location":"api/cli_commands/#ddl-validate","title":"<code>ddl validate</code>","text":"<p>Validate DDL scripts and templates.</p> <pre><code>ingen_fab ddl validate [OPTIONS]\n</code></pre> <p>Options: - <code>--strict</code>: Enable strict validation - <code>--template-dir PATH</code>: Template directory to validate - <code>--output-format TEXT</code>: Output format (text, json, yaml)</p> <p>Examples: <pre><code># Validate all templates\ningen_fab ddl validate\n\n# Strict validation\ningen_fab ddl validate --strict\n</code></pre></p>"},{"location":"api/cli_commands/#deployment","title":"Deployment","text":""},{"location":"api/cli_commands/#deploy","title":"<code>deploy</code>","text":"<p>Deploy project to Fabric workspace.</p> <pre><code>ingen_fab deploy [OPTIONS]\n</code></pre> <p>Options: - <code>--environment TEXT</code>: Target environment - <code>--workspace-id TEXT</code>: Fabric workspace ID - <code>--dry-run</code>: Show what would be deployed - <code>--force</code>: Force deployment even if conflicts exist - <code>--parallel</code>: Enable parallel deployment</p> <p>Examples: <pre><code># Deploy to development environment\ningen_fab deploy --environment development\n\n# Deploy with dry run\ningen_fab deploy --dry-run\n\n# Force deployment\ningen_fab deploy --force\n</code></pre></p>"},{"location":"api/cli_commands/#undeploy","title":"<code>undeploy</code>","text":"<p>Remove deployed items from Fabric workspace.</p> <pre><code>ingen_fab undeploy [OPTIONS]\n</code></pre> <p>Options: - <code>--environment TEXT</code>: Target environment - <code>--workspace-id TEXT</code>: Fabric workspace ID - <code>--confirm</code>: Skip confirmation prompt - <code>--item-type TEXT</code>: Undeploy specific item types only</p> <p>Examples: <pre><code># Undeploy from development\ningen_fab undeploy --environment development\n\n# Undeploy only notebooks\ningen_fab undeploy --item-type notebook\n</code></pre></p>"},{"location":"api/cli_commands/#notebook-management","title":"Notebook Management","text":""},{"location":"api/cli_commands/#notebook-create","title":"<code>notebook create</code>","text":"<p>Create a new notebook from template.</p> <pre><code>ingen_fab notebook create [OPTIONS] NOTEBOOK_NAME\n</code></pre> <p>Options: - <code>--template TEXT</code>: Notebook template to use - <code>--language TEXT</code>: Programming language (python, scala, sql) - <code>--output-dir PATH</code>: Output directory</p> <p>Examples: <pre><code># Create Python notebook\ningen_fab notebook create data_processing --language python\n\n# Create from template\ningen_fab notebook create etl_pipeline --template data-pipeline\n</code></pre></p>"},{"location":"api/cli_commands/#notebook-validate","title":"<code>notebook validate</code>","text":"<p>Validate notebook syntax and structure.</p> <pre><code>ingen_fab notebook validate [OPTIONS] [NOTEBOOK_PATH]\n</code></pre> <p>Options: - <code>--strict</code>: Enable strict validation - <code>--check-dependencies</code>: Check for missing dependencies - <code>--output-format TEXT</code>: Output format for results</p> <p>Examples: <pre><code># Validate specific notebook\ningen_fab notebook validate notebooks/data_processing.py\n\n# Validate all notebooks\ningen_fab notebook validate --strict\n</code></pre></p>"},{"location":"api/cli_commands/#notebook-execute","title":"<code>notebook execute</code>","text":"<p>Execute notebook in Fabric environment.</p> <pre><code>ingen_fab notebook execute [OPTIONS] NOTEBOOK_PATH\n</code></pre> <p>Options: - <code>--environment TEXT</code>: Target environment - <code>--workspace-id TEXT</code>: Fabric workspace ID - <code>--parameters FILE</code>: Parameters file (JSON) - <code>--timeout INTEGER</code>: Execution timeout in seconds</p> <p>Examples: <pre><code># Execute notebook\ningen_fab notebook execute notebooks/data_processing.py\n\n# Execute with parameters\ningen_fab notebook execute notebooks/etl.py --parameters params.json\n</code></pre></p>"},{"location":"api/cli_commands/#workspace-management","title":"Workspace Management","text":""},{"location":"api/cli_commands/#workspace-list","title":"<code>workspace list</code>","text":"<p>List available Fabric workspaces.</p> <pre><code>ingen_fab workspace list [OPTIONS]\n</code></pre> <p>Options: - <code>--output-format TEXT</code>: Output format (table, json, yaml) - <code>--filter TEXT</code>: Filter workspaces by name</p> <p>Examples: <pre><code># List all workspaces\ningen_fab workspace list\n\n# List workspaces in JSON format\ningen_fab workspace list --output-format json\n</code></pre></p>"},{"location":"api/cli_commands/#workspace-info","title":"<code>workspace info</code>","text":"<p>Get detailed information about a workspace.</p> <pre><code>ingen_fab workspace info [OPTIONS] WORKSPACE_ID\n</code></pre> <p>Options: - <code>--output-format TEXT</code>: Output format - <code>--show-items</code>: Include workspace items</p> <p>Examples: <pre><code># Get workspace information\ningen_fab workspace info abc-123-def\n\n# Include workspace items\ningen_fab workspace info abc-123-def --show-items\n</code></pre></p>"},{"location":"api/cli_commands/#workspace-items","title":"<code>workspace items</code>","text":"<p>List items in a workspace.</p> <pre><code>ingen_fab workspace items [OPTIONS] WORKSPACE_ID\n</code></pre> <p>Options: - <code>--type TEXT</code>: Filter by item type - <code>--output-format TEXT</code>: Output format</p> <p>Examples: <pre><code># List all items\ningen_fab workspace items abc-123-def\n\n# List only notebooks\ningen_fab workspace items abc-123-def --type notebook\n</code></pre></p>"},{"location":"api/cli_commands/#testing","title":"Testing","text":""},{"location":"api/cli_commands/#test","title":"<code>test</code>","text":"<p>Run tests for the project.</p> <pre><code>ingen_fab test [OPTIONS]\n</code></pre> <p>Options: - <code>--environment TEXT</code>: Test environment - <code>--test-type TEXT</code>: Type of tests to run (unit, integration, all) - <code>--coverage</code>: Generate coverage report - <code>--parallel</code>: Run tests in parallel</p> <p>Examples: <pre><code># Run all tests\ningen_fab test\n\n# Run unit tests only\ningen_fab test --test-type unit\n\n# Run with coverage\ningen_fab test --coverage\n</code></pre></p>"},{"location":"api/cli_commands/#test-libraries","title":"<code>test libraries</code>","text":"<p>Test Python libraries locally.</p> <pre><code>ingen_fab test libraries [OPTIONS]\n</code></pre> <p>Options: - <code>--base-dir PATH</code>: Base directory for tests - <code>--verbose</code>: Verbose output - <code>--failfast</code>: Stop on first failure</p> <p>Examples: <pre><code># Test libraries in current directory\ningen_fab test libraries --base-dir .\n\n# Test with verbose output\ningen_fab test libraries --verbose\n</code></pre></p>"},{"location":"api/cli_commands/#utilities","title":"Utilities","text":""},{"location":"api/cli_commands/#clean","title":"<code>clean</code>","text":"<p>Clean generated files and caches.</p> <pre><code>ingen_fab clean [OPTIONS]\n</code></pre> <p>Options: - <code>--cache</code>: Clean cache files - <code>--output</code>: Clean output files - <code>--all</code>: Clean all generated files</p> <p>Examples: <pre><code># Clean all generated files\ningen_fab clean --all\n\n# Clean cache only\ningen_fab clean --cache\n</code></pre></p>"},{"location":"api/cli_commands/#version","title":"<code>version</code>","text":"<p>Show version information.</p> <pre><code>ingen_fab version [OPTIONS]\n</code></pre> <p>Options: - <code>--verbose</code>: Show detailed version information - <code>--check-updates</code>: Check for available updates</p> <p>Examples: <pre><code># Show version\ningen_fab version\n\n# Check for updates\ningen_fab version --check-updates\n</code></pre></p>"},{"location":"api/cli_commands/#configuration","title":"Configuration","text":""},{"location":"api/cli_commands/#configuration-file","title":"Configuration File","text":"<p>The CLI looks for configuration in these locations:</p> <ol> <li><code>./ingen_fab.yaml</code> (project-specific)</li> <li><code>~/.ingen_fab/config.yaml</code> (user-specific)</li> <li><code>/etc/ingen_fab/config.yaml</code> (system-wide)</li> </ol>"},{"location":"api/cli_commands/#environment-variables","title":"Environment Variables","text":"<pre><code># Core settings\nexport INGEN_FAB_ENVIRONMENT=production\nexport FABRIC_WORKSPACE_ID=your-workspace-id\n\n# Authentication\nexport AZURE_CLIENT_ID=your-client-id\nexport AZURE_CLIENT_SECRET=your-client-secret\nexport AZURE_TENANT_ID=your-tenant-id\n\n# Logging\nexport INGEN_FAB_LOG_LEVEL=INFO\nexport INGEN_FAB_LOG_FILE=/path/to/log/file\n</code></pre>"},{"location":"api/cli_commands/#configuration-schema","title":"Configuration Schema","text":"<pre><code># ingen_fab.yaml\nenvironment: development\nworkspace_id: abc-123-def\n\nlogging:\n  level: INFO\n  file: logs/cli.log\n\ntemplates:\n  directory: templates/\n  variables:\n    database_name: my_database\n    schema_name: dbo\n\ndeployment:\n  parallel: true\n  timeout: 300\n  retry_count: 3\n</code></pre>"},{"location":"api/cli_commands/#exit-codes","title":"Exit Codes","text":"<p>The CLI uses standard exit codes:</p> <ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Invalid arguments</li> <li><code>3</code>: Configuration error</li> <li><code>4</code>: Authentication error</li> <li><code>5</code>: Network error</li> <li><code>6</code>: Permission error</li> </ul>"},{"location":"api/cli_commands/#error-handling","title":"Error Handling","text":""},{"location":"api/cli_commands/#common-errors","title":"Common Errors","text":""},{"location":"api/cli_commands/#authentication-errors","title":"Authentication Errors","text":"<pre><code>Error: Authentication failed. Please run 'az login' to authenticate.\n</code></pre> <p>Solution: Authenticate with Azure CLI</p>"},{"location":"api/cli_commands/#workspace-not-found","title":"Workspace Not Found","text":"<pre><code>Error: Workspace 'abc-123-def' not found or not accessible.\n</code></pre> <p>Solution: Verify workspace ID and permissions</p>"},{"location":"api/cli_commands/#template-not-found","title":"Template Not Found","text":"<pre><code>Error: Template 'custom-template' not found in template directory.\n</code></pre> <p>Solution: Check template name and directory</p>"},{"location":"api/cli_commands/#debugging","title":"Debugging","text":"<pre><code># Enable debug logging\ningen_fab --log-level DEBUG command\n\n# Verbose output\ningen_fab --verbose command\n\n# Check log file\ntail -f ~/.ingen_fab/logs/cli.log\n</code></pre>"},{"location":"api/cli_commands/#advanced-usage","title":"Advanced Usage","text":""},{"location":"api/cli_commands/#scripting","title":"Scripting","text":"<pre><code>#!/bin/bash\n# deployment_script.sh\n\n# Set environment\nexport INGEN_FAB_ENVIRONMENT=production\n\n# Compile DDL scripts\ningen_fab ddl compile --environment production\n\n# Deploy to Fabric\ningen_fab deploy --environment production --force\n\n# Run tests\ningen_fab test --environment production\n</code></pre>"},{"location":"api/cli_commands/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># Azure DevOps Pipeline\nsteps:\n- task: UsePythonVersion@0\n  inputs:\n    versionSpec: '3.12'\n\n- script: |\n    pip install insight-ingenious-for-fabric\n    ingen_fab deploy --environment production\n  displayName: 'Deploy to Fabric'\n</code></pre>"},{"location":"api/cli_commands/#custom-commands","title":"Custom Commands","text":"<pre><code># custom_commands.py\nimport typer\nfrom ingen_fab.cli import app\n\n@app.command()\ndef custom_command(name: str):\n    \"\"\"Custom command implementation\"\"\"\n    typer.echo(f\"Hello {name}!\")\n\nif __name__ == \"__main__\":\n    app()\n</code></pre>"},{"location":"api/cli_commands/#examples","title":"Examples","text":""},{"location":"api/cli_commands/#complete-workflow","title":"Complete Workflow","text":"<pre><code># Initialize new project\ningen_fab init analytics_project --template data-warehouse\n\n# Navigate to project\ncd analytics_project\n\n# Configure workspace\ningen_fab config set workspace_id abc-123-def\n\n# Compile DDL scripts\ningen_fab ddl compile --environment development\n\n# Validate notebooks\ningen_fab notebook validate\n\n# Deploy to development\ningen_fab deploy --environment development\n\n# Run tests\ningen_fab test --environment development\n\n# Deploy to production\ningen_fab deploy --environment production\n</code></pre>"},{"location":"api/cli_commands/#automation-script","title":"Automation Script","text":"<pre><code>#!/bin/bash\n# automated_deployment.sh\n\nset -e  # Exit on error\n\necho \"Starting deployment...\"\n\n# Validate configuration\ningen_fab config show\n\n# Compile and validate\ningen_fab ddl compile --environment $ENVIRONMENT\ningen_fab ddl validate --strict\n\n# Deploy\ningen_fab deploy --environment $ENVIRONMENT --force\n\n# Test deployment\ningen_fab test --environment $ENVIRONMENT\n\necho \"Deployment completed successfully!\"\n</code></pre>"},{"location":"api/cli_commands/#best-practices","title":"Best Practices","text":""},{"location":"api/cli_commands/#command-organization","title":"Command Organization","text":"<ol> <li>Use consistent naming: Follow verb-noun pattern</li> <li>Group related commands: Use subcommands for related operations</li> <li>Provide help text: Include descriptions for all commands and options</li> <li>Handle errors gracefully: Provide meaningful error messages</li> </ol>"},{"location":"api/cli_commands/#configuration-management","title":"Configuration Management","text":"<ol> <li>Use environment-specific configs: Separate configs for dev/prod</li> <li>Validate configuration: Check configuration before execution</li> <li>Use defaults: Provide sensible defaults for common options</li> <li>Document configuration: Include examples and explanations</li> </ol>"},{"location":"api/cli_commands/#error-handling_1","title":"Error Handling","text":"<ol> <li>Provide clear error messages: Explain what went wrong and how to fix it</li> <li>Use appropriate exit codes: Follow standard conventions</li> <li>Log errors: Write detailed error information to log files</li> <li>Offer recovery options: Suggest next steps when possible</li> </ol>"},{"location":"api/cli_commands/#support","title":"Support","text":"<p>For additional help:</p> <ul> <li>Use <code>--help</code> with any command for detailed information</li> <li>Check the log files for detailed error information</li> <li>Refer to the User Guide for comprehensive documentation</li> <li>Visit the GitHub repository for issues and discussions</li> </ul>"},{"location":"api/python_apis/","title":"Python APIs","text":""},{"location":"api/python_apis/#overview","title":"Overview","text":"<p>The Ingenious Fabric Accelerator provides comprehensive Python APIs for programmatic access to all functionality. These APIs enable you to build custom solutions, integrate with existing workflows, and automate complex operations.</p>"},{"location":"api/python_apis/#core-modules","title":"Core Modules","text":""},{"location":"api/python_apis/#ingen_fabpython_libs","title":"<code>ingen_fab.python_libs</code>","text":"<p>The core Python libraries module provides environment-agnostic utilities.</p>"},{"location":"api/python_apis/#get_notebook_utils","title":"<code>get_notebook_utils()</code>","text":"<p>Returns the appropriate notebook utilities for the current environment.</p> <pre><code>from ingen_fab.python_libs import get_notebook_utils\n\n# Get environment-appropriate utilities\nutils = get_notebook_utils()\n\n# Execute SQL query\nresult = utils.execute_query(\"SELECT * FROM my_table\")\n\n# Read data\ndata = utils.read_table(\"schema.table\")\n</code></pre>"},{"location":"api/python_apis/#notebookutils-interface","title":"<code>NotebookUtils</code> Interface","text":"<p>Base interface for notebook utilities.</p> <pre><code>class NotebookUtils:\n    def execute_query(self, query: str) -&gt; Any:\n        \"\"\"Execute SQL query\"\"\"\n        pass\n\n    def read_table(self, table_name: str) -&gt; pd.DataFrame:\n        \"\"\"Read table data\"\"\"\n        pass\n\n    def write_table(self, table_name: str, data: pd.DataFrame) -&gt; None:\n        \"\"\"Write table data\"\"\"\n        pass\n\n    def get_connection(self) -&gt; Any:\n        \"\"\"Get database connection\"\"\"\n        pass\n</code></pre>"},{"location":"api/python_apis/#ingen_fabpython_libspython","title":"<code>ingen_fab.python_libs.python</code>","text":"<p>Python-specific implementations for local development.</p>"},{"location":"api/python_apis/#ddlutils","title":"<code>DDLUtils</code>","text":"<p>Utilities for Data Definition Language operations.</p> <pre><code>from ingen_fab.python_libs.python.ddl_utils import DDLUtils\n\nddl = DDLUtils()\n\n# Create table\nddl.create_table(\n    schema_name=\"analytics\",\n    table_name=\"user_metrics\",\n    columns=[\n        {\"name\": \"user_id\", \"type\": \"BIGINT\", \"nullable\": False},\n        {\"name\": \"metric_date\", \"type\": \"DATE\", \"nullable\": False}\n    ]\n)\n\n# Check if table exists\nexists = ddl.table_exists(\"analytics\", \"user_metrics\")\n\n# Drop table\nddl.drop_table(\"analytics\", \"user_metrics\")\n</code></pre>"},{"location":"api/python_apis/#lakehouseutils","title":"<code>LakehouseUtils</code>","text":"<p>Utilities for Lakehouse operations.</p> <pre><code>from ingen_fab.python_libs.python.lakehouse_utils import LakehouseUtils\n\nlakehouse = LakehouseUtils()\n\n# Read parquet file\ndf = lakehouse.read_parquet(\"path/to/file.parquet\")\n\n# Write parquet file\nlakehouse.write_parquet(df, \"path/to/output.parquet\")\n\n# List files\nfiles = lakehouse.list_files(\"path/to/directory\")\n</code></pre>"},{"location":"api/python_apis/#warehouseutils","title":"<code>WarehouseUtils</code>","text":"<p>Utilities for Warehouse operations.</p> <pre><code>from ingen_fab.python_libs.python.warehouse_utils import WarehouseUtils\n\nwarehouse = WarehouseUtils()\n\n# Execute SQL\nresult = warehouse.execute_sql(\"SELECT COUNT(*) FROM users\")\n\n# Bulk insert\nwarehouse.bulk_insert(\"target_table\", data)\n\n# Create view\nwarehouse.create_view(\"user_summary\", \"SELECT * FROM users WHERE active = 1\")\n</code></pre>"},{"location":"api/python_apis/#ingen_fabpython_libspyspark","title":"<code>ingen_fab.python_libs.pyspark</code>","text":"<p>PySpark-specific implementations for Fabric runtime.</p>"},{"location":"api/python_apis/#ddlutils-pyspark","title":"<code>DDLUtils</code> (PySpark)","text":"<p>PySpark implementation of DDL utilities.</p> <pre><code>from ingen_fab.python_libs.pyspark.ddl_utils import DDLUtils\n\nddl = DDLUtils()\n\n# Create Delta table\nddl.create_delta_table(\n    schema_name=\"analytics\",\n    table_name=\"events\",\n    columns=[\n        {\"name\": \"event_id\", \"type\": \"STRING\", \"nullable\": False},\n        {\"name\": \"timestamp\", \"type\": \"TIMESTAMP\", \"nullable\": False}\n    ]\n)\n\n# Optimize table\nddl.optimize_table(\"analytics.events\")\n</code></pre>"},{"location":"api/python_apis/#lakehouseutils-pyspark","title":"<code>LakehouseUtils</code> (PySpark)","text":"<p>PySpark implementation for Lakehouse operations.</p> <pre><code>from ingen_fab.python_libs.pyspark.lakehouse_utils import LakehouseUtils\n\nlakehouse = LakehouseUtils()\n\n# Read Delta table\ndf = lakehouse.read_delta_table(\"analytics.events\")\n\n# Write Delta table\nlakehouse.write_delta_table(df, \"analytics.processed_events\")\n\n# Merge data\nlakehouse.merge_delta_table(\n    target_table=\"analytics.users\",\n    source_df=new_users_df,\n    merge_condition=\"target.user_id = source.user_id\"\n)\n</code></pre>"},{"location":"api/python_apis/#ingen_fabddl_scripts","title":"<code>ingen_fab.ddl_scripts</code>","text":"<p>DDL script generation and management.</p>"},{"location":"api/python_apis/#ddlscriptgenerator","title":"<code>DDLScriptGenerator</code>","text":"<p>Generates DDL scripts from templates.</p> <pre><code>from ingen_fab.ddl_scripts import DDLScriptGenerator\n\ngenerator = DDLScriptGenerator()\n\n# Set template directory\ngenerator.set_template_directory(\"templates/\")\n\n# Generate scripts for environment\nscripts = generator.generate_scripts(\"production\")\n\n# Generate specific script\nscript = generator.generate_script(\"create_tables.sql.jinja\", variables={\n    \"schema_name\": \"analytics\",\n    \"environment\": \"production\"\n})\n</code></pre>"},{"location":"api/python_apis/#notebookgenerator","title":"<code>NotebookGenerator</code>","text":"<p>Generates notebooks from templates.</p> <pre><code>from ingen_fab.ddl_scripts.notebook_generator import NotebookGenerator\n\ngenerator = NotebookGenerator()\n\n# Generate notebook\nnotebook = generator.generate_notebook(\n    template_path=\"templates/data_processing.py.jinja\",\n    variables={\n        \"source_table\": \"raw_data\",\n        \"target_table\": \"processed_data\"\n    }\n)\n\n# Save notebook\ngenerator.save_notebook(notebook, \"output/data_processing.ipynb\")\n</code></pre>"},{"location":"api/python_apis/#ingen_fabfabric_api","title":"<code>ingen_fab.fabric_api</code>","text":"<p>Microsoft Fabric API integration.</p>"},{"location":"api/python_apis/#fabricclient","title":"<code>FabricClient</code>","text":"<p>Main client for Fabric operations.</p> <pre><code>from ingen_fab.fabric_api import FabricClient\nfrom azure.identity import DefaultAzureCredential\n\n# Initialize client\ncredential = DefaultAzureCredential()\nclient = FabricClient(credential)\n\n# List workspaces\nworkspaces = client.list_workspaces()\n\n# Get workspace\nworkspace = client.get_workspace(\"workspace-id\")\n\n# List items in workspace\nitems = client.list_workspace_items(\"workspace-id\")\n</code></pre>"},{"location":"api/python_apis/#fabricworkspace","title":"<code>FabricWorkspace</code>","text":"<p>Workspace-specific operations.</p> <pre><code>from ingen_fab.fabric_api import FabricWorkspace\n\nworkspace = FabricWorkspace(\"workspace-id\")\n\n# Create notebook\nnotebook = workspace.create_notebook(\"My Notebook\", content)\n\n# Execute notebook\nresult = workspace.execute_notebook(notebook.id)\n\n# Create lakehouse\nlakehouse = workspace.create_lakehouse(\"My Lakehouse\")\n</code></pre>"},{"location":"api/python_apis/#ingen_fabnotebook_utils","title":"<code>ingen_fab.notebook_utils</code>","text":"<p>Notebook utilities and abstractions.</p>"},{"location":"api/python_apis/#simplenotebook","title":"<code>SimpleNotebook</code>","text":"<p>Basic notebook operations.</p> <pre><code>from ingen_fab.notebook_utils import SimpleNotebook\n\nnotebook = SimpleNotebook()\n\n# Add code cell\nnotebook.add_code_cell(\"print('Hello, World!')\")\n\n# Add markdown cell\nnotebook.add_markdown_cell(\"# My Analysis\")\n\n# Execute notebook\nresults = notebook.execute()\n\n# Save notebook\nnotebook.save(\"output.ipynb\")\n</code></pre>"},{"location":"api/python_apis/#fabricclinotebook","title":"<code>FabricCliNotebook</code>","text":"<p>Fabric-specific notebook operations.</p> <pre><code>from ingen_fab.notebook_utils import FabricCliNotebook\n\nnotebook = FabricCliNotebook()\n\n# Set Fabric context\nnotebook.set_workspace(\"workspace-id\")\n\n# Execute with Fabric APIs\nresult = notebook.execute_with_fabric_apis(code)\n</code></pre>"},{"location":"api/python_apis/#ingen_fabconfig_utils","title":"<code>ingen_fab.config_utils</code>","text":"<p>Configuration management utilities.</p>"},{"location":"api/python_apis/#variablelib","title":"<code>VariableLib</code>","text":"<p>Variable library management.</p> <pre><code>from ingen_fab.config_utils import VariableLib\n\nvar_lib = VariableLib()\n\n# Get variable\nvalue = var_lib.get_variable(\"database_name\")\n\n# Set variable\nvar_lib.set_variable(\"connection_string\", \"server=localhost\")\n\n# Load variables from file\nvar_lib.load_variables(\"config/variables.json\")\n</code></pre>"},{"location":"api/python_apis/#configmanager","title":"<code>ConfigManager</code>","text":"<p>Configuration management.</p> <pre><code>from ingen_fab.config_utils import ConfigManager\n\nconfig = ConfigManager()\n\n# Load configuration\nconfig.load_config(\"ingen_fab.yaml\")\n\n# Get configuration value\nworkspace_id = config.get(\"workspace_id\")\n\n# Set configuration value\nconfig.set(\"environment\", \"production\")\n</code></pre>"},{"location":"api/python_apis/#error-handling","title":"Error Handling","text":""},{"location":"api/python_apis/#exception-classes","title":"Exception Classes","text":"<pre><code>from ingen_fab.exceptions import (\n    IngenFabError,\n    NotebookUtilsError,\n    DDLScriptError,\n    FabricApiError\n)\n\n# Base exception\nclass IngenFabError(Exception):\n    \"\"\"Base exception for all Ingenious Fabric errors\"\"\"\n    pass\n\n# Specific exceptions\nclass NotebookUtilsError(IngenFabError):\n    \"\"\"Notebook utilities error\"\"\"\n    pass\n\nclass DDLScriptError(IngenFabError):\n    \"\"\"DDL script generation error\"\"\"\n    pass\n\nclass FabricApiError(IngenFabError):\n    \"\"\"Fabric API error\"\"\"\n    pass\n</code></pre>"},{"location":"api/python_apis/#error-handling-patterns","title":"Error Handling Patterns","text":"<pre><code>try:\n    utils = get_notebook_utils()\n    result = utils.execute_query(sql)\nexcept NotebookUtilsError as e:\n    logger.error(f\"Notebook operation failed: {e}\")\n    # Handle error appropriately\nexcept FabricApiError as e:\n    logger.error(f\"Fabric API error: {e}\")\n    # Handle Fabric-specific errors\nexcept IngenFabError as e:\n    logger.error(f\"General error: {e}\")\n    # Handle other errors\n</code></pre>"},{"location":"api/python_apis/#async-support","title":"Async Support","text":""},{"location":"api/python_apis/#async-operations","title":"Async Operations","text":"<pre><code>import asyncio\nfrom ingen_fab.fabric_api import AsyncFabricClient\n\nasync def main():\n    client = AsyncFabricClient()\n\n    # Async operations\n    workspaces = await client.list_workspaces()\n\n    # Concurrent operations\n    tasks = [\n        client.get_workspace(ws_id) \n        for ws_id in workspace_ids\n    ]\n    results = await asyncio.gather(*tasks)\n\n# Run async code\nasyncio.run(main())\n</code></pre>"},{"location":"api/python_apis/#type-hints","title":"Type Hints","text":""},{"location":"api/python_apis/#comprehensive-type-support","title":"Comprehensive Type Support","text":"<pre><code>from typing import List, Dict, Any, Optional, Union\nfrom pandas import DataFrame\nfrom pyspark.sql import DataFrame as SparkDataFrame\n\ndef process_data(\n    data: Union[DataFrame, SparkDataFrame],\n    config: Dict[str, Any],\n    output_path: Optional[str] = None\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Process data with full type hints\"\"\"\n    pass\n</code></pre>"},{"location":"api/python_apis/#testing","title":"Testing","text":""},{"location":"api/python_apis/#unit-testing","title":"Unit Testing","text":"<pre><code>import unittest\nfrom unittest.mock import Mock, patch\nfrom ingen_fab.python_libs import get_notebook_utils\n\nclass TestNotebookUtils(unittest.TestCase):\n    def setUp(self):\n        self.utils = get_notebook_utils()\n\n    @patch('ingen_fab.python_libs.get_connection')\n    def test_execute_query(self, mock_connection):\n        mock_connection.return_value = Mock()\n        result = self.utils.execute_query(\"SELECT 1\")\n        self.assertIsNotNone(result)\n\n    def test_table_operations(self):\n        # Test table creation\n        self.utils.create_table(\"test_schema\", \"test_table\", columns)\n\n        # Test table existence\n        exists = self.utils.table_exists(\"test_schema\", \"test_table\")\n        self.assertTrue(exists)\n</code></pre>"},{"location":"api/python_apis/#integration-testing","title":"Integration Testing","text":"<pre><code>import pytest\nfrom ingen_fab.fabric_api import FabricClient\n\n@pytest.mark.integration\nasync def test_fabric_integration():\n    client = FabricClient()\n    workspaces = await client.list_workspaces()\n    assert len(workspaces) &gt; 0\n\n    # Test workspace operations\n    workspace = await client.get_workspace(workspaces[0].id)\n    assert workspace is not None\n</code></pre>"},{"location":"api/python_apis/#mocking","title":"Mocking","text":"<pre><code>from unittest.mock import Mock, patch\nimport pandas as pd\n\n# Mock external dependencies\nwith patch('ingen_fab.python_libs.get_connection') as mock_conn:\n    mock_conn.return_value = Mock()\n    mock_conn.return_value.execute.return_value = pd.DataFrame({'col1': [1, 2, 3]})\n\n    # Test code with mocked dependencies\n    result = utils.execute_query(\"SELECT * FROM table\")\n    assert isinstance(result, pd.DataFrame)\n</code></pre>"},{"location":"api/python_apis/#performance-optimization","title":"Performance Optimization","text":""},{"location":"api/python_apis/#connection-pooling","title":"Connection Pooling","text":"<pre><code>from ingen_fab.python_libs import ConnectionPool\n\n# Configure connection pool\npool = ConnectionPool(\n    max_connections=10,\n    timeout=30,\n    retry_count=3\n)\n\n# Use pooled connections\nwith pool.get_connection() as conn:\n    result = conn.execute(query)\n</code></pre>"},{"location":"api/python_apis/#caching","title":"Caching","text":"<pre><code>from functools import lru_cache\nfrom ingen_fab.python_libs import cache\n\n# Method-level caching\n@lru_cache(maxsize=128)\ndef expensive_operation(param):\n    return compute_result(param)\n\n# Class-level caching\nclass CachedUtils:\n    @cache(ttl=300)  # Cache for 5 minutes\n    def get_table_schema(self, table_name):\n        return self.fetch_schema(table_name)\n</code></pre>"},{"location":"api/python_apis/#batch-operations","title":"Batch Operations","text":"<pre><code>from ingen_fab.python_libs import BatchProcessor\n\nprocessor = BatchProcessor(batch_size=1000)\n\n# Process large datasets in batches\nfor batch in processor.process(large_dataset):\n    results = utils.process_batch(batch)\n</code></pre>"},{"location":"api/python_apis/#advanced-features","title":"Advanced Features","text":""},{"location":"api/python_apis/#custom-implementations","title":"Custom Implementations","text":"<pre><code>from ingen_fab.python_libs import NotebookUtils\n\nclass CustomNotebookUtils(NotebookUtils):\n    def __init__(self, custom_config):\n        self.config = custom_config\n\n    def execute_query(self, query: str) -&gt; Any:\n        # Custom implementation\n        return self.custom_execute(query)\n\n    def custom_operation(self, data):\n        \"\"\"Custom business logic\"\"\"\n        return self.process_custom_data(data)\n</code></pre>"},{"location":"api/python_apis/#plugin-system","title":"Plugin System","text":"<pre><code>from ingen_fab.plugins import register_plugin\n\n@register_plugin('my_plugin')\nclass MyPlugin:\n    def initialize(self):\n        pass\n\n    def process(self, data):\n        return transformed_data\n</code></pre>"},{"location":"api/python_apis/#event-hooks","title":"Event Hooks","text":"<pre><code>from ingen_fab.events import on_event\n\n@on_event('before_query_execute')\ndef log_query(query):\n    logger.info(f\"Executing query: {query}\")\n\n@on_event('after_query_execute')\ndef log_result(result):\n    logger.info(f\"Query returned {len(result)} rows\")\n</code></pre>"},{"location":"api/python_apis/#configuration","title":"Configuration","text":""},{"location":"api/python_apis/#environment-specific-settings","title":"Environment-Specific Settings","text":"<pre><code>from ingen_fab.config_utils import get_config\n\nconfig = get_config()\n\n# Environment-specific settings\nif config.environment == 'production':\n    connection_string = config.prod_connection_string\nelse:\n    connection_string = config.dev_connection_string\n</code></pre>"},{"location":"api/python_apis/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>from ingen_fab.config_utils import ConfigManager\n\nconfig = ConfigManager()\n\n# Load configuration from multiple sources\nconfig.load_from_file('config.yaml')\nconfig.load_from_env()\nconfig.load_from_args(sys.argv)\n\n# Get merged configuration\nfinal_config = config.get_merged_config()\n</code></pre>"},{"location":"api/python_apis/#examples","title":"Examples","text":""},{"location":"api/python_apis/#complete-data-processing-pipeline","title":"Complete Data Processing Pipeline","text":"<pre><code>from ingen_fab.python_libs import get_notebook_utils\nfrom ingen_fab.python_libs.python import DDLUtils, LakehouseUtils\nfrom ingen_fab.fabric_api import FabricClient\n\n# Initialize components\nutils = get_notebook_utils()\nddl = DDLUtils()\nlakehouse = LakehouseUtils()\nfabric_client = FabricClient()\n\n# Create target table\nddl.create_table(\n    schema_name=\"analytics\",\n    table_name=\"processed_data\",\n    columns=[\n        {\"name\": \"id\", \"type\": \"BIGINT\", \"nullable\": False},\n        {\"name\": \"processed_date\", \"type\": \"TIMESTAMP\", \"nullable\": False},\n        {\"name\": \"value\", \"type\": \"DECIMAL(10,2)\", \"nullable\": True}\n    ]\n)\n\n# Read source data\nsource_data = lakehouse.read_parquet(\"input/raw_data.parquet\")\n\n# Process data\nprocessed_data = utils.execute_query(\"\"\"\n    SELECT \n        id,\n        CURRENT_TIMESTAMP() as processed_date,\n        value * 1.1 as value\n    FROM source_data\n    WHERE value &gt; 0\n\"\"\")\n\n# Write results\nlakehouse.write_parquet(processed_data, \"output/processed_data.parquet\")\n\n# Deploy to Fabric\nnotebook = fabric_client.create_notebook(\"Data Processing\", notebook_content)\nfabric_client.execute_notebook(notebook.id)\n\nprint(\"Pipeline completed successfully!\")\n</code></pre>"},{"location":"api/python_apis/#custom-utility-class","title":"Custom Utility Class","text":"<pre><code>from ingen_fab.python_libs import get_notebook_utils\nfrom typing import Dict, Any, List\n\nclass DataAnalyzer:\n    def __init__(self):\n        self.utils = get_notebook_utils()\n\n    def analyze_table(self, table_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Comprehensive table analysis\"\"\"\n\n        # Get basic stats\n        stats = self.utils.execute_query(f\"\"\"\n            SELECT \n                COUNT(*) as row_count,\n                COUNT(DISTINCT *) as distinct_count\n            FROM {table_name}\n        \"\"\")\n\n        # Get column info\n        columns = self.utils.execute_query(f\"\"\"\n            DESCRIBE {table_name}\n        \"\"\")\n\n        # Get data quality metrics\n        quality_metrics = self._calculate_quality_metrics(table_name)\n\n        return {\n            'table_name': table_name,\n            'statistics': stats,\n            'columns': columns,\n            'quality_metrics': quality_metrics\n        }\n\n    def _calculate_quality_metrics(self, table_name: str) -&gt; Dict[str, float]:\n        \"\"\"Calculate data quality metrics\"\"\"\n        # Custom data quality logic\n        pass\n\n    def generate_report(self, tables: List[str]) -&gt; str:\n        \"\"\"Generate analysis report for multiple tables\"\"\"\n        analyses = [self.analyze_table(table) for table in tables]\n        return self._format_report(analyses)\n</code></pre>"},{"location":"api/python_apis/#best-practices","title":"Best Practices","text":""},{"location":"api/python_apis/#error-handling_1","title":"Error Handling","text":"<pre><code>import logging\nfrom contextlib import contextmanager\n\nlogger = logging.getLogger(__name__)\n\n@contextmanager\ndef error_handler(operation_name: str):\n    \"\"\"Context manager for consistent error handling\"\"\"\n    try:\n        logger.info(f\"Starting {operation_name}\")\n        yield\n        logger.info(f\"Completed {operation_name}\")\n    except Exception as e:\n        logger.error(f\"Failed {operation_name}: {e}\")\n        raise\n</code></pre>"},{"location":"api/python_apis/#resource-management","title":"Resource Management","text":"<pre><code>from contextlib import contextmanager\n\n@contextmanager\ndef managed_connection():\n    \"\"\"Manage database connections properly\"\"\"\n    conn = None\n    try:\n        conn = get_connection()\n        yield conn\n    finally:\n        if conn:\n            conn.close()\n</code></pre>"},{"location":"api/python_apis/#logging","title":"Logging","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nlogger = logging.getLogger(__name__)\n\n# Use throughout your code\nlogger.info(\"Processing started\")\nlogger.debug(\"Debug information\")\nlogger.error(\"Error occurred\", exc_info=True)\n</code></pre>"},{"location":"api/python_apis/#api-reference-summary","title":"API Reference Summary","text":""},{"location":"api/python_apis/#core-classes","title":"Core Classes","text":"<ul> <li><code>NotebookUtils</code>: Base utilities interface</li> <li><code>DDLUtils</code>: Data Definition Language operations</li> <li><code>LakehouseUtils</code>: Lakehouse operations</li> <li><code>WarehouseUtils</code>: Warehouse operations</li> <li><code>FabricClient</code>: Fabric API client</li> <li><code>DDLScriptGenerator</code>: DDL script generation</li> <li><code>VariableLib</code>: Variable management</li> </ul>"},{"location":"api/python_apis/#key-functions","title":"Key Functions","text":"<ul> <li><code>get_notebook_utils()</code>: Get environment-appropriate utilities</li> <li><code>get_config()</code>: Get configuration settings</li> <li><code>register_plugin()</code>: Register custom plugins</li> </ul>"},{"location":"api/python_apis/#exception-classes_1","title":"Exception Classes","text":"<ul> <li><code>IngenFabError</code>: Base exception</li> <li><code>NotebookUtilsError</code>: Notebook utilities errors</li> <li><code>DDLScriptError</code>: DDL script errors</li> <li><code>FabricApiError</code>: Fabric API errors</li> </ul> <p>For complete API documentation with all methods and parameters, refer to the docstrings in the source code or generate API documentation using tools like Sphinx.</p>"},{"location":"developer_guide/","title":"Developer Guide","text":"<p>Welcome to the Developer Guide for the Ingenious Fabric Accelerator! This section is designed for developers who want to understand the architecture, extend functionality, or contribute to the project.</p>"},{"location":"developer_guide/#architecture-overview","title":"Architecture Overview","text":"<p>The Ingenious Fabric Accelerator is built with a modular architecture that separates concerns and enables extensibility:</p> <pre><code>graph TD\n    A[CLI Interface] --&gt; B[Command Modules]\n    B --&gt; C[Core Libraries]\n    C --&gt; D[Python Libraries]\n    C --&gt; E[PySpark Libraries]\n    C --&gt; F[Template Engine]\n    D --&gt; G[Fabric Runtime]\n    E --&gt; G\n    F --&gt; H[Generated Notebooks]\n    H --&gt; G</code></pre>"},{"location":"developer_guide/#core-components","title":"Core Components","text":""},{"location":"developer_guide/#python-libraries","title":"Python Libraries","text":"<p>Reusable Python and PySpark libraries that provide common functionality for Fabric workspaces.</p>"},{"location":"developer_guide/#ddl-scripts","title":"DDL Scripts","text":"<p>Template system for generating DDL notebooks from SQL and Python scripts.</p>"},{"location":"developer_guide/#notebook-utils","title":"Notebook Utils","text":"<p>Environment-agnostic utilities that work in both local development and Fabric runtime.</p>"},{"location":"developer_guide/#sql-templates","title":"SQL Templates","text":"<p>Jinja-based SQL template system supporting multiple database dialects.</p>"},{"location":"developer_guide/#development-setup","title":"Development Setup","text":""},{"location":"developer_guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+</li> <li>Git</li> <li>IDE with Python support (VS Code, PyCharm, etc.)</li> <li>Docker (optional, for containerized development)</li> </ul>"},{"location":"developer_guide/#clone-and-setup","title":"Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/your-org/ingen_fab.git\ncd ingen_fab\n\n# Set up development environment\nuv sync --all-extras\n\n# Install pre-commit hooks\npre-commit install\n\n# Verify installation\ningen_fab --help\n</code></pre>"},{"location":"developer_guide/#development-dependencies","title":"Development Dependencies","text":"<p>The project uses several development tools:</p> <ul> <li>Testing: pytest, pytest-cov, pytest-asyncio</li> <li>Linting: ruff, vulture</li> <li>Type checking: mypy (optional)</li> <li>Documentation: mkdocs, mkdocs-material</li> <li>Pre-commit: pre-commit hooks for code quality</li> </ul>"},{"location":"developer_guide/#container-development-setup","title":"Container Development Setup","text":"<p>For a consistent development environment with Apache Spark and SQL Server, use the provided dev container:</p> <ol> <li> <p>Open in Dev Container: Use VS Code's \"Dev Containers\" extension and select \"Reopen in Container\"</p> </li> <li> <p>Install PowerShell:    <pre><code>source ./scripts/dev_container_scripts/spark_minimal/pwsh_install.sh\n</code></pre></p> </li> <li> <p>Start PowerShell and install development tools:    <pre><code>pwsh\n</code></pre> <pre><code>./scripts/dev_container_scripts/spark_minimal/dev_tools.ps1\n</code></pre></p> </li> <li> <p>Restart PowerShell session:    <pre><code>. $PROFILE\n</code></pre></p> </li> <li> <p>Install SQL Server (optional):    <pre><code>bash ./scripts/dev_container_scripts/spark_minimal/sql_install_4_linux.sh\nbash /opt/mssql/bin/mssql-conf setup\n</code></pre></p> </li> </ol> <p>Note: You'll need to provide an SA password and select \"Enterprise (2)\" and \"English\" when prompted.</p> <ol> <li>Start SQL Server:    <pre><code>/opt/mssql/bin/sqlservr\n</code></pre></li> </ol> <p>The container provides a minimal setup with Apache Spark, SQL Server, and PowerShell support for local development.</p>"},{"location":"developer_guide/#project-structure","title":"Project Structure","text":"<pre><code>ingen_fab/\n\u251c\u2500\u2500 cli_utils/              # CLI command implementations\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 deploy_commands.py  # Deployment commands\n\u2502   \u251c\u2500\u2500 init_commands.py    # Project initialization\n\u2502   \u251c\u2500\u2500 notebook_commands.py # Notebook management\n\u2502   \u2514\u2500\u2500 workspace_commands.py # Workspace operations\n\u251c\u2500\u2500 ddl_scripts/            # DDL template system\n\u2502   \u251c\u2500\u2500 _templates/         # Jinja templates\n\u2502   \u251c\u2500\u2500 notebook_generator.py # Template processor\n\u2502   \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 notebook_utils/         # Notebook utilities\n\u2502   \u251c\u2500\u2500 fabric_cli_notebook.py\n\u2502   \u251c\u2500\u2500 simple_notebook.py\n\u2502   \u2514\u2500\u2500 templates/\n\u251c\u2500\u2500 python_libs/            # Core Python libraries\n\u2502   \u251c\u2500\u2500 common/            # Shared utilities\n\u2502   \u251c\u2500\u2500 interfaces/        # Abstract interfaces\n\u2502   \u251c\u2500\u2500 python/           # CPython implementations\n\u2502   \u2514\u2500\u2500 pyspark/          # PySpark implementations\n\u251c\u2500\u2500 python_libs_tests/     # Test suites\n\u251c\u2500\u2500 cli.py                 # Main CLI entry point\n\u2514\u2500\u2500 project_config.py      # Project configuration\n</code></pre>"},{"location":"developer_guide/#development-workflow","title":"Development Workflow","text":""},{"location":"developer_guide/#1-feature-development","title":"1. Feature Development","text":"<pre><code># Create feature branch\ngit checkout -b feature/new-feature\n\n# Make changes\n# ... develop your feature ...\n\n# Run tests\npytest ./tests/ -v\npytest ./ingen_fab/python_libs_tests/ -v\n\n# Check code quality\nruff check .\nruff format .\n\n# Commit changes\ngit add .\ngit commit -m \"Add new feature: description\"\n</code></pre>"},{"location":"developer_guide/#2-testing","title":"2. Testing","text":"<pre><code># Run all tests\npytest\n\n# Run specific test modules\npytest ./tests/test_cli.py -v\npytest ./ingen_fab/python_libs_tests/python/test_warehouse_utils_pytest.py -v\n\n# Run with coverage\npytest --cov=ingen_fab --cov-report=html\n\n# Test CLI commands\ningen_fab test local libraries --base-dir .\n</code></pre>"},{"location":"developer_guide/#3-documentation","title":"3. Documentation","text":"<pre><code># Serve documentation locally\nmkdocs serve\n\n# Build documentation\nmkdocs build\n\n# Deploy documentation\nmkdocs gh-deploy\n</code></pre>"},{"location":"developer_guide/#adding-new-features","title":"Adding New Features","text":""},{"location":"developer_guide/#adding-a-new-cli-command","title":"Adding a New CLI Command","text":"<ol> <li> <p>Create command module:    <pre><code># cli_utils/my_new_commands.py\nimport typer\nfrom typing_extensions import Annotated\n\ndef my_new_command(\n    param: Annotated[str, typer.Option(help=\"Description\")]\n):\n    \"\"\"My new command description.\"\"\"\n    print(f\"Executing with param: {param}\")\n</code></pre></p> </li> <li> <p>Register command in CLI:    <pre><code># cli.py\nfrom cli_utils import my_new_commands\n\n# Add command to app\napp.add_typer(\n    my_new_commands.app,\n    name=\"mynew\",\n    help=\"My new command group\"\n)\n</code></pre></p> </li> <li> <p>Add tests:    <pre><code># tests/test_my_new_commands.py\nfrom typer.testing import CliRunner\nfrom ingen_fab.cli import app\n\ndef test_my_new_command():\n    runner = CliRunner()\n    result = runner.invoke(app, [\"mynew\", \"command\", \"--param\", \"value\"])\n    assert result.exit_code == 0\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/#adding-a-new-python-library","title":"Adding a New Python Library","text":"<ol> <li> <p>Create the library:    <pre><code># python_libs/python/my_new_utils.py\nfrom typing import Any\nfrom .notebook_utils_abstraction import get_notebook_utils\n\nclass MyNewUtils:\n    def __init__(self):\n        self.notebook_utils = get_notebook_utils()\n\n    def my_function(self) -&gt; Any:\n        \"\"\"New utility function.\"\"\"\n        return \"result\"\n</code></pre></p> </li> <li> <p>Create tests:    <pre><code># python_libs_tests/python/test_my_new_utils_pytest.py\nimport pytest\nfrom ingen_fab.python_libs.python.my_new_utils import MyNewUtils\n\ndef test_my_function():\n    utils = MyNewUtils()\n    result = utils.my_function()\n    assert result == \"result\"\n</code></pre></p> </li> <li> <p>Add to template injection:    <pre><code># python_libs/gather_python_libs.py\n# Add your library to the collection process\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/#adding-a-new-ddl-template","title":"Adding a New DDL Template","text":"<ol> <li> <p>Create templates:    <pre><code>&lt;!-- ddl_scripts/_templates/common/my_new_template.py.jinja --&gt;\n# Generated DDL script for {{ entity_name }}\nfrom my_new_utils import MyNewUtils\n\nutils = MyNewUtils()\nresult = utils.my_function()\nprint(f\"Result: {result}\")\n</code></pre></p> </li> <li> <p>Update notebook generator:    <pre><code># ddl_scripts/notebook_generator.py\n# Add template to the generation process\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/#code-standards","title":"Code Standards","text":""},{"location":"developer_guide/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8 style guidelines</li> <li>Use type hints where appropriate</li> <li>Write docstrings for all public functions</li> <li>Use meaningful variable and function names</li> </ul>"},{"location":"developer_guide/#testing","title":"Testing","text":"<ul> <li>Write tests for all new functionality</li> <li>Aim for &gt;80% code coverage</li> <li>Use descriptive test names</li> <li>Test both success and failure cases</li> </ul>"},{"location":"developer_guide/#documentation","title":"Documentation","text":"<ul> <li>Update documentation for new features</li> <li>Include code examples</li> <li>Write clear, concise explanations</li> <li>Update CLI help text</li> </ul>"},{"location":"developer_guide/#debugging","title":"Debugging","text":""},{"location":"developer_guide/#local-development","title":"Local Development","text":"<pre><code># Run with verbose output\ningen_fab --help\n\n# Debug specific commands - use VS Code launch configuration\nSee .vscode/launch.json for pre-configured debug setups\n\n# Use logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"developer_guide/#testing-issues","title":"Testing Issues","text":"<pre><code># Run specific test\npytest ./tests/test_cli.py::test_specific_function -v -s\n\n# Debug test failures\npytest ./tests/test_cli.py::test_specific_function --pdb\n\n# Check test coverage\npytest --cov=ingen_fab --cov-report=term-missing\n</code></pre>"},{"location":"developer_guide/#contributing","title":"Contributing","text":""},{"location":"developer_guide/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create feature branch</li> <li>Make changes with tests</li> <li>Update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"developer_guide/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li> Code follows style guidelines</li> <li> Tests are included and passing</li> <li> Documentation is updated</li> <li> No breaking changes (or properly documented)</li> <li> Performance impact is considered</li> </ul>"},{"location":"developer_guide/#advanced-topics","title":"Advanced Topics","text":""},{"location":"developer_guide/#custom-template-development","title":"Custom Template Development","text":"<p>Learn how to create custom templates for specific use cases.</p>"},{"location":"developer_guide/#plugin-architecture","title":"Plugin Architecture","text":"<p>Understand how to extend the CLI with plugins.</p>"},{"location":"developer_guide/#performance-optimization","title":"Performance Optimization","text":"<p>Best practices for optimizing generation and deployment performance.</p>"},{"location":"developer_guide/#integration-testing","title":"Integration Testing","text":"<p>Setting up comprehensive integration tests with Fabric.</p>"},{"location":"developer_guide/#resources","title":"Resources","text":""},{"location":"developer_guide/#internal-documentation","title":"Internal Documentation","text":"<ul> <li>Python Libraries - Detailed library documentation</li> <li>DDL Scripts - Template system guide</li> <li>Notebook Utils - Utility abstractions</li> <li>SQL Templates - SQL template reference</li> </ul>"},{"location":"developer_guide/#external-resources","title":"External Resources","text":"<ul> <li>Typer Documentation</li> <li>Jinja2 Documentation</li> <li>Microsoft Fabric Documentation</li> <li>pytest Documentation</li> </ul>"},{"location":"developer_guide/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: This site covers most development topics</li> <li>Issues: Report bugs or request features on GitHub</li> <li>Discussions: Join community discussions for questions</li> <li>Code Review: Submit pull requests for feedback</li> </ul> <p>Ready to contribute? Start with the Python Libraries guide to understand the core architecture!</p>"},{"location":"developer_guide/ddl_scripts/","title":"DDL Scripts","text":""},{"location":"developer_guide/ddl_scripts/#overview","title":"Overview","text":"<p>The DDL Scripts system provides a template-based approach for generating Data Definition Language (DDL) notebooks for Microsoft Fabric. This system allows you to create reusable templates that can be customized for different environments and use cases.</p>"},{"location":"developer_guide/ddl_scripts/#architecture","title":"Architecture","text":"<p>The DDL Scripts system consists of:</p> <ul> <li>Templates: Jinja2 templates that define the structure and content of DDL scripts</li> <li>Generators: Python modules that process templates and generate notebooks</li> <li>Configuration: YAML and JSON files that define variables and settings</li> </ul>"},{"location":"developer_guide/ddl_scripts/#key-components","title":"Key Components","text":""},{"location":"developer_guide/ddl_scripts/#template-engine","title":"Template Engine","text":"<p>The template engine uses Jinja2 to process templates and generate executable notebooks. Templates can include:</p> <ul> <li>SQL statements</li> <li>Python code</li> <li>Environment-specific variables</li> <li>Conditional logic</li> </ul>"},{"location":"developer_guide/ddl_scripts/#notebook-generator","title":"Notebook Generator","text":"<p>The notebook generator (<code>notebook_generator.py</code>) processes templates and creates Jupyter notebooks that can be executed in Microsoft Fabric.</p>"},{"location":"developer_guide/ddl_scripts/#usage","title":"Usage","text":""},{"location":"developer_guide/ddl_scripts/#basic-template-structure","title":"Basic Template Structure","text":"<pre><code># Generated DDL script for {{ entity_name }}\n\n\nCREATE TABLE {{ table_name }} (\n\n)\n</code></pre>"},{"location":"developer_guide/ddl_scripts/#generating-notebooks","title":"Generating Notebooks","text":"<pre><code># Generate DDL notebooks from templates\ningen_fab ddl compile --environment production\n</code></pre>"},{"location":"developer_guide/ddl_scripts/#template-development","title":"Template Development","text":""},{"location":"developer_guide/ddl_scripts/#creating-new-templates","title":"Creating New Templates","text":"<ol> <li>Create template files in <code>_templates/</code> directory</li> <li>Use Jinja2 syntax for dynamic content</li> <li>Include appropriate metadata and configuration</li> <li>Test template generation locally</li> </ol>"},{"location":"developer_guide/ddl_scripts/#best-practices","title":"Best Practices","text":"<ul> <li>Use meaningful variable names</li> <li>Include error handling</li> <li>Add documentation comments</li> <li>Test with different environments</li> <li>Follow consistent naming conventions</li> </ul>"},{"location":"developer_guide/ddl_scripts/#configuration","title":"Configuration","text":"<p>Templates can be configured using:</p> <ul> <li>Environment variables</li> <li>Configuration files</li> <li>Command-line parameters</li> <li>Template-specific settings</li> </ul>"},{"location":"developer_guide/ddl_scripts/#advanced-features","title":"Advanced Features","text":""},{"location":"developer_guide/ddl_scripts/#conditional-generation","title":"Conditional Generation","text":"<p>Templates support conditional logic for environment-specific customization:</p> <pre><code>-- Development settings\n</code></pre>"},{"location":"developer_guide/ddl_scripts/#template-inheritance","title":"Template Inheritance","text":"<p>Templates can extend base templates for consistency:</p> <p><code>jinja2{% extends \"base_template.sql.jinja\" %} {% block content %} -- Custom content here {% endblock %}</code></p>"},{"location":"developer_guide/ddl_scripts/#integration","title":"Integration","text":"<p>DDL Scripts integrate with:</p> <ul> <li>Microsoft Fabric workspaces</li> <li>Azure DevOps pipelines</li> <li>Local development environments</li> <li>CI/CD workflows</li> </ul>"},{"location":"developer_guide/ddl_scripts/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer_guide/ddl_scripts/#common-issues","title":"Common Issues","text":"<ol> <li>Template Syntax Errors: Check Jinja2 syntax</li> <li>Missing Variables: Ensure all required variables are provided</li> <li>Generation Failures: Check file permissions and paths</li> <li>Environment Issues: Verify configuration settings</li> </ol>"},{"location":"developer_guide/ddl_scripts/#debugging","title":"Debugging","text":"<p>Use verbose mode for detailed output:</p> <pre><code>ingen_fab ddl compile --verbose\n</code></pre>"},{"location":"developer_guide/ddl_scripts/#examples","title":"Examples","text":"<p>See the <code>examples/</code> directory for sample templates and usage patterns.</p>"},{"location":"developer_guide/ddl_scripts/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the Python APIs reference.</p>"},{"location":"developer_guide/notebook_utils/","title":"Notebook Utils","text":""},{"location":"developer_guide/notebook_utils/#overview","title":"Overview","text":"<p>The Notebook Utils module provides environment-agnostic utilities that work seamlessly in both local development and Microsoft Fabric runtime environments. These utilities abstract away the differences between environments and provide consistent interfaces for common operations.</p>"},{"location":"developer_guide/notebook_utils/#architecture","title":"Architecture","text":"<p>The notebook utilities are designed with a layered architecture:</p> <pre><code>graph TD\n    A[Notebook Utils Interface] --&gt; B[Environment Detection]\n    B --&gt; C[Local Environment]\n    B --&gt; D[Fabric Environment]\n    C --&gt; E[Local File System]\n    C --&gt; F[Local Database]\n    D --&gt; G[Fabric Lakehouse]\n    D --&gt; H[Fabric Warehouse]</code></pre>"},{"location":"developer_guide/notebook_utils/#key-components","title":"Key Components","text":""},{"location":"developer_guide/notebook_utils/#environment-abstraction","title":"Environment Abstraction","text":"<p>The utilities automatically detect the runtime environment and provide appropriate implementations:</p> <ul> <li>Local Development: Uses local file system and database connections</li> <li>Fabric Runtime: Uses Fabric-specific APIs and storage</li> </ul>"},{"location":"developer_guide/notebook_utils/#core-utilities","title":"Core Utilities","text":""},{"location":"developer_guide/notebook_utils/#simple-notebook","title":"Simple Notebook","text":"<ul> <li>Basic notebook operations</li> <li>Cell management</li> <li>Execution tracking</li> </ul>"},{"location":"developer_guide/notebook_utils/#fabric-cli-notebook","title":"Fabric CLI Notebook","text":"<ul> <li>Fabric-specific notebook operations</li> <li>Integration with Fabric APIs</li> <li>Workspace management</li> </ul>"},{"location":"developer_guide/notebook_utils/#notebook-block-injector","title":"Notebook Block Injector","text":"<ul> <li>Dynamic code injection</li> <li>Template processing</li> <li>Environment-specific customization</li> </ul>"},{"location":"developer_guide/notebook_utils/#usage","title":"Usage","text":""},{"location":"developer_guide/notebook_utils/#basic-operations","title":"Basic Operations","text":"<pre><code>from ingen_fab.notebook_utils import get_notebook_utils\n\n# Get environment-appropriate utilities\nutils = get_notebook_utils()\n\n# Perform operations\nresult = utils.execute_query(\"SELECT * FROM my_table\")\n</code></pre>"},{"location":"developer_guide/notebook_utils/#environment-detection","title":"Environment Detection","text":"<pre><code>from ingen_fab.notebook_utils import detect_environment\n\nenv = detect_environment()\nif env == 'fabric':\n    # Fabric-specific code\n    pass\nelif env == 'local':\n    # Local development code\n    pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#file-operations","title":"File Operations","text":"<pre><code># Read files (works in both environments)\ndata = utils.read_file(\"path/to/file.csv\")\n\n# Write files\nutils.write_file(\"output.json\", data)\n</code></pre>"},{"location":"developer_guide/notebook_utils/#configuration","title":"Configuration","text":""},{"location":"developer_guide/notebook_utils/#environment-variables","title":"Environment Variables","text":"<p>The utilities respect environment-specific configuration:</p> <pre><code># Local development\nexport NOTEBOOK_ENV=local\nexport DB_CONNECTION_STRING=...\n\n# Fabric runtime (automatically detected)\nexport FABRIC_WORKSPACE_ID=...\n</code></pre>"},{"location":"developer_guide/notebook_utils/#settings-files","title":"Settings Files","text":"<p>Configuration can be managed through settings files:</p> <pre><code>{\n    \"environment\": \"local\",\n    \"database\": {\n        \"connection_string\": \"...\",\n        \"timeout\": 30\n    },\n    \"logging\": {\n        \"level\": \"INFO\"\n    }\n}\n</code></pre>"},{"location":"developer_guide/notebook_utils/#api-reference","title":"API Reference","text":""},{"location":"developer_guide/notebook_utils/#notebookutils-interface","title":"NotebookUtils Interface","text":"<pre><code>class NotebookUtils:\n    def execute_query(self, query: str) -&gt; Any:\n        \"\"\"Execute SQL query in current environment\"\"\"\n        pass\n\n    def read_file(self, path: str) -&gt; Any:\n        \"\"\"Read file from storage\"\"\"\n        pass\n\n    def write_file(self, path: str, data: Any) -&gt; None:\n        \"\"\"Write file to storage\"\"\"\n        pass\n\n    def get_connection(self) -&gt; Any:\n        \"\"\"Get database connection\"\"\"\n        pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#environment-specific-implementations","title":"Environment-Specific Implementations","text":""},{"location":"developer_guide/notebook_utils/#local-environment","title":"Local Environment","text":"<pre><code>class LocalNotebookUtils(NotebookUtils):\n    \"\"\"Local development implementation\"\"\"\n    pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#fabric-environment","title":"Fabric Environment","text":"<pre><code>class FabricNotebookUtils(NotebookUtils):\n    \"\"\"Microsoft Fabric implementation\"\"\"\n    pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#testing","title":"Testing","text":""},{"location":"developer_guide/notebook_utils/#unit-tests","title":"Unit Tests","text":"<pre><code>import pytest\nfrom notebook_utils import get_notebook_utils\n\ndef test_environment_detection():\n    utils = get_notebook_utils()\n    assert utils is not None\n\ndef test_query_execution():\n    utils = get_notebook_utils()\n    result = utils.execute_query(\"SELECT 1\")\n    assert result is not None\n</code></pre>"},{"location":"developer_guide/notebook_utils/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_fabric_integration():\n    \"\"\"Test integration with Fabric environment\"\"\"\n    # Integration test code\n    pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#best-practices","title":"Best Practices","text":""},{"location":"developer_guide/notebook_utils/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    result = utils.execute_query(query)\nexcept NotebookUtilsError as e:\n    logger.error(f\"Query failed: {e}\")\n    # Handle error appropriately\n</code></pre>"},{"location":"developer_guide/notebook_utils/#resource-management","title":"Resource Management","text":"<pre><code># Use context managers when available\nwith utils.get_connection() as conn:\n    result = conn.execute(query)\n</code></pre>"},{"location":"developer_guide/notebook_utils/#logging","title":"Logging","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\nlogger.info(\"Executing notebook operation\")\n</code></pre>"},{"location":"developer_guide/notebook_utils/#advanced-features","title":"Advanced Features","text":""},{"location":"developer_guide/notebook_utils/#custom-implementations","title":"Custom Implementations","text":"<p>You can create custom implementations for specific use cases:</p> <pre><code>class CustomNotebookUtils(NotebookUtils):\n    def custom_operation(self):\n        \"\"\"Custom functionality\"\"\"\n        pass\n</code></pre>"},{"location":"developer_guide/notebook_utils/#plugin-system","title":"Plugin System","text":"<p>The utilities support a plugin system for extending functionality:</p> <pre><code>from notebook_utils import register_plugin\n\nregister_plugin('my_plugin', MyPlugin)\n</code></pre>"},{"location":"developer_guide/notebook_utils/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer_guide/notebook_utils/#common-issues","title":"Common Issues","text":"<ol> <li>Environment Detection Failures: Check environment variables</li> <li>Connection Issues: Verify database credentials</li> <li>File Access Errors: Check file permissions</li> <li>API Failures: Verify Fabric workspace settings</li> </ol>"},{"location":"developer_guide/notebook_utils/#debugging","title":"Debugging","text":"<p>Enable debug logging:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"developer_guide/notebook_utils/#examples","title":"Examples","text":"<p>See the <code>examples/</code> directory for complete usage examples and patterns.</p>"},{"location":"developer_guide/notebook_utils/#integration","title":"Integration","text":"<p>The notebook utilities integrate with:</p> <ul> <li>DDL Scripts for template processing</li> <li>Python Libraries for core functionality</li> <li>SQL Templates for query generation</li> </ul>"},{"location":"developer_guide/python_libraries/","title":"Python Libraries","text":"<p>The Python libraries are the heart of the Ingenious Fabric Accelerator, providing reusable components that work seamlessly across both local development and Fabric runtime environments. This allows developers to build high quality, reusable code libraries that can be both unit tested and functionally tested locally before being deployed to Fabric.</p>"},{"location":"developer_guide/python_libraries/#architecture","title":"Architecture","text":"<p>The library architecture follows a layered approach:</p>"},{"location":"developer_guide/python_libraries/#library-abstraction","title":"Library Abstraction","text":"<pre><code>graph TB\n    A[Fabric Notebooks] --&gt; B[Python Libraries]\n    B --&gt; C[Local Development]\n    B --&gt; D[Fabric Workspace]\n\n    classDef grey fill:#a9a9a9,stroke:#000,stroke-width:1px,color:#fff;\n    classDef green fill:#228B22,stroke:#000,stroke-width:1px,color:#fff;\n\n    class C grey;\n    class D green;   \n</code></pre>"},{"location":"developer_guide/python_libraries/#table-operation-abstractions","title":"Table Operation Abstractions","text":"<pre><code>graph TB\n    K[Datastore Interface] --&gt; L[Lakehouse Implementation]\n    K --&gt; M[Warehouse Implementation]\n    L --&gt; N[Local Spark Instance]\n    L --&gt; O[Fabric Lakehouse]\n    M --&gt; P[Local SQL Server]\n    M --&gt; Q[Fabric Warehouse]\n\n    classDef grey fill:#a9a9a9,stroke:#000,stroke-width:1px,color:#fff;\n    classDef green fill:#228B22,stroke:#000,stroke-width:1px,color:#fff;\n\n    class N,P grey;\n    class O,Q green;    \n\n</code></pre>"},{"location":"developer_guide/python_libraries/#directory-structure","title":"Directory Structure","text":"<pre><code>python_libs/\n\u251c\u2500\u2500 common/                    # Shared utilities\n\u2502   \u251c\u2500\u2500 config_utils.py       # Configuration management\n\u2502   \u251c\u2500\u2500 data_utils.py         # Data processing utilities\n\u2502   \u2514\u2500\u2500 workflow_utils.py     # Workflow orchestration\n\u251c\u2500\u2500 interfaces/               # Abstract interfaces\n\u2502   \u251c\u2500\u2500 data_store_interface.py\n\u2502   \u2514\u2500\u2500 ddl_utils_interface.py\n\u251c\u2500\u2500 python/                   # CPython implementations\n\u2502   \u251c\u2500\u2500 ddl_utils.py          # DDL execution utilities\n\u2502   \u251c\u2500\u2500 lakehouse_utils.py    # Lakehouse operations\n\u2502   \u251c\u2500\u2500 notebook_utils_abstraction.py\n\u2502   \u251c\u2500\u2500 pipeline_utils.py     # Pipeline utilities\n\u2502   \u251c\u2500\u2500 sql_template_factory/ # SQL template system\n\u2502   \u2514\u2500\u2500 warehouse_utils.py    # Warehouse operations\n\u251c\u2500\u2500 pyspark/                  # PySpark implementations\n\u2502   \u251c\u2500\u2500 ddl_utils.py          # Spark DDL utilities\n\u2502   \u251c\u2500\u2500 lakehouse_utils.py    # Spark lakehouse operations\n\u2502   \u251c\u2500\u2500 notebook_utils_abstraction.py\n\u2502   \u2514\u2500\u2500 parquet_load_utils.py # Parquet processing\n\u2514\u2500\u2500 gather_python_libs.py    # Library collection script\n</code></pre>"},{"location":"developer_guide/python_libraries/#core-components","title":"Core Components","text":""},{"location":"developer_guide/python_libraries/#common-utilities","title":"Common Utilities","text":""},{"location":"developer_guide/python_libraries/#config_utilspy","title":"<code>config_utils.py</code>","text":"<p>Configuration management with environment-specific settings:</p> <pre><code>from common.config_utils import FabricConfig\n\n# Load configuration from environment\nconfig = FabricConfig.from_environment()\n\n# Access configuration values\nworkspace_id = config.workspace_id\nlakehouse_id = config.lakehouse_id\n</code></pre>"},{"location":"developer_guide/python_libraries/#data_utilspy","title":"<code>data_utils.py</code>","text":"<p>Data processing and validation utilities:</p> <pre><code>from common.data_utils import DataValidator, DataTransformer\n\n# Validate data\nvalidator = DataValidator()\nis_valid = validator.validate_schema(dataframe, expected_schema)\n\n# Transform data\ntransformer = DataTransformer()\ncleaned_data = transformer.clean_data(dataframe)\n</code></pre>"},{"location":"developer_guide/python_libraries/#workflow_utilspy","title":"<code>workflow_utils.py</code>","text":"<p>Workflow orchestration and dependency management:</p> <pre><code>from common.workflow_utils import WorkflowOrchestrator\n\n# Create workflow\norchestrator = WorkflowOrchestrator()\norchestrator.add_task(\"task1\", dependencies=[])\norchestrator.add_task(\"task2\", dependencies=[\"task1\"])\norchestrator.execute()\n</code></pre>"},{"location":"developer_guide/python_libraries/#interfaces","title":"Interfaces","text":""},{"location":"developer_guide/python_libraries/#data_store_interfacepy","title":"<code>data_store_interface.py</code>","text":"<p>Abstract interface for data store operations:</p> <pre><code>from abc import ABC, abstractmethod\n\nclass DataStoreInterface(ABC):\n    @abstractmethod\n    def read_table(self, table_name: str) -&gt; Any:\n        pass\n\n    @abstractmethod\n    def write_table(self, table_name: str, data: Any) -&gt; None:\n        pass\n</code></pre>"},{"location":"developer_guide/python_libraries/#ddl_utils_interfacepy","title":"<code>ddl_utils_interface.py</code>","text":"<p>Interface for DDL execution:</p> <pre><code>class DDLUtilsInterface(ABC):\n    @abstractmethod\n    def execute_ddl(self, sql: str, description: str) -&gt; None:\n        pass\n\n    @abstractmethod\n    def log_execution(self, script_name: str, description: str) -&gt; None:\n        pass\n</code></pre>"},{"location":"developer_guide/python_libraries/#python-implementation","title":"Python Implementation","text":""},{"location":"developer_guide/python_libraries/#ddl_utilspy","title":"<code>ddl_utils.py</code>","text":"<p>DDL execution with logging and error handling:</p> <pre><code>from python.ddl_utils import DDLUtils\n\nddl_utils = DDLUtils(\n    target_warehouse_id=\"warehouse-guid\",\n    target_workspace_id=\"workspace-guid\",\n    config_workspace_id=\"config-workspace-guid\",\n    config_lakehouse_id=\"config-lakehouse-guid\"\n)\n\n# Execute DDL with logging\nddl_utils.execute_ddl(\n    sql=\"CREATE TABLE test (id INT, name STRING)\",\n    description=\"Create test table\"\n)\n</code></pre>"},{"location":"developer_guide/python_libraries/#lakehouse_utilspy","title":"<code>lakehouse_utils.py</code>","text":"<p>Lakehouse operations for file and table management:</p> <pre><code>from python.lakehouse_utils import LakehouseUtils\n\nlakehouse_utils = LakehouseUtils(\n    target_lakehouse_id=\"lakehouse-guid\",\n    target_workspace_id=\"workspace-guid\"\n)\n\n# File operations\nfiles = lakehouse_utils.list_files(\"Tables/\")\nlakehouse_utils.upload_file(\"local_file.csv\", \"Files/data/\")\n\n# Table operations\ntables = lakehouse_utils.list_tables()\ndf = lakehouse_utils.read_table(\"config.metadata\")\n</code></pre>"},{"location":"developer_guide/python_libraries/#warehouse_utilspy","title":"<code>warehouse_utils.py</code>","text":"<p>Warehouse connectivity and query execution:</p> <pre><code>from python.warehouse_utils import WarehouseUtils\n\nwarehouse_utils = WarehouseUtils(\n    target_warehouse_id=\"warehouse-guid\",\n    target_workspace_id=\"workspace-guid\",\n    dialect=\"fabric\"  # or \"sqlserver\"\n)\n\n# Execute queries\nresult = warehouse_utils.execute_query(\"SELECT * FROM config.metadata\")\nwarehouse_utils.execute_non_query(\"INSERT INTO logs VALUES (...)\")\n</code></pre>"},{"location":"developer_guide/python_libraries/#notebook_utils_abstractionpy","title":"<code>notebook_utils_abstraction.py</code>","text":"<p>Environment-agnostic notebook utilities:</p> <pre><code>from python.notebook_utils_abstraction import get_notebook_utils\n\n# Automatically detects environment\nutils = get_notebook_utils()\n\n# Works in both local and Fabric environments\nutils.display(dataframe)\nconnection = utils.connect_to_artifact(warehouse_id, workspace_id)\nsecret = utils.get_secret(\"API_KEY\", \"key-vault-name\")\n</code></pre>"},{"location":"developer_guide/python_libraries/#pyspark-implementation","title":"PySpark Implementation","text":""},{"location":"developer_guide/python_libraries/#ddl_utilspy_1","title":"<code>ddl_utils.py</code>","text":"<p>Spark-compatible DDL execution:</p> <pre><code>from pyspark.ddl_utils import DDLUtils\n\nddl_utils = DDLUtils(\n    target_lakehouse_id=\"lakehouse-guid\",\n    target_workspace_id=\"workspace-guid\",\n    spark_session=spark\n)\n\n# Execute DDL in Spark context\nddl_utils.execute_ddl(\n    sql=\"CREATE TABLE delta_table USING DELTA AS SELECT * FROM source\",\n    description=\"Create Delta table\"\n)\n</code></pre>"},{"location":"developer_guide/python_libraries/#lakehouse_utilspy_1","title":"<code>lakehouse_utils.py</code>","text":"<p>Spark-based lakehouse operations:</p> <pre><code>from pyspark.lakehouse_utils import LakehouseUtils\n\nlakehouse_utils = LakehouseUtils(\n    target_lakehouse_id=\"lakehouse-guid\",\n    target_workspace_id=\"workspace-guid\",\n    spark_session=spark\n)\n\n# Read/write Delta tables\ndf = lakehouse_utils.read_delta_table(\"config.metadata\")\nlakehouse_utils.write_delta_table(df, \"output.results\")\n</code></pre>"},{"location":"developer_guide/python_libraries/#parquet_load_utilspy","title":"<code>parquet_load_utils.py</code>","text":"<p>Parquet file processing utilities:</p> <pre><code>from pyspark.parquet_load_utils import ParquetLoadUtils\n\nparquet_utils = ParquetLoadUtils(spark_session=spark)\n\n# Load and process parquet files\ndf = parquet_utils.load_parquet_files(\"path/to/files/*.parquet\")\nprocessed_df = parquet_utils.process_parquet_data(df, transformations)\nparquet_utils.save_to_delta(\"output_table\", processed_df)\n</code></pre>"},{"location":"developer_guide/python_libraries/#sql-template-factory","title":"SQL Template Factory","text":"<p>The SQL template system provides database-agnostic SQL generation:</p> <pre><code>from python.sql_templates import SQLTemplates\n\n# Create templates instance\ntemplates = SQLTemplates(dialect=\"fabric\")  # or \"sqlserver\"\n\n# Generate SQL\nsql = templates.render(\"check_table_exists\", \n                      schema_name=\"config\", \n                      table_name=\"metadata\")\n</code></pre> <p>Available templates: - <code>check_table_exists</code> - Check if table exists - <code>create_table</code> - Create table with schema - <code>drop_table</code> - Drop table if exists - <code>insert_row</code> - Insert single row - <code>list_tables</code> - List all tables - <code>get_table_schema</code> - Get table schema information</p>"},{"location":"developer_guide/python_libraries/#testing","title":"Testing","text":""},{"location":"developer_guide/python_libraries/#unit-tests","title":"Unit Tests","text":"<p>Each library has comprehensive unit tests:</p> <pre><code># Run all library tests\npytest ./ingen_fab/python_libs_tests/ -v\n\n# Run specific library tests\npytest ./ingen_fab/python_libs_tests/python/test_warehouse_utils_pytest.py -v\npytest ./ingen_fab/python_libs_tests/pyspark/test_lakehouse_utils_pytest.py -v\n\n# Run with coverage\npytest ./ingen_fab/python_libs_tests/ --cov=ingen_fab.python_libs --cov-report=html\n</code></pre>"},{"location":"developer_guide/python_libraries/#integration-tests","title":"Integration Tests","text":"<p>Test with actual Fabric workspaces:</p> <pre><code># Test with environment variables set\nexport FABRIC_WORKSPACE_ID=\"your-workspace-id\"\nexport FABRIC_LAKEHOUSE_ID=\"your-lakehouse-id\"\npytest ./ingen_fab/python_libs_tests/integration/ -v\n</code></pre>"},{"location":"developer_guide/python_libraries/#development-guidelines","title":"Development Guidelines","text":""},{"location":"developer_guide/python_libraries/#adding-new-libraries","title":"Adding New Libraries","text":"<ol> <li> <p>Create the library module:    <pre><code># python_libs/python/my_new_utils.py\nfrom .notebook_utils_abstraction import get_notebook_utils\n\nclass MyNewUtils:\n    def __init__(self):\n        self.notebook_utils = get_notebook_utils()\n\n    def my_method(self):\n        return \"result\"\n</code></pre></p> </li> <li> <p>Add corresponding tests:    <pre><code># python_libs_tests/python/test_my_new_utils_pytest.py\nimport pytest\nfrom ingen_fab.python_libs.python.my_new_utils import MyNewUtils\n\ndef test_my_method():\n    utils = MyNewUtils()\n    assert utils.my_method() == \"result\"\n</code></pre></p> </li> <li> <p>Update library collection:    <pre><code># python_libs/gather_python_libs.py\n# Add your library to the collection process\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/python_libraries/#interface-implementation","title":"Interface Implementation","text":"<p>When creating new implementations:</p> <ol> <li> <p>Define interface first:    <pre><code># interfaces/my_interface.py\nfrom abc import ABC, abstractmethod\n\nclass MyInterface(ABC):\n    @abstractmethod\n    def my_method(self) -&gt; str:\n        pass\n</code></pre></p> </li> <li> <p>Implement for both runtimes:    <pre><code># python/my_implementation.py\nfrom ..interfaces.my_interface import MyInterface\n\nclass MyImplementation(MyInterface):\n    def my_method(self) -&gt; str:\n        return \"python implementation\"\n</code></pre></p> </li> <li> <p>Create PySpark version:    <pre><code># pyspark/my_implementation.py\nfrom ..interfaces.my_interface import MyInterface\n\nclass MyImplementation(MyInterface):\n    def my_method(self) -&gt; str:\n        return \"pyspark implementation\"\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/python_libraries/#best-practices","title":"Best Practices","text":"<ol> <li>Environment Agnostic: Use abstractions to work in both local and Fabric environments</li> <li>Error Handling: Always include proper error handling and logging</li> <li>Type Hints: Use type hints for better code documentation</li> <li>Testing: Write comprehensive tests for all functionality</li> <li>Documentation: Include docstrings and usage examples</li> </ol>"},{"location":"developer_guide/python_libraries/#library-injection","title":"Library Injection","text":"<p>Libraries are automatically injected into generated notebooks:</p> <pre><code># In generated notebook\nfrom lakehouse_utils import LakehouseUtils\nfrom warehouse_utils import WarehouseUtils\nfrom ddl_utils import DDLUtils\n\n# Libraries are available for use\nlakehouse_utils = LakehouseUtils()\nwarehouse_utils = WarehouseUtils()\nddl_utils = DDLUtils()\n</code></pre>"},{"location":"developer_guide/python_libraries/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Lazy Loading: Libraries use lazy loading where possible</li> <li>Connection Pooling: Database connections are reused</li> <li>Caching: Results are cached when appropriate</li> <li>Memory Management: Large datasets are processed in chunks</li> </ul>"},{"location":"developer_guide/python_libraries/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer_guide/python_libraries/#common-issues","title":"Common Issues","text":"<ol> <li>Import Errors: Check that libraries are properly injected</li> <li>Connection Failures: Verify workspace and lakehouse IDs</li> <li>Permission Errors: Ensure proper authentication</li> <li>Type Errors: Use type hints and validation</li> </ol>"},{"location":"developer_guide/python_libraries/#debugging","title":"Debugging","text":"<pre><code># Enable debug logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Test library functionality\nfrom python.warehouse_utils import WarehouseUtils\nutils = WarehouseUtils()\nutils.test_connection()\n</code></pre> <p>The Python libraries provide a robust foundation for building Fabric applications with consistent, testable, and maintainable code.</p>"},{"location":"developer_guide/sql_templates/","title":"SQL Templates","text":""},{"location":"developer_guide/sql_templates/#overview","title":"Overview","text":"<p>The SQL Templates system provides a flexible, Jinja2-based templating engine for generating SQL queries across different database dialects. This system supports Microsoft Fabric (Spark SQL), SQL Server, and other database platforms with consistent interfaces and reusable templates.</p>"},{"location":"developer_guide/sql_templates/#architecture","title":"Architecture","text":"<p>The SQL template system is organized by database dialect:</p> <pre><code>sql_template_factory/\n\u251c\u2500\u2500 fabric/           # Microsoft Fabric templates\n\u251c\u2500\u2500 sql_server/       # SQL Server templates\n\u251c\u2500\u2500 common/           # Shared templates\n\u2514\u2500\u2500 generate_templates.py  # Template generator\n</code></pre>"},{"location":"developer_guide/sql_templates/#supported-dialects","title":"Supported Dialects","text":""},{"location":"developer_guide/sql_templates/#microsoft-fabric-spark-sql","title":"Microsoft Fabric (Spark SQL)","text":"<ul> <li>Delta Lake operations</li> <li>Lakehouse queries</li> <li>Warehouse operations</li> <li>PySpark integration</li> </ul>"},{"location":"developer_guide/sql_templates/#sql-server","title":"SQL Server","text":"<ul> <li>Traditional SQL Server syntax</li> <li>Stored procedures</li> <li>Views and functions</li> <li>Performance optimizations</li> </ul>"},{"location":"developer_guide/sql_templates/#core-templates","title":"Core Templates","text":""},{"location":"developer_guide/sql_templates/#table-operations","title":"Table Operations","text":""},{"location":"developer_guide/sql_templates/#create-table","title":"Create Table","text":"<p><code>sql-- fabric/create_table.sql.jinja CREATE TABLE {{ schema_name }}.{{ table_name }} (     {% for column in columns %}     {{ column.name }} {{ column.type }}{% if column.nullable %} NULL{% else %} NOT NULL{% endif %}{% if not loop.last %},{% endif %}     {% endfor %} ) {% if partition_by %} PARTITIONED BY ({{ partition_by | join(', ') }}) {% endif %}</code></p>"},{"location":"developer_guide/sql_templates/#read-table","title":"Read Table","text":"<p><code>sql-- fabric/read_table.sql.jinja SELECT      {% for column in columns %}     {{ column }}{% if not loop.last %},{% endif %}     {% endfor %} FROM {{ schema_name }}.{{ table_name }} {% if where_clause %} WHERE {{ where_clause }} {% endif %} {% if limit %} LIMIT {{ limit }} {% endif %}</code></p>"},{"location":"developer_guide/sql_templates/#schema-operations","title":"Schema Operations","text":""},{"location":"developer_guide/sql_templates/#list-schemas","title":"List Schemas","text":"<p><code>sql-- fabric/list_schemas.sql.jinja SHOW SCHEMAS {% if like_pattern %} LIKE '{{ like_pattern }}' {% endif %}</code></p>"},{"location":"developer_guide/sql_templates/#check-schema-exists","title":"Check Schema Exists","text":"<p><code>sql-- fabric/check_schema_exists.sql.jinja SELECT COUNT(*) as schema_count FROM information_schema.schemata  WHERE schema_name = '{{ schema_name }}'</code></p>"},{"location":"developer_guide/sql_templates/#data-operations","title":"Data Operations","text":""},{"location":"developer_guide/sql_templates/#insert-data","title":"Insert Data","text":"<p><code>sql-- fabric/insert_row.sql.jinja INSERT INTO {{ schema_name }}.{{ table_name }} ({{ columns | join(', ') }}) VALUES {% for row in rows %} ({{ row | join(', ') }}){% if not loop.last %},{% endif %} {% endfor %}</code></p>"},{"location":"developer_guide/sql_templates/#delete-data","title":"Delete Data","text":"<p><code>sql-- fabric/delete_from_table.sql.jinja DELETE FROM {{ schema_name }}.{{ table_name }} {% if where_clause %} WHERE {{ where_clause }} {% endif %}</code></p>"},{"location":"developer_guide/sql_templates/#template-generation","title":"Template Generation","text":""},{"location":"developer_guide/sql_templates/#python-interface","title":"Python Interface","text":"<pre><code>from sql_template_factory import get_template\n\n# Get template for specific dialect\ntemplate = get_template('fabric', 'create_table')\n\n# Render template with parameters\nsql = template.render(\n    schema_name='my_schema',\n    table_name='my_table',\n    columns=[\n        {'name': 'id', 'type': 'BIGINT', 'nullable': False},\n        {'name': 'name', 'type': 'STRING', 'nullable': True}\n    ]\n)\n</code></pre>"},{"location":"developer_guide/sql_templates/#template-factory","title":"Template Factory","text":"<pre><code>class SqlTemplateFactory:\n    def __init__(self, dialect='fabric'):\n        self.dialect = dialect\n\n    def create_table(self, schema_name, table_name, columns):\n        \"\"\"Generate CREATE TABLE statement\"\"\"\n        template = self.get_template('create_table')\n        return template.render(\n            schema_name=schema_name,\n            table_name=table_name,\n            columns=columns\n        )\n\n    def read_table(self, schema_name, table_name, columns=None, where_clause=None):\n        \"\"\"Generate SELECT statement\"\"\"\n        template = self.get_template('read_table')\n        return template.render(\n            schema_name=schema_name,\n            table_name=table_name,\n            columns=columns or ['*'],\n            where_clause=where_clause\n        )\n</code></pre>"},{"location":"developer_guide/sql_templates/#usage-examples","title":"Usage Examples","text":""},{"location":"developer_guide/sql_templates/#basic-table-creation","title":"Basic Table Creation","text":"<pre><code>from sql_template_factory import SqlTemplateFactory\n\nfactory = SqlTemplateFactory('fabric')\n\n# Create table\ncreate_sql = factory.create_table(\n    schema_name='analytics',\n    table_name='user_metrics',\n    columns=[\n        {'name': 'user_id', 'type': 'BIGINT', 'nullable': False},\n        {'name': 'metric_date', 'type': 'DATE', 'nullable': False},\n        {'name': 'page_views', 'type': 'INT', 'nullable': True}\n    ]\n)\n\nprint(create_sql)\n</code></pre>"},{"location":"developer_guide/sql_templates/#dynamic-query-building","title":"Dynamic Query Building","text":"<pre><code># Build query with conditions\nquery = factory.read_table(\n    schema_name='analytics',\n    table_name='user_metrics',\n    columns=['user_id', 'SUM(page_views) as total_views'],\n    where_clause='metric_date &gt;= \"2024-01-01\"'\n)\n</code></pre>"},{"location":"developer_guide/sql_templates/#cross-dialect-support","title":"Cross-Dialect Support","text":"<pre><code># Create templates for different dialects\nfabric_factory = SqlTemplateFactory('fabric')\nsqlserver_factory = SqlTemplateFactory('sql_server')\n\n# Same interface, different SQL output\nfabric_sql = fabric_factory.create_table(schema, table, columns)\nsqlserver_sql = sqlserver_factory.create_table(schema, table, columns)\n</code></pre>"},{"location":"developer_guide/sql_templates/#configuration","title":"Configuration","text":""},{"location":"developer_guide/sql_templates/#template-paths","title":"Template Paths","text":"<pre><code># Configure custom template paths\nfactory = SqlTemplateFactory(\n    dialect='fabric',\n    template_path='/custom/templates'\n)\n</code></pre>"},{"location":"developer_guide/sql_templates/#environment-variables","title":"Environment Variables","text":"<pre><code># Set default dialect\nexport SQL_TEMPLATE_DIALECT=fabric\n\n# Set custom template directory\nexport SQL_TEMPLATE_PATH=/path/to/templates\n</code></pre>"},{"location":"developer_guide/sql_templates/#advanced-features","title":"Advanced Features","text":""},{"location":"developer_guide/sql_templates/#custom-filters","title":"Custom Filters","text":"<pre><code># Add custom Jinja2 filters\ndef quote_identifier(value):\n    return f'`{value}`'\n\nfactory.add_filter('quote', quote_identifier)\n</code></pre>"},{"location":"developer_guide/sql_templates/#template-inheritance","title":"Template Inheritance","text":"<p>```jinja2 SELECT      {% block columns %}*{% endblock %} FROM {{ schema_name }}.{{ table_name }} {% block where_clause %}{% endblock %}</p> <p>{% extends \"base_query.sql.jinja\" %} {% block content %}     user_id,     user_name,     created_date {% endblock %} {% block where_clause %} WHERE active = 1 {% endblock %}```</p>"},{"location":"developer_guide/sql_templates/#macros","title":"Macros","text":"<p><code>jinja2{% macro render_column(column) %}     {{ column.name }} {{ column.type }}     {%- if not column.nullable %} NOT NULL{% endif %}     {%- if column.default %} DEFAULT {{ column.default }}{% endif %} {% endmacro %}</code></p>"},{"location":"developer_guide/sql_templates/#integration","title":"Integration","text":""},{"location":"developer_guide/sql_templates/#with-ddl-scripts","title":"With DDL Scripts","text":"<pre><code>from ddl_scripts import DDLScriptGenerator\nfrom sql_template_factory import SqlTemplateFactory\n\nclass FabricDDLGenerator(DDLScriptGenerator):\n    def __init__(self):\n        self.sql_factory = SqlTemplateFactory('fabric')\n\n    def generate_create_table(self, schema, table, columns):\n        return self.sql_factory.create_table(schema, table, columns)\n</code></pre>"},{"location":"developer_guide/sql_templates/#with-notebook-utils","title":"With Notebook Utils","text":"<pre><code>from notebook_utils import get_notebook_utils\nfrom sql_template_factory import SqlTemplateFactory\n\nutils = get_notebook_utils()\nfactory = SqlTemplateFactory('fabric')\n\n# Generate and execute query\nsql = factory.read_table('analytics', 'metrics')\nresult = utils.execute_query(sql)\n</code></pre>"},{"location":"developer_guide/sql_templates/#testing","title":"Testing","text":""},{"location":"developer_guide/sql_templates/#template-tests","title":"Template Tests","text":"<pre><code>import pytest\nfrom sql_template_factory import SqlTemplateFactory\n\ndef test_create_table_template():\n    factory = SqlTemplateFactory('fabric')\n    sql = factory.create_table(\n        'test_schema',\n        'test_table',\n        [{'name': 'id', 'type': 'BIGINT', 'nullable': False}]\n    )\n    assert 'CREATE TABLE test_schema.test_table' in sql\n    assert 'id BIGINT NOT NULL' in sql\n</code></pre>"},{"location":"developer_guide/sql_templates/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_fabric_integration():\n    \"\"\"Test template generation with Fabric\"\"\"\n    factory = SqlTemplateFactory('fabric')\n    # Test with actual Fabric environment\n    pass\n</code></pre>"},{"location":"developer_guide/sql_templates/#best-practices","title":"Best Practices","text":""},{"location":"developer_guide/sql_templates/#template-organization","title":"Template Organization","text":"<ol> <li>Separate by dialect: Keep templates organized by database type</li> <li>Use meaningful names: Template names should reflect their purpose</li> <li>Include documentation: Add comments explaining template usage</li> <li>Version control: Track template changes over time</li> </ol>"},{"location":"developer_guide/sql_templates/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Template caching: Cache compiled templates for reuse</li> <li>Lazy loading: Load templates only when needed</li> <li>Validation: Validate template parameters before rendering</li> </ol>"},{"location":"developer_guide/sql_templates/#security","title":"Security","text":"<ol> <li>Parameter validation: Validate all input parameters</li> <li>SQL injection prevention: Use parameterized queries where possible</li> <li>Access control: Limit template access based on user permissions</li> </ol>"},{"location":"developer_guide/sql_templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer_guide/sql_templates/#common-issues","title":"Common Issues","text":"<ol> <li>Template not found: Check template path and naming</li> <li>Rendering errors: Verify all required parameters are provided</li> <li>Syntax errors: Check Jinja2 template syntax</li> <li>Dialect mismatches: Ensure template matches target database</li> </ol>"},{"location":"developer_guide/sql_templates/#debugging","title":"Debugging","text":"<pre><code># Enable template debugging\nfactory = SqlTemplateFactory('fabric', debug=True)\n\n# View rendered template\nprint(factory.debug_render('create_table', **params))\n</code></pre>"},{"location":"developer_guide/sql_templates/#api-reference","title":"API Reference","text":"<p>For complete API documentation, see the Python APIs reference.</p>"},{"location":"developer_guide/sql_templates/#examples","title":"Examples","text":"<p>Complete examples are available in the <code>examples/</code> directory, including:</p> <ul> <li>Basic template usage</li> <li>Cross-dialect queries</li> <li>Custom template development</li> <li>Integration patterns</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples and real-world scenarios for using the Ingenious Fabric Accelerator. From simple getting-started examples to complex multi-environment deployments, these examples will help you understand how to use the tool effectively.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":""},{"location":"examples/#sample-project","title":"Sample Project","text":"<p>A complete walkthrough of the included sample project, demonstrating: - Project structure and organization - Environment configuration - DDL script development - Deployment workflow - Testing strategies</p>"},{"location":"examples/#project-templates","title":"Project Templates","text":"<p>Guide to using and customizing project templates: - Understanding template structure - Creating custom templates - Template variables and substitution - Best practices for template development</p>"},{"location":"examples/#quick-examples","title":"Quick Examples","text":""},{"location":"examples/#basic-project-setup","title":"Basic Project Setup","text":"<pre><code># Create a new project\ningen_fab init solution --project-name \"Analytics Platform\"\n\n# Navigate to project directory\ncd analytics-platform\n\n# Configure your environment\nvim fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/development.json\n</code></pre>"},{"location":"examples/#simple-ddl-script","title":"Simple DDL Script","text":"<pre><code># ddl_scripts/Lakehouses/Config/001_Initial_Setup/001_create_config_table.py\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\n# Initialize utilities\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\n# Create configuration table\nsql = \"\"\"\nCREATE TABLE IF NOT EXISTS config.application_settings (\n    setting_name STRING,\n    setting_value STRING,\n    environment STRING,\n    created_date TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/config/application_settings'\n\"\"\"\n\nddl_utils.execute_ddl(sql, \"Create application settings table\")\nprint(\"\u2705 Configuration table created successfully!\")\n</code></pre>"},{"location":"examples/#deployment-workflow","title":"Deployment Workflow","text":"<pre><code># Generate notebooks\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n\n# Test locally\ningen_fab test local libraries --base-dir .\n\n# Deploy to development\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n\n# Test on platform\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n</code></pre>"},{"location":"examples/#common-patterns","title":"Common Patterns","text":""},{"location":"examples/#configuration-management","title":"Configuration Management","text":"<pre><code># Using environment-specific configuration\nfrom common.config_utils import FabricConfig\n\nconfig = FabricConfig.from_environment()\nworkspace_id = config.workspace_id\nlakehouse_id = config.lakehouse_id\n</code></pre>"},{"location":"examples/#data-processing","title":"Data Processing","text":"<pre><code># Processing data with utilities\nfrom lakehouse_utils import LakehouseUtils\nfrom warehouse_utils import WarehouseUtils\n\n# Read from lakehouse\nlakehouse_utils = LakehouseUtils()\nsource_data = lakehouse_utils.read_table(\"raw.source_data\")\n\n# Process and write to warehouse\nwarehouse_utils = WarehouseUtils()\nprocessed_data = process_data(source_data)\nwarehouse_utils.write_table(\"processed.clean_data\", processed_data)\n</code></pre>"},{"location":"examples/#testing-approach","title":"Testing Approach","text":"<pre><code># Testing utilities locally\nfrom python.warehouse_utils import WarehouseUtils\n\ndef test_warehouse_connection():\n    utils = WarehouseUtils(dialect=\"sqlserver\")  # Use local SQL Server\n    assert utils.test_connection()\n\ndef test_data_processing():\n    utils = WarehouseUtils()\n    result = utils.execute_query(\"SELECT COUNT(*) FROM test_table\")\n    assert result &gt; 0\n</code></pre>"},{"location":"examples/#advanced-examples","title":"Advanced Examples","text":""},{"location":"examples/#multi-environment-deployment","title":"Multi-Environment Deployment","text":"<pre><code># Deploy to multiple environments\nfor env in development test production; do\n    echo \"Deploying to $env...\"\n    ingen_fab deploy to-environment \\\n        --fabric-workspace-repo-dir . \\\n        --fabric-environment $env\n\n    echo \"Testing $env deployment...\"\n    ingen_fab test platform notebooks \\\n        --base-dir ./fabric_workspace_items\ndone\n</code></pre>"},{"location":"examples/#custom-template-usage","title":"Custom Template Usage","text":"<pre><code># Custom DDL script with advanced features\nfrom lakehouse_utils import LakehouseUtils\nfrom warehouse_utils import WarehouseUtils\nfrom notebook_utils_abstraction import get_notebook_utils\n\n# Get environment-appropriate utilities\nnotebook_utils = get_notebook_utils()\nlakehouse_utils = LakehouseUtils()\n\n# Create complex data structure\nsql = \"\"\"\nCREATE TABLE IF NOT EXISTS analytics.fact_sales (\n    sale_id BIGINT,\n    product_id BIGINT,\n    customer_id BIGINT,\n    sale_date DATE,\n    amount DECIMAL(10,2),\n    region STRING,\n    partition_date DATE\n) USING DELTA\nPARTITIONED BY (partition_date)\nLOCATION 'Tables/analytics/fact_sales'\n\"\"\"\n\ntry:\n    ddl_utils.execute_ddl(sql, \"Create fact_sales table\")\n    notebook_utils.display(\"\u2705 Fact sales table created successfully!\")\nexcept Exception as e:\n    notebook_utils.display(f\"\u274c Error creating table: {e}\")\n    raise\n</code></pre>"},{"location":"examples/#best-practices-examples","title":"Best Practices Examples","text":""},{"location":"examples/#error-handling","title":"Error Handling","text":"<pre><code># Robust error handling in DDL scripts\nfrom ddl_utils import DDLUtils\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nddl_utils = DDLUtils()\n\ntry:\n    # Attempt DDL execution\n    ddl_utils.execute_ddl(complex_sql, \"Create complex table\")\n    logger.info(\"DDL executed successfully\")\nexcept Exception as e:\n    logger.error(f\"DDL execution failed: {e}\")\n    # Cleanup or rollback logic\n    ddl_utils.execute_ddl(rollback_sql, \"Rollback changes\")\n    raise\n</code></pre>"},{"location":"examples/#performance-optimization","title":"Performance Optimization","text":"<pre><code># Optimized data processing\nfrom pyspark.lakehouse_utils import LakehouseUtils\nfrom pyspark.parquet_load_utils import ParquetLoadUtils\n\n# Use PySpark for large data processing\nlakehouse_utils = LakehouseUtils(spark_session=spark)\nparquet_utils = ParquetLoadUtils(spark_session=spark)\n\n# Process large datasets efficiently\nlarge_df = lakehouse_utils.read_delta_table(\"raw.large_dataset\")\nprocessed_df = parquet_utils.process_parquet_data(large_df, transformations)\nlakehouse_utils.write_delta_table(processed_df, \"processed.large_dataset\")\n</code></pre>"},{"location":"examples/#configuration-driven-development","title":"Configuration-Driven Development","text":"<pre><code># Configuration-driven DDL script\nfrom common.config_utils import FabricConfig\nfrom ddl_utils import DDLUtils\n\nconfig = FabricConfig.from_environment()\nddl_utils = DDLUtils()\n\n# Use configuration to drive behavior\ntable_name = config.get_setting(\"target_table_name\")\nretention_days = config.get_setting(\"data_retention_days\", default=30)\n\nsql = f\"\"\"\nCREATE TABLE IF NOT EXISTS {table_name} (\n    id BIGINT,\n    data STRING,\n    created_date TIMESTAMP\n) USING DELTA\nTBLPROPERTIES (\n    'delta.logRetentionDuration' = 'interval {retention_days} days'\n)\n\"\"\"\n\nddl_utils.execute_ddl(sql, f\"Create {table_name} with {retention_days} day retention\")\n</code></pre>"},{"location":"examples/#troubleshooting-examples","title":"Troubleshooting Examples","text":""},{"location":"examples/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"examples/#authentication-problems","title":"Authentication Problems","text":"<pre><code># Check authentication\naz account show\n\n# Set environment variables\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n\n# Test deployment\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --dry-run\n</code></pre>"},{"location":"examples/#ddl-script-issues","title":"DDL Script Issues","text":"<pre><code># Debug DDL scripts\nfrom ddl_utils import DDLUtils\n\nddl_utils = DDLUtils()\n\n# Test SQL syntax\ntest_sql = \"SELECT 1 as test\"\ntry:\n    ddl_utils.execute_ddl(test_sql, \"Test connection\")\n    print(\"\u2705 Connection successful\")\nexcept Exception as e:\n    print(f\"\u274c Connection failed: {e}\")\n</code></pre>"},{"location":"examples/#notebook-generation-issues","title":"Notebook Generation Issues","text":"<pre><code># Check template structure\nfind ddl_scripts -name \"*.py\" -o -name \"*.sql\" | sort\n\n# Verify file naming\nls -la ddl_scripts/Lakehouses/Config/001_Initial_Setup/\n\n# Test generation\ningen_fab ddl compile-notebooks --output-mode local --generation-mode lakehouse\n</code></pre>"},{"location":"examples/#integration-examples","title":"Integration Examples","text":""},{"location":"examples/#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code># .github/workflows/fabric-deploy.yml\nname: Deploy to Fabric\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.12'\n\n    - name: Install dependencies\n      run: |\n        pip install uv\n        uv sync\n\n    - name: Generate notebooks\n      run: |\n        uv run ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\n        uv run ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n\n    - name: Deploy to staging\n      run: |\n        uv run ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment staging\n      env:\n        AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\n        AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\n        AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}\n</code></pre>"},{"location":"examples/#docker-integration","title":"Docker Integration","text":"<pre><code># Dockerfile for containerized deployment\nFROM python:3.12-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y git &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install uv\nRUN pip install uv\n\n# Copy project files\nCOPY . .\n\n# Install project dependencies\nRUN uv sync\n\n# Set entrypoint\nENTRYPOINT [\"uv\", \"run\", \"ingen_fab\"]\n</code></pre>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<p>Ready to try these examples? Start with:</p> <ol> <li>Sample Project - Complete walkthrough</li> <li>Project Templates - Customization guide</li> <li>User Guide - Comprehensive usage documentation</li> <li>Developer Guide - Architecture and development</li> </ol>"},{"location":"examples/#contributing-examples","title":"Contributing Examples","text":"<p>Have a great example to share? We welcome contributions! Please:</p> <ol> <li>Fork the repository</li> <li>Add your example to the appropriate section</li> <li>Include complete, tested code</li> <li>Add clear documentation</li> <li>Submit a pull request</li> </ol> <p>Your examples help the entire community learn and succeed with the Ingenious Fabric Accelerator!</p>"},{"location":"examples/sample_project/","title":"Sample Project Walkthrough","text":"<p>This comprehensive walkthrough demonstrates the complete workflow for managing a Microsoft Fabric workspace using the Ingenious Fabric Accelerator. The sample project includes everything you need to understand the tool's capabilities and best practices.</p>"},{"location":"examples/sample_project/#what-youll-learn","title":"What You'll Learn","text":"<p>By following this walkthrough, you'll understand:</p> <ul> <li>Complete project structure and organization</li> <li>Environment-specific variable management</li> <li>DDL script development and organization</li> <li>Notebook generation and deployment</li> <li>Testing strategies and validation</li> <li>Multi-environment deployment workflows</li> </ul>"},{"location":"examples/sample_project/#project-overview","title":"Project Overview","text":"<p>The sample project demonstrates a typical data platform setup with:</p> <ul> <li>Configuration Management: Environment-specific settings and variables</li> <li>Data Architecture: Lakehouse and warehouse implementations</li> <li>ETL Pipelines: Data extraction, transformation, and loading</li> <li>Monitoring: Logging and execution tracking</li> <li>Testing: Both local and platform testing capabilities</li> </ul>"},{"location":"examples/sample_project/#project-structure","title":"Project Structure","text":"<pre><code>sample_project/\n\u251c\u2500\u2500 ddl_scripts/              # DDL scripts for tables and configuration\n\u2502   \u251c\u2500\u2500 Lakehouses/          # Lakehouse DDL scripts\n\u2502   \u2502   \u2514\u2500\u2500 Config/          # Configuration tables\n\u2502   \u2502       \u2514\u2500\u2500 001_Initial_Creation/\n\u2502   \u2502           \u251c\u2500\u2500 001_config_parquet_loads_create.py\n\u2502   \u2502           \u251c\u2500\u2500 002_config.synapse_extract_objects.py\n\u2502   \u2502           \u251c\u2500\u2500 003_log_parquet_loads_create.py\n\u2502   \u2502           \u251c\u2500\u2500 004_log_synapse_loads_create.py\n\u2502   \u2502           \u251c\u2500\u2500 005_config_synapse_loads_insert.py\n\u2502   \u2502           \u2514\u2500\u2500 006_config_parquet_loads_insert.py\n\u2502   \u2514\u2500\u2500 Warehouses/          # Warehouse DDL scripts\n\u2502       \u2514\u2500\u2500 Config/          # Configuration tables\n\u2502           \u2514\u2500\u2500 001_Initial_Creation/\n\u2502               \u251c\u2500\u2500 001_config_parquet_loads_create.sql\n\u2502               \u251c\u2500\u2500 002_config_synapse_loads_create.sql\n\u2502               \u251c\u2500\u2500 003_log_parquet_loads_create.sql\n\u2502               \u251c\u2500\u2500 004_log_synapse_loads_create.sql\n\u2502               \u251c\u2500\u2500 005_config_synapse_loads_insert.sql\n\u2502               \u2514\u2500\u2500 006_config_parquet_loads_insert.sql\n\u251c\u2500\u2500 fabric_workspace_items/   # Generated Fabric artifacts\n\u2502   \u251c\u2500\u2500 config/              # Variable library\n\u2502   \u2502   \u2514\u2500\u2500 var_lib.VariableLibrary/\n\u2502   \u2502       \u251c\u2500\u2500 settings.json\n\u2502   \u2502       \u251c\u2500\u2500 variables.json\n\u2502   \u2502       \u2514\u2500\u2500 valueSets/\n\u2502   \u2502           \u251c\u2500\u2500 development.json\n\u2502   \u2502           \u251c\u2500\u2500 test.json\n\u2502   \u2502           \u2514\u2500\u2500 production.json\n\u2502   \u251c\u2500\u2500 ddl_scripts/         # Generated DDL notebooks\n\u2502   \u251c\u2500\u2500 extract/             # Data extraction notebooks\n\u2502   \u251c\u2500\u2500 load/                # Data loading notebooks\n\u2502   \u251c\u2500\u2500 lakehouses/          # Lakehouse definitions\n\u2502   \u251c\u2500\u2500 platform_testing/    # Platform testing notebooks\n\u2502   \u2514\u2500\u2500 warehouses/          # Warehouse definitions\n\u251c\u2500\u2500 diagrams/                # Architecture diagrams\n\u2514\u2500\u2500 platform_manifest_*.yml  # Environment-specific configurations\n</code></pre>"},{"location":"examples/sample_project/#step-by-step-walkthrough","title":"Step-by-Step Walkthrough","text":""},{"location":"examples/sample_project/#step-1-prerequisites","title":"Step 1: Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li> Microsoft Fabric workspace created</li> <li> Ingenious Fabric Accelerator installed</li> <li> Azure authentication configured</li> <li> Lakehouse and warehouse IDs available</li> </ul>"},{"location":"examples/sample_project/#step-2-environment-configuration","title":"Step 2: Environment Configuration","text":"<p>The sample project includes pre-configured environment files. Update them with your workspace details:</p> Development EnvironmentTest EnvironmentProduction Environment <pre><code>{\n  \"fabric_environment\": \"development\",\n  \"config_workspace_id\": \"your-workspace-guid\",\n  \"config_lakehouse_id\": \"your-lakehouse-guid\",\n  \"edw_workspace_id\": \"your-workspace-guid\",\n  \"edw_lakehouse_id\": \"your-lakehouse-guid\",\n  \"edw_warehouse_id\": \"your-warehouse-guid\"\n}\n</code></pre> <pre><code>{\n  \"fabric_environment\": \"test\",\n  \"config_workspace_id\": \"your-test-workspace-guid\",\n  \"config_lakehouse_id\": \"your-test-lakehouse-guid\",\n  \"edw_workspace_id\": \"your-test-workspace-guid\",\n  \"edw_lakehouse_id\": \"your-test-lakehouse-guid\",\n  \"edw_warehouse_id\": \"your-test-warehouse-guid\"\n}\n</code></pre> <pre><code>{\n  \"fabric_environment\": \"production\",\n  \"config_workspace_id\": \"your-prod-workspace-guid\",\n  \"config_lakehouse_id\": \"your-prod-lakehouse-guid\",\n  \"edw_workspace_id\": \"your-prod-workspace-guid\",\n  \"edw_lakehouse_id\": \"your-prod-lakehouse-guid\",\n  \"edw_warehouse_id\": \"your-prod-warehouse-guid\"\n}\n</code></pre>"},{"location":"examples/sample_project/#step-3-understanding-the-ddl-scripts","title":"Step 3: Understanding the DDL Scripts","text":"<p>The sample project includes comprehensive DDL scripts that demonstrate best practices:</p>"},{"location":"examples/sample_project/#lakehouse-ddl-scripts","title":"Lakehouse DDL Scripts","text":"<p>Configuration Tables Creation: <pre><code># 001_config_parquet_loads_create.py\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\n# Create parquet load configuration table\nsql_create_config = \"\"\"\nCREATE TABLE IF NOT EXISTS config.parquet_loads (\n    load_id STRING,\n    source_path STRING,\n    target_table STRING,\n    load_type STRING,\n    schedule STRING,\n    is_active BOOLEAN,\n    created_date TIMESTAMP,\n    last_updated TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/config/parquet_loads'\n\"\"\"\n\nddl_utils.execute_ddl(sql_create_config, \"Create parquet loads configuration table\")\nprint(\"\u2705 Parquet loads configuration table created\")\n</code></pre></p> <p>Logging Tables Creation: <pre><code># 003_log_parquet_loads_create.py\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\n# Create parquet load logging table\nsql_create_log = \"\"\"\nCREATE TABLE IF NOT EXISTS log.parquet_loads (\n    log_id STRING,\n    load_id STRING,\n    execution_date TIMESTAMP,\n    status STRING,\n    records_processed BIGINT,\n    execution_time_seconds DOUBLE,\n    error_message STRING,\n    created_date TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/log/parquet_loads'\n\"\"\"\n\nddl_utils.execute_ddl(sql_create_log, \"Create parquet loads logging table\")\nprint(\"\u2705 Parquet loads logging table created\")\n</code></pre></p>"},{"location":"examples/sample_project/#warehouse-ddl-scripts","title":"Warehouse DDL Scripts","text":"<p>SQL-based Configuration: <pre><code>-- 001_config_parquet_loads_create.sql\nCREATE TABLE IF NOT EXISTS config.parquet_loads (\n    load_id NVARCHAR(50) NOT NULL,\n    source_path NVARCHAR(500) NOT NULL,\n    target_table NVARCHAR(200) NOT NULL,\n    load_type NVARCHAR(20) NOT NULL,\n    schedule NVARCHAR(100),\n    is_active BIT NOT NULL DEFAULT 1,\n    created_date DATETIME2 NOT NULL DEFAULT GETDATE(),\n    last_updated DATETIME2 NOT NULL DEFAULT GETDATE(),\n    PRIMARY KEY (load_id)\n);\n</code></pre></p>"},{"location":"examples/sample_project/#step-4-generate-ddl-notebooks","title":"Step 4: Generate DDL Notebooks","text":"<p>Transform the DDL scripts into executable notebooks:</p> <pre><code># Navigate to the project root\ncd sample_project\n\n# Generate DDL notebooks for warehouses\ningen_fab ddl compile-notebooks \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development \\\n    --output-mode fabric \\\n    --generation-mode warehouse\n\n# Generate DDL notebooks for lakehouses\ningen_fab ddl compile-notebooks \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development \\\n    --output-mode fabric \\\n    --generation-mode lakehouse\n</code></pre> <p>This generates several types of notebooks:</p> <p>Individual DDL Notebooks: - One notebook per DDL script - Includes error handling and logging - Environment-specific variable substitution</p> <p>Orchestrator Notebooks: - <code>00_orchestrator_Config_lakehouse.Notebook</code> - Runs all lakehouse DDL scripts - <code>00_orchestrator_Config_warehouse.Notebook</code> - Runs all warehouse DDL scripts - <code>00_all_lakehouses_orchestrator.Notebook</code> - Master orchestrator for all lakehouses - <code>00_all_warehouses_orchestrator.Notebook</code> - Master orchestrator for all warehouses</p>"},{"location":"examples/sample_project/#step-5-deploy-to-fabric","title":"Step 5: Deploy to Fabric","text":"<p>Deploy the complete solution to your Fabric workspace:</p> <pre><code># Deploy all artifacts to development environment\ningen_fab deploy to-environment \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development\n</code></pre> <p>This deployment includes: - Variable library with environment-specific configurations - All generated DDL notebooks - Data extraction and loading notebooks - Platform testing notebooks - Lakehouse and warehouse definitions</p>"},{"location":"examples/sample_project/#step-6-execute-ddl-scripts","title":"Step 6: Execute DDL Scripts","text":"<p>Navigate to your Fabric workspace and execute the DDL scripts:</p> <ol> <li>Open your Fabric workspace</li> <li>Navigate to the <code>ddl_scripts</code> folder</li> <li>Run the orchestrator notebooks in sequence:</li> <li>First: <code>00_all_warehouses_orchestrator</code> (if using warehouses)</li> <li>Then: <code>00_all_lakehouses_orchestrator</code> (if using lakehouses)</li> </ol> <p>The orchestrator notebooks will: - Execute all DDL scripts in the correct order - Track execution state to prevent duplicate runs - Provide comprehensive logging and error handling - Display progress and results</p>"},{"location":"examples/sample_project/#step-7-verify-your-deployment","title":"Step 7: Verify Your Deployment","text":"<p>Test that everything is working correctly:</p> <pre><code># Test the deployment using CLI\ningen_fab test platform notebooks \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development\n</code></pre> <p>Or run the platform testing notebooks directly in Fabric: - <code>platform_testing/python_platform_test.Notebook</code> - <code>platform_testing/pyspark_platform_test.Notebook</code></p>"},{"location":"examples/sample_project/#step-8-explore-the-data-architecture","title":"Step 8: Explore the Data Architecture","text":"<p>Once deployed, you'll have the following data architecture:</p>"},{"location":"examples/sample_project/#configuration-schema","title":"Configuration Schema","text":"<ul> <li><code>config.parquet_loads</code> - Parquet loading configuration</li> <li><code>config.synapse_extract_objects</code> - Synapse extraction settings</li> <li><code>config.synapse_loads</code> - Synapse loading configuration</li> </ul>"},{"location":"examples/sample_project/#logging-schema","title":"Logging Schema","text":"<ul> <li><code>log.parquet_loads</code> - Parquet loading execution logs</li> <li><code>log.synapse_loads</code> - Synapse loading execution logs</li> </ul>"},{"location":"examples/sample_project/#sample-data-flow","title":"Sample Data Flow","text":"<pre><code>graph LR\n    A[Source Data] --&gt; B[Extract Notebook]\n    B --&gt; C[Lakehouse Storage]\n    C --&gt; D[Transform Notebook]\n    D --&gt; E[Warehouse Tables]\n    E --&gt; F[Analytics]\n\n    G[Configuration] --&gt; B\n    G --&gt; D\n    H[Logging] --&gt; B\n    H --&gt; D</code></pre>"},{"location":"examples/sample_project/#key-features-demonstrated","title":"Key Features Demonstrated","text":""},{"location":"examples/sample_project/#1-environment-specific-configuration","title":"1. Environment-Specific Configuration","text":"<p>The sample shows how to manage multiple environments:</p> <ul> <li>Development: For development and testing</li> <li>Test: For integration testing</li> <li>Production: For live production workloads</li> </ul> <p>Each environment has its own variable set with appropriate workspace and resource IDs.</p>"},{"location":"examples/sample_project/#2-ddl-script-organization","title":"2. DDL Script Organization","text":"<p>The project demonstrates best practices for DDL script organization:</p> <ul> <li>Numbered Sequences: Scripts execute in order (001_, 002_, etc.)</li> <li>Logical Grouping: Related scripts are grouped in folders</li> <li>Mixed Languages: Both Python and SQL scripts are supported</li> <li>Idempotent Operations: Scripts can be run multiple times safely</li> </ul>"},{"location":"examples/sample_project/#3-comprehensive-logging","title":"3. Comprehensive Logging","text":"<p>Every operation is logged with:</p> <ul> <li>Execution Status: Success or failure</li> <li>Timing Information: Execution duration</li> <li>Error Details: Detailed error messages when failures occur</li> <li>Audit Trail: Who, what, when for all operations</li> </ul>"},{"location":"examples/sample_project/#4-testing-framework","title":"4. Testing Framework","text":"<p>The sample includes multiple levels of testing:</p> <ul> <li>Local Testing: Test libraries and logic locally</li> <li>Platform Testing: Validate deployment on Fabric</li> <li>Integration Testing: End-to-end workflow validation</li> </ul>"},{"location":"examples/sample_project/#5-data-pipeline-configuration","title":"5. Data Pipeline Configuration","text":"<p>Configuration-driven data pipelines:</p> <ul> <li>Parquet Processing: Configurable parquet file processing</li> <li>Synapse Integration: Legacy Synapse data source integration</li> <li>Flexible Scheduling: Configurable execution schedules</li> <li>Error Handling: Comprehensive error handling and recovery</li> </ul>"},{"location":"examples/sample_project/#customization-guide","title":"Customization Guide","text":""},{"location":"examples/sample_project/#adding-new-ddl-scripts","title":"Adding New DDL Scripts","text":"<ol> <li> <p>Create new script file:    <pre><code># ddl_scripts/Lakehouses/Config/001_Initial_Creation/007_new_table_create.py\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\nsql = \"\"\"\nCREATE TABLE IF NOT EXISTS config.new_table (\n    id BIGINT,\n    name STRING,\n    created_date TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/config/new_table'\n\"\"\"\n\nddl_utils.execute_ddl(sql, \"Create new table\")\nprint(\"\u2705 New table created successfully\")\n</code></pre></p> </li> <li> <p>Regenerate notebooks:    <pre><code>ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n</code></pre></p> </li> <li> <p>Redeploy:    <pre><code>ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n</code></pre></p> </li> </ol>"},{"location":"examples/sample_project/#adding-new-environments","title":"Adding New Environments","text":"<ol> <li> <p>Create new variable set:    <pre><code># fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/staging.json\n{\n  \"fabric_environment\": \"staging\",\n  \"config_workspace_id\": \"staging-workspace-guid\",\n  \"config_lakehouse_id\": \"staging-lakehouse-guid\"\n}\n</code></pre></p> </li> <li> <p>Create platform manifest:    <pre><code># platform_manifest_staging.yml\nenvironment: staging\nworkspace_id: staging-workspace-guid\n# ... other staging-specific settings\n</code></pre></p> </li> <li> <p>Deploy to new environment:    <pre><code>ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment staging\n</code></pre></p> </li> </ol>"},{"location":"examples/sample_project/#advanced-usage","title":"Advanced Usage","text":""},{"location":"examples/sample_project/#multi-project-setup","title":"Multi-Project Setup","text":"<p>Use the sample as a template for multiple projects:</p> <pre><code># Create multiple projects based on the sample\nfor project in analytics ml-platform reporting; do\n    cp -r sample_project $project\n    cd $project\n    # Update configuration for specific project\n    vim fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/development.json\n    cd ..\ndone\n</code></pre>"},{"location":"examples/sample_project/#cicd-integration","title":"CI/CD Integration","text":"<p>Integrate with CI/CD pipelines:</p> <pre><code># .github/workflows/deploy.yml\nname: Deploy Sample Project\n\non:\n  push:\n    branches: [ main ]\n    paths: [ 'sample_project/**' ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.12'\n\n    - name: Install dependencies\n      run: |\n        pip install uv\n        uv sync\n\n    - name: Deploy sample project\n      run: |\n        cd sample_project\n        uv run ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\n        uv run ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n        uv run ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n      env:\n        AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\n        AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\n        AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}\n</code></pre>"},{"location":"examples/sample_project/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/sample_project/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Authentication Errors:    <pre><code># Check Azure authentication\naz account show\n\n# Or use environment variables\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n</code></pre></p> </li> <li> <p>Variable Resolution Issues:    <pre><code># Verify variable files exist and are valid JSON\ncat fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/development.json | jq .\n\n# Test variable injection\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --dry-run\n</code></pre></p> </li> <li> <p>DDL Script Failures:</p> </li> <li>Check workspace and lakehouse IDs are correct</li> <li>Verify DDL script syntax</li> <li>Review execution logs in Fabric notebook output</li> </ol>"},{"location":"examples/sample_project/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Review the User Guide for detailed command usage</li> <li>CLI Help: Use <code>ingen_fab --help</code> for command-specific help</li> <li>Examples: Check other examples in this section</li> <li>Issues: Report problems on GitHub Issues</li> </ul>"},{"location":"examples/sample_project/#next-steps","title":"Next Steps","text":"<p>Now that you've explored the sample project:</p> <ol> <li>Customize it for your specific use case</li> <li>Create your own project using the patterns you've learned</li> <li>Explore advanced features in the Developer Guide</li> <li>Learn about Python libraries that power the functionality</li> <li>Contribute back by sharing your own examples and improvements</li> </ol> <p>The sample project provides a solid foundation for building sophisticated data platforms with the Ingenious Fabric Accelerator. Use it as a starting point for your own projects and adapt the patterns to meet your specific requirements.</p>"},{"location":"examples/templates/","title":"Project Templates","text":""},{"location":"examples/templates/#overview","title":"Overview","text":"<p>The Ingenious Fabric Accelerator provides a comprehensive set of project templates to help you quickly bootstrap new Microsoft Fabric projects. These templates include pre-configured workspace items, DDL scripts, and common patterns for data processing workflows.</p>"},{"location":"examples/templates/#available-templates","title":"Available Templates","text":""},{"location":"examples/templates/#basic-project-template","title":"Basic Project Template","text":"<p>A minimal project structure with essential components:</p> <pre><code>project_templates/\n\u251c\u2500\u2500 ddl_scripts/           # DDL generation scripts\n\u251c\u2500\u2500 fabric_workspace_items/ # Fabric workspace definitions\n\u251c\u2500\u2500 README.md             # Project documentation\n\u2514\u2500\u2500 .gitignore           # Git ignore patterns\n</code></pre>"},{"location":"examples/templates/#data-warehouse-template","title":"Data Warehouse Template","text":"<p>Complete template for building data warehouses:</p> <pre><code>project_templates/\n\u251c\u2500\u2500 ddl_scripts/\n\u2502   \u251c\u2500\u2500 Warehouses/\n\u2502   \u2502   \u2514\u2500\u2500 EDW/\n\u2502   \u2502       \u2514\u2500\u2500 001_Initial_Creation/\n\u2502   \u2514\u2500\u2500 Lakehouses/\n\u2502       \u2514\u2500\u2500 Config/\n\u2502           \u2514\u2500\u2500 001_Initial_Creation/\n\u251c\u2500\u2500 fabric_workspace_items/\n\u2502   \u251c\u2500\u2500 warehouses/\n\u2502   \u2502   \u2514\u2500\u2500 EDW.Warehouse/\n\u2502   \u2514\u2500\u2500 lakehouses/\n\u2502       \u2514\u2500\u2500 config.Lakehouse/\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 variables.json\n</code></pre>"},{"location":"examples/templates/#etl-pipeline-template","title":"ETL Pipeline Template","text":"<p>Template for data extraction, transformation, and loading:</p> <pre><code>project_templates/\n\u251c\u2500\u2500 extract/\n\u2502   \u251c\u2500\u2500 extract_from_synapse.Notebook/\n\u2502   \u2514\u2500\u2500 extract_pipeline.DataPipeline/\n\u251c\u2500\u2500 transform/\n\u2502   \u251c\u2500\u2500 data_transformation.Notebook/\n\u2502   \u2514\u2500\u2500 validation_rules.Notebook/\n\u251c\u2500\u2500 load/\n\u2502   \u2514\u2500\u2500 load_to_warehouse.Notebook/\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 pipeline_config.json\n</code></pre>"},{"location":"examples/templates/#using-templates","title":"Using Templates","text":""},{"location":"examples/templates/#initialize-new-project","title":"Initialize New Project","text":"<pre><code># Create new project from template\ningen_fab init --template basic --name my_project\n\n# Create with specific template\ningen_fab init --template data-warehouse --name analytics_project\n</code></pre>"},{"location":"examples/templates/#custom-template-creation","title":"Custom Template Creation","text":"<pre><code># Create custom template\nmkdir my_custom_template\ncd my_custom_template\n\n# Set up template structure\nmkdir -p ddl_scripts/Warehouses/MyWarehouse/001_Initial_Creation\nmkdir -p fabric_workspace_items/warehouses\nmkdir -p config\n</code></pre>"},{"location":"examples/templates/#template-structure","title":"Template Structure","text":""},{"location":"examples/templates/#ddl-scripts","title":"DDL Scripts","text":"<p>Templates include pre-configured DDL scripts:</p> <pre><code># ddl_scripts/Warehouses/Config/001_Initial_Creation/001_config_tables.py\nfrom ddl_utils import create_table\n\n# Configuration tables\ncreate_table(\n    schema_name='config',\n    table_name='extraction_log',\n    columns=[\n        {'name': 'id', 'type': 'BIGINT', 'nullable': False},\n        {'name': 'source_system', 'type': 'STRING', 'nullable': False},\n        {'name': 'extraction_date', 'type': 'TIMESTAMP', 'nullable': False},\n        {'name': 'status', 'type': 'STRING', 'nullable': False}\n    ]\n)\n</code></pre>"},{"location":"examples/templates/#fabric-workspace-items","title":"Fabric Workspace Items","text":"<p>Templates provide workspace item definitions:</p> <pre><code>{\n  \"type\": \"Warehouse\",\n  \"displayName\": \"EDW\",\n  \"description\": \"Enterprise Data Warehouse\"\n}\n</code></pre>"},{"location":"examples/templates/#configuration-files","title":"Configuration Files","text":"<p>Templates include configuration for different environments:</p> <pre><code>{\n  \"environments\": {\n    \"development\": {\n      \"workspace_id\": \"dev-workspace-id\",\n      \"database_name\": \"dev_edw\"\n    },\n    \"production\": {\n      \"workspace_id\": \"prod-workspace-id\",\n      \"database_name\": \"prod_edw\"\n    }\n  }\n}\n</code></pre>"},{"location":"examples/templates/#template-customization","title":"Template Customization","text":""},{"location":"examples/templates/#variables-and-substitution","title":"Variables and Substitution","text":"<p>Templates support variable substitution:</p> <pre><code># Template with variables\nDATABASE_NAME = \"{{ database_name }}\"\nSCHEMA_NAME = \"{{ schema_name }}\"\n\n# Configuration\n{\n  \"database_name\": \"my_warehouse\",\n  \"schema_name\": \"analytics\"\n}\n</code></pre>"},{"location":"examples/templates/#conditional-logic","title":"Conditional Logic","text":"<p>Templates can include conditional content:</p>"},{"location":"examples/templates/#template-inheritance","title":"Template Inheritance","text":"<p>Templates can extend base templates:</p> <pre><code># base_warehouse.py\nclass BaseWarehouse:\n    def __init__(self):\n        self.connection = get_connection()\n\n    def create_schema(self, schema_name):\n        \"\"\"Base schema creation\"\"\"\n        pass\n\n# custom_warehouse.py\nclass CustomWarehouse(BaseWarehouse):\n    def create_analytics_schema(self):\n        \"\"\"Custom analytics schema\"\"\"\n        self.create_schema('analytics')\n</code></pre>"},{"location":"examples/templates/#template-development","title":"Template Development","text":""},{"location":"examples/templates/#creating-custom-templates","title":"Creating Custom Templates","text":"<ol> <li>Define structure: Create directory structure</li> <li>Add templates: Create Jinja2 templates</li> <li>Configure variables: Define template variables</li> <li>Add documentation: Include README and examples</li> <li>Test templates: Validate template generation</li> </ol>"},{"location":"examples/templates/#template-validation","title":"Template Validation","text":"<pre><code># validate_template.py\nfrom jinja2 import Template\nimport json\n\ndef validate_template(template_path, variables):\n    \"\"\"Validate template can be rendered\"\"\"\n    with open(template_path, 'r') as f:\n        template = Template(f.read())\n\n    try:\n        result = template.render(**variables)\n        return True, result\n    except Exception as e:\n        return False, str(e)\n</code></pre>"},{"location":"examples/templates/#best-practices","title":"Best Practices","text":"<ol> <li>Use meaningful names: Template and variable names should be descriptive</li> <li>Include documentation: Add comments and README files</li> <li>Provide examples: Include sample configurations</li> <li>Test thoroughly: Validate templates in different environments</li> <li>Version control: Track template changes</li> </ol>"},{"location":"examples/templates/#template-categories","title":"Template Categories","text":""},{"location":"examples/templates/#data-engineering","title":"Data Engineering","text":"<p>Templates for data processing workflows:</p> <ul> <li>Bronze/Silver/Gold: Medallion architecture patterns</li> <li>Batch Processing: Scheduled data processing</li> <li>Stream Processing: Real-time data ingestion</li> <li>Data Quality: Validation and monitoring</li> </ul>"},{"location":"examples/templates/#analytics","title":"Analytics","text":"<p>Templates for analytics workloads:</p> <ul> <li>Reporting: Standard report templates</li> <li>Dashboards: Interactive dashboard patterns</li> <li>Data Science: ML and AI workflows</li> <li>Business Intelligence: BI solution templates</li> </ul>"},{"location":"examples/templates/#integration","title":"Integration","text":"<p>Templates for system integration:</p> <ul> <li>API Integration: REST API connectors</li> <li>Database Sync: Database synchronization</li> <li>File Processing: File ingestion patterns</li> <li>Event Processing: Event-driven architectures</li> </ul>"},{"location":"examples/templates/#configuration-management","title":"Configuration Management","text":""},{"location":"examples/templates/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<pre><code>{\n  \"environments\": {\n    \"local\": {\n      \"database_server\": \"localhost\",\n      \"authentication\": \"integrated\"\n    },\n    \"development\": {\n      \"database_server\": \"dev-sql-server\",\n      \"authentication\": \"service_principal\"\n    },\n    \"production\": {\n      \"database_server\": \"prod-sql-server\",\n      \"authentication\": \"service_principal\"\n    }\n  }\n}\n</code></pre>"},{"location":"examples/templates/#variable-libraries","title":"Variable Libraries","text":"<p>Templates integrate with variable libraries:</p> <pre><code>from variable_lib import get_variable\n\n# Get environment-specific variables\ndatabase_name = get_variable('database_name')\nconnection_string = get_variable('connection_string')\n</code></pre>"},{"location":"examples/templates/#deployment","title":"Deployment","text":""},{"location":"examples/templates/#template-deployment","title":"Template Deployment","text":"<pre><code># Deploy template to environment\ningen_fab deploy --template my_template --environment production\n\n# Deploy with variable overrides\ningen_fab deploy --template my_template --environment production --vars database_name=prod_db\n</code></pre>"},{"location":"examples/templates/#cicd-integration","title":"CI/CD Integration","text":"<p>Templates can be deployed through CI/CD pipelines:</p> <pre><code># azure-pipelines.yml\n- task: PythonScript@0\n  displayName: 'Deploy Template'\n  inputs:\n    scriptSource: 'inline'\n    script: |\n      import subprocess\n      subprocess.run(['ingen_fab', 'deploy', '--template', 'analytics', '--environment', 'production'])\n</code></pre>"},{"location":"examples/templates/#examples","title":"Examples","text":""},{"location":"examples/templates/#sample-project-structure","title":"Sample Project Structure","text":"<pre><code>my_analytics_project/\n\u251c\u2500\u2500 ddl_scripts/\n\u2502   \u251c\u2500\u2500 Warehouses/\n\u2502   \u2502   \u2514\u2500\u2500 Analytics/\n\u2502   \u2502       \u2514\u2500\u2500 001_Initial_Creation/\n\u2502   \u2502           \u251c\u2500\u2500 001_fact_tables.sql\n\u2502   \u2502           \u251c\u2500\u2500 002_dimension_tables.sql\n\u2502   \u2502           \u2514\u2500\u2500 003_views.sql\n\u2502   \u2514\u2500\u2500 Lakehouses/\n\u2502       \u2514\u2500\u2500 RawData/\n\u2502           \u2514\u2500\u2500 001_Initial_Creation/\n\u2502               \u251c\u2500\u2500 001_source_tables.py\n\u2502               \u2514\u2500\u2500 002_staging_tables.py\n\u251c\u2500\u2500 fabric_workspace_items/\n\u2502   \u251c\u2500\u2500 warehouses/\n\u2502   \u2502   \u2514\u2500\u2500 Analytics.Warehouse/\n\u2502   \u2502       \u2514\u2500\u2500 .platform\n\u2502   \u251c\u2500\u2500 lakehouses/\n\u2502   \u2502   \u2514\u2500\u2500 RawData.Lakehouse/\n\u2502   \u2502       \u2514\u2500\u2500 .platform\n\u2502   \u2514\u2500\u2500 notebooks/\n\u2502       \u251c\u2500\u2500 data_extraction.Notebook/\n\u2502       \u2514\u2500\u2500 data_transformation.Notebook/\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 variables.json\n\u2502   \u2514\u2500\u2500 environment_config.json\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"examples/templates/#template-usage-examples","title":"Template Usage Examples","text":"<pre><code># Using template in notebook\nfrom template_utils import load_template\n\n# Load and render template\ntemplate = load_template('data_extraction')\nnotebook_content = template.render(\n    source_system='salesforce',\n    target_table='raw_contacts',\n    environment='production'\n)\n\n# Execute generated content\nexec(notebook_content)\n</code></pre>"},{"location":"examples/templates/#integration-with-fabric","title":"Integration with Fabric","text":""},{"location":"examples/templates/#workspace-integration","title":"Workspace Integration","text":"<p>Templates integrate with Fabric workspaces:</p> <pre><code>from fabric_api import FabricWorkspace\n\nworkspace = FabricWorkspace(workspace_id)\n\n# Deploy template items to workspace\nfor item in template.get_workspace_items():\n    workspace.create_item(item)\n</code></pre>"},{"location":"examples/templates/#pipeline-integration","title":"Pipeline Integration","text":"<p>Templates can be used in data pipelines:</p> <pre><code># Pipeline activity using template\n{\n    \"name\": \"ExecuteTemplate\",\n    \"type\": \"ExecuteNotebook\",\n    \"typeProperties\": {\n        \"notebook\": {\n            \"referenceName\": \"{{ template_name }}\",\n            \"type\": \"NotebookReference\"\n        },\n        \"parameters\": {\n            \"source_table\": \"{{ source_table }}\",\n            \"target_table\": \"{{ target_table }}\"\n        }\n    }\n}\n</code></pre>"},{"location":"examples/templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/templates/#common-issues","title":"Common Issues","text":"<ol> <li>Template not found: Check template path and naming</li> <li>Variable errors: Verify all required variables are provided</li> <li>Rendering failures: Check Jinja2 template syntax</li> <li>Deployment errors: Verify workspace permissions</li> </ol>"},{"location":"examples/templates/#debugging","title":"Debugging","text":"<pre><code># Debug template rendering\nfrom template_utils import debug_template\n\ndebug_info = debug_template(\n    template_name='my_template',\n    variables={'key': 'value'}\n)\nprint(debug_info)\n</code></pre>"},{"location":"examples/templates/#resources","title":"Resources","text":"<ul> <li>DDL Scripts - Template system details</li> <li>Notebook Utils - Notebook integration</li> <li>Sample Project - Complete project example</li> <li>CLI Reference - Command-line usage</li> </ul>"},{"location":"user_guide/","title":"User Guide","text":"<p>Welcome to the Ingenious Fabric Accelerator User Guide! This section provides comprehensive information on how to use the tool effectively for your Microsoft Fabric projects.</p>"},{"location":"user_guide/#what-youll-learn","title":"What You'll Learn","text":"<p>This guide covers everything you need to know to get started and become proficient with the Ingenious Fabric Accelerator:</p>"},{"location":"user_guide/#installation","title":"Installation","text":"<ul> <li>System requirements</li> <li>Installation methods</li> <li>Environment setup</li> <li>Verification steps</li> </ul>"},{"location":"user_guide/#quick-start","title":"Quick Start","text":"<ul> <li>Your first project</li> <li>Basic commands</li> <li>Common workflows</li> <li>Tips for success</li> </ul>"},{"location":"user_guide/#cli-reference","title":"CLI Reference","text":"<ul> <li>Complete command reference</li> <li>Options and parameters</li> <li>Usage examples</li> <li>Best practices</li> </ul>"},{"location":"user_guide/#workflows","title":"Workflows","text":"<ul> <li>Development workflow</li> <li>Deployment strategies</li> <li>Testing approaches</li> <li>Troubleshooting</li> </ul>"},{"location":"user_guide/#prerequisites","title":"Prerequisites","text":"<p>Before using the Ingenious Fabric Accelerator, ensure you have:</p> <ul> <li>Python 3.12 or higher</li> <li>Access to a Microsoft Fabric workspace</li> <li>Basic understanding of SQL and Python</li> <li>Familiarity with command-line tools</li> </ul>"},{"location":"user_guide/#getting-help","title":"Getting Help","text":"<p>If you need assistance:</p> <ol> <li>Check this documentation - Most questions are answered here</li> <li>Use the built-in help - Run <code>ingen_fab --help</code> for command-specific help</li> <li>Review examples - Check the Examples section</li> <li>Report issues - Use GitHub Issues for bugs</li> </ol>"},{"location":"user_guide/#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> Installation</p> <p>Get up and running quickly</p> <p> Install Now</p> </li> <li> <p> Quick Start</p> <p>Your first project in minutes</p> <p> Start Here</p> </li> <li> <p> CLI Reference</p> <p>Complete command documentation</p> <p> Commands</p> </li> <li> <p>:material-workflow:{ .lg .middle } Workflows</p> <p>Best practices and patterns</p> <p> Workflows</p> </li> </ul>"},{"location":"user_guide/cli_reference/","title":"CLI Reference","text":"<p>Complete reference for all Ingenious Fabric Accelerator commands, options, and usage patterns.</p>"},{"location":"user_guide/cli_reference/#global-options","title":"Global Options","text":"<p>These options are available for all commands:</p> <pre><code>ingen_fab [GLOBAL_OPTIONS] COMMAND [COMMAND_OPTIONS]\n</code></pre> Option Description Environment Variable <code>--fabric-workspace-repo-dir</code> Directory containing fabric workspace repository files <code>FABRIC_WORKSPACE_REPO_DIR</code> <code>--fabric-environment</code> Target environment (development, test, production) <code>FABRIC_ENVIRONMENT</code> <code>--help</code> Show help message - <code>--version</code> Show version information -"},{"location":"user_guide/cli_reference/#command-groups","title":"Command Groups","text":""},{"location":"user_guide/cli_reference/#init","title":"init","text":"<p>Initialize solutions and projects.</p>"},{"location":"user_guide/cli_reference/#init-solution","title":"<code>init solution</code>","text":"<p>Create a new Fabric workspace project with proper structure.</p> <pre><code>ingen_fab init solution --project-name \"My Project\"\n</code></pre> <p>Options: - <code>--project-name</code> (required): Name of the project - <code>--template-dir</code>: Custom template directory (default: built-in templates) - <code>--force</code>: Overwrite existing files</p> <p>Examples: <pre><code># Create a new project\ningen_fab init solution --project-name \"Data Analytics Platform\"\n\n# Create project with custom template\ningen_fab init solution --project-name \"ML Pipeline\" --template-dir ./custom-templates\n\n# Force overwrite existing project\ningen_fab init solution --project-name \"Existing Project\" --force\n</code></pre></p>"},{"location":"user_guide/cli_reference/#ddl","title":"ddl","text":"<p>Compile DDL notebooks from templates.</p>"},{"location":"user_guide/cli_reference/#ddl-compile-notebooks","title":"<code>ddl compile-notebooks</code>","text":"<p>Generate DDL notebooks from SQL and Python scripts.</p> <pre><code>ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\n</code></pre> <p>Options: - <code>--output-mode</code>: Output destination (<code>fabric</code>, <code>local</code>) - <code>--generation-mode</code>: Target platform (<code>warehouse</code>, <code>lakehouse</code>) - <code>--force</code>: Overwrite existing notebooks</p> <p>Examples: <pre><code># Generate warehouse notebooks for Fabric deployment\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\n\n# Generate lakehouse notebooks locally\ningen_fab ddl compile-notebooks --output-mode local --generation-mode lakehouse\n\n# Force regeneration of all notebooks\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse --force\n</code></pre></p>"},{"location":"user_guide/cli_reference/#deploy","title":"deploy","text":"<p>Deploy to environments and manage workspace items.</p>"},{"location":"user_guide/cli_reference/#deploy-to-environment","title":"<code>deploy to-environment</code>","text":"<p>Deploy all artifacts to a specific environment.</p> <pre><code>ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n</code></pre> <p>Options: - <code>--fabric-workspace-repo-dir</code>: Source directory for deployment - <code>--fabric-environment</code>: Target environment - <code>--dry-run</code>: Show what would be deployed without actually deploying - <code>--force</code>: Force deployment even if validation fails</p> <p>Examples: <pre><code># Deploy to development\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n\n# Dry run deployment\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production --dry-run\n\n# Force deployment\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment test --force\n</code></pre></p>"},{"location":"user_guide/cli_reference/#notebook","title":"notebook","text":"<p>Manage and scan notebook content.</p>"},{"location":"user_guide/cli_reference/#notebook-find-content-files","title":"<code>notebook find-content-files</code>","text":"<p>Find all notebook-content.py files in a directory.</p> <pre><code>ingen_fab notebook find-content-files --base-dir ./fabric_workspace_items\n</code></pre>"},{"location":"user_guide/cli_reference/#notebook-scan-blocks","title":"<code>notebook scan-blocks</code>","text":"<p>Scan and analyze notebook code blocks.</p> <pre><code>ingen_fab notebook scan-blocks --base-dir ./fabric_workspace_items\n</code></pre> <p>Options: - <code>--base-dir</code>: Directory to scan - <code>--output-format</code>: Output format (<code>json</code>, <code>table</code>, <code>summary</code>) - <code>--include-patterns</code>: File patterns to include - <code>--exclude-patterns</code>: File patterns to exclude</p> <p>Examples: <pre><code># Find all notebook files\ningen_fab notebook find-content-files --base-dir ./fabric_workspace_items\n\n# Scan blocks with JSON output\ningen_fab notebook scan-blocks --base-dir ./fabric_workspace_items --output-format json\n\n# Scan specific patterns\ningen_fab notebook scan-blocks --base-dir ./fabric_workspace_items --include-patterns \"*.py\"\n</code></pre></p>"},{"location":"user_guide/cli_reference/#test","title":"test","text":"<p>Test notebooks and Python blocks.</p>"},{"location":"user_guide/cli_reference/#test-local","title":"<code>test local</code>","text":"<p>Test components locally.</p> <pre><code># Test libraries\ningen_fab test local libraries --base-dir .\n\n# Test notebooks\ningen_fab test local notebooks --base-dir ./fabric_workspace_items\n</code></pre>"},{"location":"user_guide/cli_reference/#test-platform","title":"<code>test platform</code>","text":"<p>Test components on the Fabric platform.</p> <pre><code># Test notebooks on platform\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n</code></pre> <p>Options: - <code>--base-dir</code>: Directory containing tests - <code>--test-pattern</code>: Pattern to match test files - <code>--verbose</code>: Show detailed output - <code>--failfast</code>: Stop on first failure</p> <p>Examples: <pre><code># Test all libraries locally\ningen_fab test local libraries --base-dir . --verbose\n\n# Test specific pattern\ningen_fab test local notebooks --base-dir ./fabric_workspace_items --test-pattern \"*test*\"\n\n# Test on platform with fail-fast\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items --failfast\n</code></pre></p>"},{"location":"user_guide/cli_reference/#configuration","title":"Configuration","text":""},{"location":"user_guide/cli_reference/#environment-variables","title":"Environment Variables","text":"<p>Set these to avoid specifying options repeatedly:</p> <pre><code># Core configuration\nexport FABRIC_WORKSPACE_REPO_DIR=\"./sample_project\"\nexport FABRIC_ENVIRONMENT=\"development\"\n\n# Authentication\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n\n# Optional: SQL Server for local testing\nexport SQL_SERVER_SA_PASSWORD=\"YourStrong!Passw0rd\"\n</code></pre>"},{"location":"user_guide/cli_reference/#configuration-files","title":"Configuration Files","text":"<p>The tool looks for configuration in: 1. <code>platform_manifest_*.yml</code> files in your project root 2. Variable library files in <code>fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/</code> 3. Environment variables</p>"},{"location":"user_guide/cli_reference/#common-usage-patterns","title":"Common Usage Patterns","text":""},{"location":"user_guide/cli_reference/#development-workflow","title":"Development Workflow","text":"<pre><code># 1. Create project\ningen_fab init solution --project-name \"My Project\"\n\n# 2. Edit DDL scripts and configuration\n# ... make changes ...\n\n# 3. Generate notebooks\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n\n# 4. Test locally\ningen_fab test local libraries --base-dir .\n\n# 5. Deploy to development\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n\n# 6. Test on platform\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n</code></pre>"},{"location":"user_guide/cli_reference/#multi-environment-deployment","title":"Multi-Environment Deployment","text":"<pre><code># Deploy to different environments\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment test\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production\n</code></pre>"},{"location":"user_guide/cli_reference/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":"<pre><code># Dry run to see what would be deployed\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --dry-run\n\n# Verbose testing\ningen_fab test local libraries --base-dir . --verbose\n\n# Scan notebooks for issues\ningen_fab notebook scan-blocks --base-dir ./fabric_workspace_items --output-format json\n</code></pre>"},{"location":"user_guide/cli_reference/#error-handling","title":"Error Handling","text":""},{"location":"user_guide/cli_reference/#common-error-codes","title":"Common Error Codes","text":"Exit Code Description 0 Success 1 General error 2 Configuration error 3 Authentication error 4 Deployment error 5 Test failure"},{"location":"user_guide/cli_reference/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ol> <li>Use <code>--help</code> with any command for detailed usage</li> <li>Check environment variables if commands fail unexpectedly</li> <li>Use <code>--dry-run</code> to preview changes before deployment</li> <li>Enable verbose output with <code>--verbose</code> for debugging</li> <li>Check log files in your workspace for detailed error messages</li> </ol>"},{"location":"user_guide/cli_reference/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user_guide/cli_reference/#custom-templates","title":"Custom Templates","text":"<pre><code># Use custom project templates\ningen_fab init solution --project-name \"Custom Project\" --template-dir ./my-templates\n</code></pre>"},{"location":"user_guide/cli_reference/#batch-operations","title":"Batch Operations","text":"<pre><code># Process multiple environments\nfor env in development test production; do\n    ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment $env\ndone\n</code></pre>"},{"location":"user_guide/cli_reference/#integration-with-cicd","title":"Integration with CI/CD","text":"<pre><code># CI/CD pipeline example\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse\ningen_fab test local libraries --base-dir . --failfast\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production\n</code></pre>"},{"location":"user_guide/cli_reference/#getting-help","title":"Getting Help","text":"<ul> <li>Command help: <code>ingen_fab COMMAND --help</code></li> <li>Global help: <code>ingen_fab --help</code></li> <li>Version info: <code>ingen_fab --version</code></li> <li>Documentation: This documentation site</li> <li>Issues: GitHub Issues</li> </ul>"},{"location":"user_guide/installation/","title":"Installation","text":"<p>This guide will help you install and set up the Ingenious Fabric Accelerator on your system.</p>"},{"location":"user_guide/installation/#requirements","title":"Requirements","text":"<p>Before installing, ensure your system meets these requirements:</p> <ul> <li>Python 3.12 or higher</li> <li>Git (for cloning the repository)</li> <li>Microsoft Fabric workspace (for deployment)</li> <li>Azure CLI (optional, for authentication)</li> </ul>"},{"location":"user_guide/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"user_guide/installation/#method-1-using-uv-recommended","title":"Method 1: Using uv (Recommended)","text":"<p>uv is the fastest way to install and manage Python dependencies:</p> <pre><code># Install uv if you haven't already\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Clone the repository\ngit clone https://github.com/your-org/ingen_fab.git\ncd ingen_fab\n\n# Install with uv\nuv sync\n</code></pre>"},{"location":"user_guide/installation/#method-2-using-pip","title":"Method 2: Using pip","text":"<pre><code># Clone the repository\ngit clone https://github.com/your-org/ingen_fab.git\ncd ingen_fab\n\n# Create and activate virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install the package\npip install -e .[dev]\n</code></pre>"},{"location":"user_guide/installation/#method-3-development-installation","title":"Method 3: Development Installation","text":"<p>For development work, install with all dependencies:</p> <pre><code># Using uv\nuv sync --all-extras\n\n# Using pip\npip install -e .[dev,docs,tests]\n</code></pre>"},{"location":"user_guide/installation/#environment-setup","title":"Environment Setup","text":""},{"location":"user_guide/installation/#environment-variables","title":"Environment Variables","text":"<p>Set these environment variables to avoid specifying them on each command:</p> <pre><code># Project location\nexport FABRIC_WORKSPACE_REPO_DIR=\"./sample_project\"\n\n# Target environment\nexport FABRIC_ENVIRONMENT=\"development\"\n\n# Authentication (for deployment)\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n</code></pre>"},{"location":"user_guide/installation/#shell-configuration","title":"Shell Configuration","text":"<p>Add these to your shell profile (<code>.bashrc</code>, <code>.zshrc</code>, etc.):</p> <pre><code># Add to ~/.bashrc or ~/.zshrc\nexport PATH=\"$PATH:$HOME/.local/bin\"\n\n# Optional: Create aliases\nalias ifab=\"ingen_fab\"\nalias ifab-help=\"ingen_fab --help\"\n</code></pre>"},{"location":"user_guide/installation/#verification","title":"Verification","text":"<p>Verify your installation by running:</p> <pre><code># Check version\ningen_fab --version\n\n# Display help\ningen_fab --help\n\n# Run a basic command\ningen_fab init --help\n</code></pre> <p>Expected output: <pre><code>Usage: ingen_fab [OPTIONS] COMMAND [ARGS]...\n\n  Ingenious Fabric Accelerator - A tool for managing Microsoft Fabric assets.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  init      Initialize solutions and projects\n  ddl       Compile DDL notebooks from templates\n  deploy    Deploy to environments and manage workspace items\n  notebook  Manage and scan notebook content\n  test      Test notebooks and Python blocks\n</code></pre></p>"},{"location":"user_guide/installation/#docker-installation-optional","title":"Docker Installation (Optional)","text":"<p>For containerized environments:</p> <pre><code>FROM python:3.12-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install uv\nRUN pip install uv\n\n# Copy and install application\nCOPY . /app\nWORKDIR /app\nRUN uv sync\n\n# Set entrypoint\nENTRYPOINT [\"uv\", \"run\", \"ingen_fab\"]\n</code></pre>"},{"location":"user_guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/installation/#common-issues","title":"Common Issues","text":""},{"location":"user_guide/installation/#permission-errors","title":"Permission Errors","text":"<p>If you encounter permission errors: <pre><code># Use user installation\npip install --user -e .[dev]\n\n# Or fix permissions\nsudo chown -R $USER:$USER /path/to/ingen_fab\n</code></pre></p>"},{"location":"user_guide/installation/#python-version-issues","title":"Python Version Issues","text":"<p>Check your Python version: <pre><code>python --version\n# Should show Python 3.12.x or higher\n</code></pre></p>"},{"location":"user_guide/installation/#import-errors","title":"Import Errors","text":"<p>If you get import errors: <pre><code># Reinstall in development mode\npip install -e .\n\n# Or check your PYTHONPATH\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n</code></pre></p>"},{"location":"user_guide/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"user_guide/installation/#windows","title":"Windows","text":"<ul> <li>Use PowerShell or Command Prompt</li> <li>Virtual environment activation: <code>.venv\\Scripts\\activate</code></li> <li>Path separators: Use forward slashes in commands</li> </ul>"},{"location":"user_guide/installation/#macos","title":"macOS","text":"<ul> <li>May need to install Command Line Tools: <code>xcode-select --install</code></li> <li>Use Homebrew for additional dependencies if needed</li> </ul>"},{"location":"user_guide/installation/#linux","title":"Linux","text":"<ul> <li>Install build tools: <code>sudo apt-get install build-essential</code></li> <li>Some distributions may require additional packages</li> </ul>"},{"location":"user_guide/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, you can:</p> <ol> <li>Get started quickly with your first project</li> <li>Learn the commands available</li> <li>Explore examples to see real-world usage</li> <li>Read the workflows for best practices</li> </ol>"},{"location":"user_guide/installation/#updating","title":"Updating","text":"<p>To update to the latest version:</p> <pre><code># With uv\nuv sync --upgrade\n\n# With pip\npip install --upgrade -e .[dev]\n</code></pre>"},{"location":"user_guide/installation/#uninstalling","title":"Uninstalling","text":"<p>To remove the installation:</p> <pre><code># With uv\nuv clean\n\n# With pip\npip uninstall insight-ingenious-for-fabric\n</code></pre>"},{"location":"user_guide/quick_start/","title":"Quick Start","text":"<p>Get up and running with the Ingenious Fabric Accelerator in just a few minutes! This guide will walk you through creating your first project and deploying it to Microsoft Fabric.</p>"},{"location":"user_guide/quick_start/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li> Installed the Ingenious Fabric Accelerator (Installation Guide)</li> <li> Access to a Microsoft Fabric workspace</li> <li> Basic understanding of SQL and Python</li> </ul>"},{"location":"user_guide/quick_start/#step-1-initialize-your-first-project","title":"Step 1: Initialize Your First Project","text":"<p>Create a new project directory and initialize it:</p> <pre><code># Create and navigate to your project directory\nmkdir my-fabric-project\ncd my-fabric-project\n\n# Initialize the project\ningen_fab init solution --project-name \"My First Fabric Project\"\n</code></pre> <p>This creates the following structure: <pre><code>my-fabric-project/\n\u251c\u2500\u2500 ddl_scripts/              # Your DDL scripts go here\n\u251c\u2500\u2500 fabric_workspace_items/   # Generated Fabric artifacts\n\u251c\u2500\u2500 diagrams/                 # Architecture diagrams\n\u2514\u2500\u2500 platform_manifest_*.yml  # Environment configurations\n</code></pre></p>"},{"location":"user_guide/quick_start/#step-2-configure-your-environment","title":"Step 2: Configure Your Environment","text":"<p>Edit the variable library with your Fabric workspace details:</p> <pre><code># Edit the development environment variables\nvim fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/development.json\n</code></pre> <p>Update the configuration with your workspace IDs:</p> <pre><code>{\n  \"fabric_environment\": \"development\",\n  \"config_workspace_id\": \"your-workspace-guid\",\n  \"config_lakehouse_id\": \"your-lakehouse-guid\",\n  \"edw_workspace_id\": \"your-workspace-guid\",\n  \"edw_lakehouse_id\": \"your-lakehouse-guid\",\n  \"edw_warehouse_id\": \"your-warehouse-guid\"\n}\n</code></pre> <p>Finding Your Workspace IDs</p> <p>You can find workspace and lakehouse IDs in the Microsoft Fabric portal URL when you navigate to your workspace or lakehouse.</p>"},{"location":"user_guide/quick_start/#step-3-create-your-first-ddl-script","title":"Step 3: Create Your First DDL Script","text":"<p>Create a simple DDL script to set up a configuration table:</p> <pre><code># Create the DDL script directory\nmkdir -p ddl_scripts/Lakehouses/Config/001_Initial_Setup\n\n# Create your first DDL script\ncat &gt; ddl_scripts/Lakehouses/Config/001_Initial_Setup/001_create_config_table.py &lt;&lt; 'EOF'\n# Create configuration table for the project\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\n# Initialize utilities\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\n# Create the configuration table\nsql_create_table = \"\"\"\nCREATE TABLE IF NOT EXISTS config.project_metadata (\n    id BIGINT,\n    project_name STRING,\n    environment STRING,\n    created_date TIMESTAMP,\n    last_updated TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/config/project_metadata'\n\"\"\"\n\n# Execute the DDL\nddl_utils.execute_ddl(sql_create_table, \"Create project metadata table\")\n\n# Insert initial configuration\nsql_insert_config = \"\"\"\nINSERT INTO config.project_metadata VALUES (\n    1,\n    'My First Fabric Project',\n    'development',\n    current_timestamp(),\n    current_timestamp()\n)\n\"\"\"\n\nddl_utils.execute_ddl(sql_insert_config, \"Insert initial project metadata\")\n\nprint(\"\u2705 Project configuration table created successfully!\")\nEOF\n</code></pre>"},{"location":"user_guide/quick_start/#step-4-generate-ddl-notebooks","title":"Step 4: Generate DDL Notebooks","text":"<p>Transform your DDL scripts into executable notebooks:</p> <pre><code># Generate notebooks for lakehouses\ningen_fab ddl compile-notebooks \\\n    --output-mode fabric \\\n    --generation-mode lakehouse\n\n# Generate notebooks for warehouses (if you have any)\ningen_fab ddl compile-notebooks \\\n    --output-mode fabric \\\n    --generation-mode warehouse\n</code></pre> <p>This creates orchestrator notebooks in <code>fabric_workspace_items/ddl_scripts/</code> that will: - Execute your DDL scripts in the correct order - Track execution state to prevent duplicate runs - Provide comprehensive logging and error handling</p>"},{"location":"user_guide/quick_start/#step-5-deploy-to-fabric","title":"Step 5: Deploy to Fabric","text":"<p>Deploy your project to your Fabric workspace:</p> <pre><code># Deploy to development environment\ningen_fab deploy to-environment \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development\n</code></pre> <p>Authentication Required</p> <p>Make sure you've set up your Azure credentials before deploying. You can use Azure CLI (<code>az login</code>) or environment variables.</p>"},{"location":"user_guide/quick_start/#step-6-run-your-ddl-scripts","title":"Step 6: Run Your DDL Scripts","text":"<ol> <li>Navigate to your Fabric workspace in the Microsoft Fabric portal</li> <li>Find the generated notebooks in the <code>ddl_scripts</code> folder</li> <li>Run the orchestrator notebook: <code>00_all_lakehouses_orchestrator</code></li> </ol> <p>The orchestrator will: - Execute all DDL scripts in the correct sequence - Log execution status and prevent duplicate runs - Handle errors gracefully with detailed logging</p>"},{"location":"user_guide/quick_start/#step-7-verify-your-deployment","title":"Step 7: Verify Your Deployment","text":"<p>Test that everything is working correctly:</p> <pre><code># Test your deployment\ningen_fab test platform notebooks \\\n    --fabric-workspace-repo-dir . \\\n    --fabric-environment development\n</code></pre> <p>Or run the platform testing notebooks directly in Fabric: - <code>platform_testing/python_platform_test.Notebook</code> - <code>platform_testing/pyspark_platform_test.Notebook</code></p>"},{"location":"user_guide/quick_start/#common-first-time-workflows","title":"Common First-Time Workflows","text":""},{"location":"user_guide/quick_start/#adding-more-ddl-scripts","title":"Adding More DDL Scripts","text":"<pre><code># Create a new DDL script for additional tables\ncat &gt; ddl_scripts/Lakehouses/Config/001_Initial_Setup/002_create_data_tables.py &lt;&lt; 'EOF'\n# Create additional data tables\nfrom lakehouse_utils import LakehouseUtils\nfrom ddl_utils import DDLUtils\n\nlakehouse_utils = LakehouseUtils()\nddl_utils = DDLUtils()\n\n# Create a sample data table\nsql_create_table = \"\"\"\nCREATE TABLE IF NOT EXISTS data.sample_data (\n    id BIGINT,\n    name STRING,\n    value DOUBLE,\n    created_date TIMESTAMP\n) USING DELTA\nLOCATION 'Tables/data/sample_data'\n\"\"\"\n\nddl_utils.execute_ddl(sql_create_table, \"Create sample data table\")\nprint(\"\u2705 Sample data table created successfully!\")\nEOF\n\n# Regenerate notebooks\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n\n# Redeploy\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n</code></pre>"},{"location":"user_guide/quick_start/#testing-changes-locally","title":"Testing Changes Locally","text":"<pre><code># Test your Python libraries locally\ningen_fab test local libraries --base-dir .\n\n# Test specific notebooks\ningen_fab test local notebooks --base-dir ./fabric_workspace_items\n</code></pre>"},{"location":"user_guide/quick_start/#next-steps","title":"Next Steps","text":"<p>Now that you have a working project, you can:</p> <ol> <li>Learn more commands - Explore all available CLI commands</li> <li>Study the sample project - See a complete real-world example</li> <li>Understand workflows - Learn best practices for development and deployment</li> <li>Explore Python libraries - Understand the available utilities</li> </ol>"},{"location":"user_guide/quick_start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/quick_start/#common-issues","title":"Common Issues","text":"<p>Deployment fails with authentication error: <pre><code># Set up Azure authentication\naz login\n# Or set environment variables\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n</code></pre></p> <p>DDL scripts fail to execute: - Check that your workspace and lakehouse IDs are correct - Ensure your DDL scripts have valid syntax - Review the execution logs in the Fabric notebook output</p> <p>Notebooks not generated: - Verify that your DDL scripts are in the correct directory structure - Check that file names start with numbers (001_, 002_, etc.) - Ensure scripts have proper file extensions (.py or .sql)</p>"},{"location":"user_guide/quick_start/#getting-help","title":"Getting Help","text":"<ul> <li>Use <code>ingen_fab --help</code> for command-specific help</li> <li>Check the Examples for more complex scenarios</li> <li>Review the Workflows for best practices</li> <li>Report issues on GitHub</li> </ul> <p>Congratulations!</p> <p>You've successfully created and deployed your first Fabric project! You're now ready to build more complex data solutions with the Ingenious Fabric Accelerator.</p>"},{"location":"user_guide/workflows/","title":"Workflows","text":"<p>This guide covers best practices and common workflows for using the Ingenious Fabric Accelerator effectively in your projects.</p>"},{"location":"user_guide/workflows/#development-workflow","title":"Development Workflow","text":""},{"location":"user_guide/workflows/#1-project-setup","title":"1. Project Setup","text":"<pre><code># Initialize new project\ningen_fab init solution --project-name \"Data Analytics Platform\"\n\n# Configure your environment variables\nexport FABRIC_WORKSPACE_REPO_DIR=\".\"\nexport FABRIC_ENVIRONMENT=\"development\"\n</code></pre>"},{"location":"user_guide/workflows/#2-development-cycle","title":"2. Development Cycle","text":"<pre><code>graph TD\n    A[Write DDL Scripts] --&gt; B[Generate Notebooks]\n    B --&gt; C[Test Locally]\n    C --&gt; D{Tests Pass?}\n    D --&gt;|No| A\n    D --&gt;|Yes| E[Deploy to Dev]\n    E --&gt; F[Test on Platform]\n    F --&gt; G{Platform Tests Pass?}\n    G --&gt;|No| A\n    G --&gt;|Yes| H[Deploy to Higher Environments]</code></pre> <p>Step-by-step:</p> <ol> <li> <p>Write DDL Scripts <pre><code># Create DDL scripts in numbered order\nmkdir -p ddl_scripts/Lakehouses/Config/001_Initial_Setup\nvim ddl_scripts/Lakehouses/Config/001_Initial_Setup/001_create_tables.py\n</code></pre></p> </li> <li> <p>Generate Notebooks <pre><code>ingen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse\n</code></pre></p> </li> <li> <p>Test Locally <pre><code>ingen_fab test local libraries --base-dir .\n</code></pre></p> </li> <li> <p>Deploy to Development <pre><code>ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n</code></pre></p> </li> <li> <p>Test on Platform <pre><code>ingen_fab test platform notebooks --base-dir ./fabric_workspace_items\n</code></pre></p> </li> </ol>"},{"location":"user_guide/workflows/#environment-management","title":"Environment Management","text":""},{"location":"user_guide/workflows/#environment-strategy","title":"Environment Strategy","text":"<p>Recommended environment progression:</p> <pre><code>Local Development \u2192 Development \u2192 Test \u2192 Production\n</code></pre>"},{"location":"user_guide/workflows/#environment-configuration","title":"Environment Configuration","text":"<p>Each environment should have its own configuration:</p> <pre><code>fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/\n\u251c\u2500\u2500 development.json\n\u251c\u2500\u2500 test.json\n\u2514\u2500\u2500 production.json\n</code></pre> <p>Example configuration:</p> development.jsontest.jsonproduction.json <pre><code>{\n  \"fabric_environment\": \"development\",\n  \"config_workspace_id\": \"dev-workspace-guid\",\n  \"config_lakehouse_id\": \"dev-lakehouse-guid\",\n  \"data_retention_days\": 30,\n  \"enable_debug_logging\": true\n}\n</code></pre> <pre><code>{\n  \"fabric_environment\": \"test\",\n  \"config_workspace_id\": \"test-workspace-guid\",\n  \"config_lakehouse_id\": \"test-lakehouse-guid\",\n  \"data_retention_days\": 90,\n  \"enable_debug_logging\": false\n}\n</code></pre> <pre><code>{\n  \"fabric_environment\": \"production\",\n  \"config_workspace_id\": \"prod-workspace-guid\",\n  \"config_lakehouse_id\": \"prod-lakehouse-guid\",\n  \"data_retention_days\": 365,\n  \"enable_debug_logging\": false\n}\n</code></pre>"},{"location":"user_guide/workflows/#deployment-strategy","title":"Deployment Strategy","text":"<pre><code># Deploy to development first\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n\n# Test thoroughly\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n\n# Deploy to test\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment test\n\n# Final deployment to production\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production\n</code></pre>"},{"location":"user_guide/workflows/#ddl-script-organization","title":"DDL Script Organization","text":""},{"location":"user_guide/workflows/#directory-structure","title":"Directory Structure","text":"<pre><code>ddl_scripts/\n\u251c\u2500\u2500 Lakehouses/\n\u2502   \u251c\u2500\u2500 Config/\n\u2502   \u2502   \u251c\u2500\u2500 001_Initial_Setup/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 001_create_config_tables.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 002_insert_initial_data.py\n\u2502   \u2502   \u2514\u2500\u2500 002_Schema_Updates/\n\u2502   \u2502       \u2514\u2500\u2500 001_add_new_columns.py\n\u2502   \u2514\u2500\u2500 Data/\n\u2502       \u2514\u2500\u2500 001_Initial_Setup/\n\u2502           \u2514\u2500\u2500 001_create_data_tables.py\n\u2514\u2500\u2500 Warehouses/\n    \u2514\u2500\u2500 EDW/\n        \u251c\u2500\u2500 001_Initial_Setup/\n        \u2502   \u251c\u2500\u2500 001_create_schemas.sql\n        \u2502   \u2514\u2500\u2500 002_create_tables.sql\n        \u2514\u2500\u2500 002_Data_Load/\n            \u2514\u2500\u2500 001_load_reference_data.sql\n</code></pre>"},{"location":"user_guide/workflows/#naming-conventions","title":"Naming Conventions","text":"<p>Folders: - Use descriptive names: <code>001_Initial_Setup</code>, <code>002_Schema_Updates</code> - Include version numbers for ordering - Group related scripts together</p> <p>Files: - Start with numbers: <code>001_</code>, <code>002_</code>, etc. - Use descriptive names: <code>create_config_tables.py</code> - Use appropriate extensions: <code>.py</code> for Python, <code>.sql</code> for SQL</p>"},{"location":"user_guide/workflows/#script-best-practices","title":"Script Best Practices","text":"<ol> <li> <p>Idempotent Operations <pre><code># Always use IF NOT EXISTS\nsql = \"\"\"\nCREATE TABLE IF NOT EXISTS config.metadata (\n    id BIGINT,\n    name STRING,\n    value STRING\n) USING DELTA\n\"\"\"\n</code></pre></p> </li> <li> <p>Error Handling <pre><code>try:\n    ddl_utils.execute_ddl(sql, \"Create metadata table\")\n    print(\"\u2705 Metadata table created successfully\")\nexcept Exception as e:\n    print(f\"\u274c Failed to create metadata table: {e}\")\n    raise\n</code></pre></p> </li> <li> <p>Logging <pre><code>ddl_utils.log_execution(\"001_create_config_tables.py\", \"Create configuration tables\")\n</code></pre></p> </li> </ol>"},{"location":"user_guide/workflows/#testing-strategies","title":"Testing Strategies","text":""},{"location":"user_guide/workflows/#local-testing","title":"Local Testing","text":"<p>Test your code before deploying:</p> <pre><code># Test Python libraries\ningen_fab test local libraries --base-dir .\n\n# Test specific modules\npython -m pytest ./ingen_fab/python_libs_tests/ -v\n\n# Test notebook generation\ningen_fab ddl compile-notebooks --output-mode local --generation-mode lakehouse\n</code></pre>"},{"location":"user_guide/workflows/#platform-testing","title":"Platform Testing","text":"<p>Test on Fabric platform:</p> <pre><code># Test generated notebooks\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n\n# Or run specific test notebooks in Fabric\n# - platform_testing/python_platform_test.Notebook\n# - platform_testing/pyspark_platform_test.Notebook\n</code></pre>"},{"location":"user_guide/workflows/#continuous-integration","title":"Continuous Integration","text":"<p>Example CI/CD workflow:</p> <pre><code># .github/workflows/ci.yml\nname: CI\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.12'\n\n    - name: Install dependencies\n      run: |\n        pip install uv\n        uv sync\n\n    - name: Run tests\n      run: |\n        uv run ingen_fab test local libraries --base-dir .\n\n    - name: Generate notebooks\n      run: |\n        uv run ingen_fab ddl compile-notebooks --output-mode local --generation-mode warehouse\n        uv run ingen_fab ddl compile-notebooks --output-mode local --generation-mode lakehouse\n\n    - name: Deploy to staging\n      if: github.ref == 'refs/heads/main'\n      run: |\n        uv run ingen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development\n      env:\n        AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\n        AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\n        AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}\n</code></pre>"},{"location":"user_guide/workflows/#troubleshooting-workflow","title":"Troubleshooting Workflow","text":""},{"location":"user_guide/workflows/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<ol> <li> <p>Authentication Failures <pre><code># Check Azure CLI authentication\naz account show\n\n# Or use environment variables\nexport AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n</code></pre></p> </li> <li> <p>DDL Script Failures <pre><code># Check script syntax locally\npython ddl_scripts/Lakehouses/Config/001_Initial_Setup/001_create_tables.py\n\n# Review generated notebooks\ncat fabric_workspace_items/ddl_scripts/Lakehouses/Config/001_Initial_Creation_Config_Lakehouses.Notebook/notebook-content.py\n</code></pre></p> </li> <li> <p>Variable Resolution Issues <pre><code># Verify variable files\ncat fabric_workspace_items/config/var_lib.VariableLibrary/valueSets/development.json\n\n# Test variable injection\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --dry-run\n</code></pre></p> </li> </ol>"},{"location":"user_guide/workflows/#debug-workflow","title":"Debug Workflow","text":"<pre><code># 1. Use dry-run to preview changes\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --dry-run\n\n# 2. Test locally first\ningen_fab test local libraries --base-dir . --verbose\n\n# 3. Check notebook content\ningen_fab notebook scan-blocks --base-dir ./fabric_workspace_items --output-format json\n\n# 4. Deploy with verbose output\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment development --verbose\n</code></pre>"},{"location":"user_guide/workflows/#advanced-workflows","title":"Advanced Workflows","text":""},{"location":"user_guide/workflows/#multi-project-management","title":"Multi-Project Management","text":"<pre><code># Create multiple related projects\nfor project in analytics ml-pipeline reporting; do\n    mkdir $project\n    cd $project\n    ingen_fab init solution --project-name \"$project\"\n    cd ..\ndone\n</code></pre>"},{"location":"user_guide/workflows/#shared-libraries","title":"Shared Libraries","text":"<pre><code># Create shared library project\ningen_fab init solution --project-name \"shared-libs\"\n\n# Reference shared libraries in other projects\n# Update python_libs/ to include shared components\n</code></pre>"},{"location":"user_guide/workflows/#environment-promotion","title":"Environment Promotion","text":"<pre><code># Promote from development to test\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment test\n\n# Validate in test environment\ningen_fab test platform notebooks --base-dir ./fabric_workspace_items\n\n# Promote to production\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production\n</code></pre>"},{"location":"user_guide/workflows/#best-practices","title":"Best Practices","text":""},{"location":"user_guide/workflows/#code-organization","title":"Code Organization","text":"<ul> <li>Separate concerns: Keep DDL scripts focused on single responsibilities</li> <li>Version control: Use descriptive commit messages and branch strategies</li> <li>Documentation: Include README files in each major directory</li> </ul>"},{"location":"user_guide/workflows/#development-practices","title":"Development Practices","text":"<ul> <li>Test early and often: Run local tests before platform deployment</li> <li>Use version control: Commit changes frequently with meaningful messages</li> <li>Environment parity: Keep environments as similar as possible</li> </ul>"},{"location":"user_guide/workflows/#deployment-practices","title":"Deployment Practices","text":"<ul> <li>Gradual rollout: Deploy to development first, then test, then production</li> <li>Backup strategy: Ensure you can rollback changes if needed</li> <li>Monitoring: Monitor execution logs in Fabric after deployment</li> </ul>"},{"location":"user_guide/workflows/#security-practices","title":"Security Practices","text":"<ul> <li>Secret management: Use Azure Key Vault or environment variables</li> <li>Access control: Implement proper RBAC in Fabric workspaces</li> <li>Audit logging: Enable audit logs for all environments</li> </ul>"},{"location":"user_guide/workflows/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user_guide/workflows/#notebook-generation","title":"Notebook Generation","text":"<pre><code># Generate notebooks in parallel for large projects\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode warehouse &amp;\ningen_fab ddl compile-notebooks --output-mode fabric --generation-mode lakehouse &amp;\nwait\n</code></pre>"},{"location":"user_guide/workflows/#testing","title":"Testing","text":"<pre><code># Run tests in parallel\ningen_fab test local libraries --base-dir . --parallel\n</code></pre>"},{"location":"user_guide/workflows/#deployment","title":"Deployment","text":"<pre><code># Use dry-run to validate before actual deployment\ningen_fab deploy to-environment --fabric-workspace-repo-dir . --fabric-environment production --dry-run\n</code></pre> <p>This workflow guide provides a comprehensive approach to using the Ingenious Fabric Accelerator effectively in your projects. Adapt these patterns to fit your specific needs and organizational requirements.</p>"}]}