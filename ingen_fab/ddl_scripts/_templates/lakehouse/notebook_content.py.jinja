{%- import './common/nb_macros.py.jinja' as macros -%}
{% if language_group == "synapse_pyspark" %}
{%- include "/common/nb_header_pyspark.py.jinja" %}
{% else %}
{%- include "/common/nb_header_python.py.jinja" %}
{% endif %}

{% include "/common/nb_cell_mount_lib_path.py.jinja" %}


{{macros.python_cell_with_heading(" Now Load the Custom Python Libraries")}}

if run_mode == "local":
    from ingen_fab/python_libs/common/config_utils.py import *
    from ingen_fab.python_libs.pyspark.lakehouse_utils import lakehouse_utils
    from ingen_fab.python_libs.pyspark.ddl_utils import ddl_utils
    from ingen_fab.python_libs.pyspark.notebook_utils_abstraction import notebookutils
    from ingen_fab.python_libs.pyspark.parquet_load_utils import parquet_load_utils 
else:
    files_to_load = [
        "ingen_fab/python_libs/common/config_utils.py",
        "ingen_fab/python_libs/pyspark/lakehouse_utils.py",
        "ingen_fab/python_libs/pyspark/ddl_utils.py",
        "ingen_fab/python_libs/pyspark/notebook_utils_abstraction.py",
        "ingen_fab/python_libs/pyspark/parquet_load_utils.py"
    ]

    load_python_modules_from_path(mount_path, files_to_load)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "jupyter_python"
# META }

# MARKDOWN ********************

# ## üß™üß™ Run DDL Scripts


# CELL ********************


target_lakehouse_config_prefix = "{{target_lakehouse_config_prefix | required}}"

configs: ConfigsObject = get_configs_as_object()
config_lakehouse = lakehouse_utils(
    target_workspace_id=configs.edw_workspace_id,
    target_lakehouse_id=configs.edw_lakehouse_id,
    spark=spark  # Pass the Spark session if available
)


target_lakehouse = lakehouse_utils(
    target_workspace_id=config_utils.get_config_value(f"{target_lakehouse_config_prefix.lower()}_workspace_id"),
    target_lakehouse_id=config_utils.get_config_value(f"{target_lakehouse_config_prefix.lower()}_lakehouse_id"),
    spark=spark  # Pass the Spark session if available
)

du = ddl_utils(
    target_workspace_id=target_lakehouse.target_workspace_id,
    target_lakehouse_id=target_lakehouse.target_store_id,
    spark=spark  # Pass the Spark session if available
)

from pyspark.sql.types import (
    IntegerType,
    StringType,
    StructField,
    StructType,
    TimestampType,
    LongType
)




{% for content in cells %}

{{ content }}

{% endfor %}




# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ## üìá Print the execution log

# CELL ********************



du.print_log() 




# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ## ‚úîÔ∏è If we make it to the end return a successful result

# CELL ********************



notebookutils.mssparkutils.notebook.exit("success")




{%include "/common/nb_footer.py.jinja" %}