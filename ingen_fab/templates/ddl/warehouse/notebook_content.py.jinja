{%- import 'shared/notebook/macros/notebook_macros.py.jinja' as macros -%}
{% if language_group == "synapse_pyspark" %}
{%- include "shared/notebook/headers/pyspark.py.jinja" %}
{% else %}
{%- include "shared/notebook/headers/python.py.jinja" %}
{% endif %}


{% include "shared/notebook/environment/library_loader.py.jinja" %}


{{macros.python_cell_with_heading("## üóÇÔ∏è Now Load the Custom Python Libraries")}}

import sys

if "notebookutils" in sys.modules and hasattr(notebookutils, 'fs'):
    # Fabric mode - load from mounted path
    mount_path = notebookutils.fs.getMountPath("/config_files")
    from datetime import datetime
    files_to_load = [
        "ingen_fab/python_libs/common/config_utils.py",
        "ingen_fab/python_libs/pyspark/notebook_utils_abstraction.py",
        "ingen_fab/python_libs/python/sql_templates.py",
        "ingen_fab/python_libs/python/warehouse_utils.py",
        "ingen_fab/python_libs/python/warehouse_ddl_utils.py",
        "ingen_fab/python_libs/python/pipeline_utils.py"
    ]

    # Use the mount path directly for load_python_modules_from_path
    load_python_modules_from_path(mount_path, files_to_load)
    
    # Verify all required modules are available after loading
    print("üìã Verifying loaded modules...")
    try:
        # Test if config functions are available
        if 'get_configs_as_object' in globals():
            test_config = get_configs_as_object()
            print("‚úÖ Config utilities loaded successfully")
        else:
            print("‚ö†Ô∏è get_configs_as_object function not found in globals")
            
        # Test if WarehouseDDLUtils is available
        if 'WarehouseDDLUtils' in globals():
            print("‚úÖ WarehouseDDLUtils class loaded successfully")
        else:
            print("‚ö†Ô∏è WarehouseDDLUtils class not found in globals")
            
        # Test if SQLTemplates is available
        if 'SQLTemplates' in globals():
            print("‚úÖ SQLTemplates class loaded successfully")
        else:
            print("‚ö†Ô∏è SQLTemplates class not found in globals")
            
        # Show available globals for debugging
        relevant_globals = [k for k in globals().keys() if not k.startswith('_') and ('config' in k.lower() or 'warehouse' in k.lower() or 'ddl' in k.lower() or 'utils' in k.lower() or 'sql' in k.lower() or 'template' in k.lower())]
        print(f"üìã Relevant loaded globals: {relevant_globals}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error testing loaded modules: {str(e)}")
        print("This is expected if config variables are not yet injected")
else:
    # Local mode - direct imports
    from datetime import datetime
    from ingen_fab.python_libs.common.config_utils import *
    from ingen_fab.python_libs.pyspark.notebook_utils_abstraction import NotebookUtilsFactory
    from ingen_fab.python_libs.python.sql_templates import SQLTemplates
    from ingen_fab.python_libs.python.warehouse_utils import warehouse_utils
    from ingen_fab.python_libs.python.warehouse_ddl_utils import WarehouseDDLUtils
    from ingen_fab.python_libs.python.pipeline_utils import PipelineUtils
    notebookutils = NotebookUtilsFactory.create_instance()

{{macros.python_cell_with_heading("## üì¶ Install Required Packages and Import Libraries")}}

# Install pyodbc for warehouse connections
%pip install pyodbc

# Required packages for Python structures and utilities
import struct
from itertools import chain, repeat
import pyodbc
import sempy.fabric as fabric
import pandas as pd
from notebookutils import mssparkutils

# Set the ODBC Driver Code for AAD Token handling
SQL_COPT_SS_ACCESS_TOKEN = 1256

{{macros.python_cell_with_heading("## ‚öôÔ∏è Configuration Settings")}}

# variableLibraryInjectionStart: var_lib


# variableLibraryInjectionEnd: var_lib

{{ macros.python_cell_with_heading("## üÜï Configuration Loading and Warehouse Setup")}}

import sys

target_warehouse_config_prefix = "{{target_warehouse_config_prefix | required}}"

# Determine execution mode and load configuration utilities
if "notebookutils" in sys.modules and hasattr(notebookutils, 'fs'):
    # Fabric mode - need to load config utilities from mounted path
    mount_path = notebookutils.fs.getMountPath("/config_files")
    try:
        # Try to use existing functions first
        configs: ConfigsObject = get_configs_as_object()
        print("‚úÖ Config utilities already available")
    except NameError as e:
        print(f"üîÑ Config function not available: {str(e)}")
        print("Available globals:", [k for k in globals().keys() if 'config' in k.lower()])
        print("üîÑ Loading config utilities directly...")
        print(f"üìÅ Mount path: {mount_path}")
        
        # Try different path formats that work with notebookutils.fs.head
        config_paths_to_try = [
            f"file:{mount_path}/ingen_fab/python_libs/common/config_utils.py",
            f"{mount_path}/ingen_fab/python_libs/common/config_utils.py",
            "/config_files/ingen_fab/python_libs/common/config_utils.py"
        ]
        
        config_loaded = False
        for config_path in config_paths_to_try:
            try:
                print(f"üîÑ Trying path: {config_path}")
                config_code = notebookutils.fs.head(config_path, 1_000_000)
                exec(config_code)
                # Test if the function is now available
                configs: ConfigsObject = get_configs_as_object()
                print(f"‚úÖ Config utilities loaded successfully from: {config_path}")
                config_loaded = True
                break
            except Exception as e:
                print(f"‚ùå Failed with path {config_path}: {str(e)}")
                continue
        
        if not config_loaded:
            print("‚ùå All direct config loading attempts failed")
            print("üîÑ Falling back to re-running load_python_modules_from_path...")
            # Try reloading all modules again
            files_to_reload = ["ingen_fab/python_libs/common/config_utils.py"]
            load_python_modules_from_path(mount_path, files_to_reload)
            try:
                configs: ConfigsObject = get_configs_as_object()
                print("‚úÖ Config utilities loaded via fallback method")
            except NameError:
                print("‚ùå Fallback method also failed")
                print("üîÑ Attempting to continue without config - this may fail later...")
                configs = None
else:
    # Local mode - functions should already be imported
    configs: ConfigsObject = get_configs_as_object()

# Get config values if configs object is available
if configs is not None:
    target_warehouse_id = get_config_value(f"{target_warehouse_config_prefix.lower()}_warehouse_id")
    target_workspace_id = get_config_value(f"{target_warehouse_config_prefix.lower()}_workspace_id")
else:
    print("‚ö†Ô∏è Config object not available, using placeholder values")
    target_warehouse_id = "placeholder_warehouse_id"
    target_workspace_id = "placeholder_workspace_id"

print(f"üè¢ FABRIC WAREHOUSE CONNECTION - EXECUTION MODE")
print(f"Target Warehouse ID: {target_warehouse_id}")
print(f"Target Workspace ID: {target_workspace_id}")
print("=" * 60)

# Get workspace information and warehouse connection details
workspace_id = spark.conf.get("trident.workspace.id")
workspace_items_df = fabric.list_items('Warehouse')

# Find the specific warehouse by ID
filtered_items_df = workspace_items_df[workspace_items_df['Id'] == target_warehouse_id]

if filtered_items_df.empty:
    print(f"‚ùå Warehouse with ID {target_warehouse_id} not found in workspace")
    raise ValueError(f"Warehouse {target_warehouse_id} not found")

# Get warehouse connection string from Fabric API
wh_connection_string = fabric.FabricRestClient().get(f"/v1/workspaces/{workspace_id}/warehouses/{target_warehouse_id}/connectionString").json()
sql_endpoint = wh_connection_string['connectionString'].split(':')[0]

print(f"‚úÖ Found warehouse: {filtered_items_df['Display Name'].values[0]}")
print(f"üì° SQL Endpoint: {sql_endpoint}")

{{ macros.python_cell_with_heading("## üîê Establish Warehouse Connection")}}

# Define the connection string using the retrieved endpoint
driver_name = "ODBC Driver 18 for SQL Server"
connection_string = "Driver={" + driver_name + "};Server=" + sql_endpoint + ",1433;Database=" + target_warehouse_id + ";Encrypt=Yes;TrustServerCertificate=No"

# Get and format the authentication token
token = mssparkutils.credentials.getToken("pbi")
token_as_bytes = bytes(token, "UTF-8")
encoded_bytes = bytes(chain.from_iterable(zip(token_as_bytes, repeat(0))))
token_bytes = struct.pack("<i", len(encoded_bytes)) + encoded_bytes

# Establish the connection with token authentication
attrs_before = {SQL_COPT_SS_ACCESS_TOKEN: token_bytes}

try:
    conn = pyodbc.connect(connection_string, autocommit=False, attrs_before=attrs_before)
    print("‚úÖ Successfully connected to warehouse!")
    warehouse_connection_available = True
except Exception as e:
    print(f"‚ùå Failed to connect to warehouse: {str(e)}")
    warehouse_connection_available = False
    conn = None

print("=" * 60)

class FabricWarehouseConnection:
    """Fabric warehouse connection using proven PyODBC approach."""
    
    def __init__(self, target_warehouse_id: str, target_workspace_id: str, connection_string: str, token_bytes: bytes):
        self.target_warehouse_id = target_warehouse_id
        self.target_workspace_id = target_workspace_id
        self._target_warehouse_id = target_warehouse_id  # For compatibility
        self._target_workspace_id = target_workspace_id  # For compatibility
        self.connection_string = connection_string
        self.token_bytes = token_bytes
        self.attrs_before = {SQL_COPT_SS_ACCESS_TOKEN: token_bytes}
        
        # Check if we can actually connect
        global warehouse_connection_available
        self.can_execute = warehouse_connection_available
    
    def get_connection(self):
        """Get a database connection to the warehouse."""
        if not self.can_execute:
            return None
        try:
            return pyodbc.connect(self.connection_string, autocommit=False, attrs_before=self.attrs_before)
        except Exception as e:
            print(f"‚ö†Ô∏è Connection failed: {str(e)}")
            return None
    
    def check_if_table_exists(self, table_name: str, schema_name: str = "dbo") -> bool:
        """Check if a table exists in the warehouse."""
        query = f"""
        SELECT COUNT(*) as count
        FROM sys.tables t
        JOIN sys.schemas s ON t.schema_id = s.schema_id
        WHERE t.name = '{table_name}' AND s.name = '{schema_name}'
        """
        
        if self.can_execute:
            try:
                result = self.execute_query(query)
                if result and len(result) > 0:
                    count = result[0][0]
                    exists = count > 0
                    print(f"üîç Table {schema_name}.{table_name}: {'EXISTS' if exists else 'NOT FOUND'}")
                    return exists
            except Exception as e:
                print(f"‚ö†Ô∏è Error checking table existence: {str(e)}")
        
        print(f"üîç CHECK TABLE EXISTS: {schema_name}.{table_name} (assuming NOT EXISTS)")
        return False
    
    def create_schema_if_not_exists(self, schema_name: str, max_retries: int = 3):
        """Create schema if it doesn't exist."""
        query = f"""
        IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = '{schema_name}')
        BEGIN
            EXEC('CREATE SCHEMA [{schema_name}]')
        END
        """
        print(f"\nüìÅ CREATE SCHEMA: {schema_name}")
        print("DDL to execute against warehouse:")
        print(f"```sql\n{query}\n```")
        
        if self.can_execute:
            self.execute_ddl(query, f"Create schema {schema_name}", max_retries)
        else:
            print("‚ö†Ô∏è Execution disabled - DDL displayed only")

    @property
    def target_store_id(self) -> str:
        """Return target warehouse ID for compatibility."""
        return self._target_warehouse_id

    def execute_query(self, query: str, conn=None, params=None, max_retries: int = 3):
        """Execute a SELECT query and return results."""
        if not self.can_execute:
            print("‚ö†Ô∏è Query execution disabled")
            return []
            
        connection = conn or self.get_connection()
        if not connection:
            return []
            
        for attempt in range(max_retries):
            try:
                cursor = connection.cursor()
                if params:
                    cursor.execute(query, params)
                else:
                    cursor.execute(query)
                
                # Fetch results for SELECT queries
                if query.strip().upper().startswith('SELECT'):
                    results = cursor.fetchall()
                    cursor.close()
                    if not conn:  # Only close if we created the connection
                        connection.close()
                    return results
                else:
                    cursor.close()
                    if not conn:
                        connection.close()
                    return []
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Query execution attempt {attempt + 1} failed: {str(e)}")
                if attempt == max_retries - 1:
                    print(f"‚ùå Query failed after {max_retries} attempts")
                    if not conn:
                        connection.close()
                    return []
                else:
                    print(f"üîÑ Retrying query execution (attempt {attempt + 2}/{max_retries})...")

    def execute_ddl(self, ddl_query: str, operation_name: str = "DDL Operation", max_retries: int = 3):
        """Execute DDL commands with proper transaction handling."""
        if not self.can_execute:
            print(f"‚ö†Ô∏è DDL execution disabled for: {operation_name}")
            return False
            
        connection = self.get_connection()
        if not connection:
            print(f"‚ùå Cannot establish connection for: {operation_name}")
            return False
            
        for attempt in range(max_retries):
            try:
                cursor = connection.cursor()
                cursor.execute(ddl_query)
                connection.commit()
                cursor.close()
                connection.close()
                print(f"‚úÖ {operation_name} executed successfully")
                return True
                
            except pyodbc.Error as ex:
                sqlstate = ex.args
                print(f"‚ùå {operation_name} failed (attempt {attempt + 1}): {sqlstate}")
                connection.rollback()
                
                if attempt == max_retries - 1:
                    print(f"‚ùå {operation_name} failed after {max_retries} attempts")
                    connection.close()
                    return False
                else:
                    print(f"üîÑ Retrying {operation_name} (attempt {attempt + 2}/{max_retries})...")
            except Exception as e:
                print(f"‚ùå Unexpected error in {operation_name} (attempt {attempt + 1}): {str(e)}")
                connection.rollback()
                if attempt == max_retries - 1:
                    connection.close()
                    return False

# Initialize the warehouse connection instance
if warehouse_connection_available and conn:
    warehouse_ddl_utils = FabricWarehouseConnection(
        target_warehouse_id, 
        target_workspace_id, 
        connection_string, 
        token_bytes
    )
    print("‚úÖ Warehouse DDL utilities initialized")
    
    # Initialize DDL utilities with run-once tracking
    try:
        # Check if WarehouseDDLUtils is available
        if 'WarehouseDDLUtils' not in globals():
            print("‚ö†Ô∏è WarehouseDDLUtils not found in globals, attempting to import directly...")
            
            # Try to load it directly if in Fabric mode
            if "notebookutils" in sys.modules and hasattr(notebookutils, 'fs'):
                mount_path = notebookutils.fs.getMountPath("/config_files")
                
                # Try different path formats for WarehouseDDLUtils
                warehouse_ddl_paths_to_try = [
                    f"file:{mount_path}/ingen_fab/python_libs/python/warehouse_ddl_utils.py",
                    f"{mount_path}/ingen_fab/python_libs/python/warehouse_ddl_utils.py",
                    "/config_files/ingen_fab/python_libs/python/warehouse_ddl_utils.py"
                ]
                
                warehouse_ddl_loaded = False
                for warehouse_ddl_path in warehouse_ddl_paths_to_try:
                    try:
                        print(f"üîÑ Trying WarehouseDDLUtils path: {warehouse_ddl_path}")
                        warehouse_ddl_utils_code = notebookutils.fs.head(warehouse_ddl_path, 1_000_000)
                        exec(warehouse_ddl_utils_code)
                        print(f"‚úÖ WarehouseDDLUtils loaded successfully from: {warehouse_ddl_path}")
                        warehouse_ddl_loaded = True
                        break
                    except Exception as e:
                        print(f"‚ùå Failed with WarehouseDDLUtils path {warehouse_ddl_path}: {str(e)}")
                        continue
                
                if not warehouse_ddl_loaded:
                    print("‚ùå All WarehouseDDLUtils direct loading attempts failed")
                    print("üîÑ Falling back to re-running load_python_modules_from_path for WarehouseDDLUtils...")
                    # Try reloading the specific module again
                    files_to_reload = ["ingen_fab/python_libs/python/warehouse_ddl_utils.py"]
                    load_python_modules_from_path(mount_path, files_to_reload)
                    
                    if 'WarehouseDDLUtils' not in globals():
                        print("‚ùå WarehouseDDLUtils still not available after fallback")
                        raise ImportError("WarehouseDDLUtils not available after all attempts")
                    else:
                        print("‚úÖ WarehouseDDLUtils loaded via fallback method")
            else:
                # Local mode - should already be imported
                from ingen_fab.python_libs.python.warehouse_ddl_utils import WarehouseDDLUtils
        
        du = WarehouseDDLUtils(
            warehouse_connection=warehouse_ddl_utils,
            target_warehouse_id=target_warehouse_id,
            target_workspace_id=target_workspace_id
        )
        print("‚úÖ Warehouse DDL execution tracking initialized")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize WarehouseDDLUtils: {str(e)}")
        print("üîÑ Continuing without run-once tracking...")
        du = None
        
else:
    warehouse_ddl_utils = None
    du = None
    print("‚ö†Ô∏è Warehouse DDL utilities not available - display mode only")

{{macros.python_cell_with_heading("## üèóÔ∏è DDL Generation and Execution")}}

# Initialize SQL Templates
try:
    # Check if SQLTemplates is available
    if 'SQLTemplates' not in globals():
        print("‚ö†Ô∏è SQLTemplates not found in globals, attempting to import directly...")
        
        # Try to load it directly if in Fabric mode
        if "notebookutils" in sys.modules and hasattr(notebookutils, 'fs'):
            mount_path = notebookutils.fs.getMountPath("/config_files")
            
            # Try different path formats for SQLTemplates
            sql_templates_paths_to_try = [
                f"file:{mount_path}/ingen_fab/python_libs/python/sql_templates.py",
                f"{mount_path}/ingen_fab/python_libs/python/sql_templates.py",
                "/config_files/ingen_fab/python_libs/python/sql_templates.py"
            ]
            
            sql_templates_loaded = False
            for sql_templates_path in sql_templates_paths_to_try:
                try:
                    print(f"üîÑ Trying SQLTemplates path: {sql_templates_path}")
                    sql_templates_code = notebookutils.fs.head(sql_templates_path, 1_000_000)
                    exec(sql_templates_code)
                    print(f"‚úÖ SQLTemplates loaded successfully from: {sql_templates_path}")
                    sql_templates_loaded = True
                    break
                except Exception as e:
                    print(f"‚ùå Failed with SQLTemplates path {sql_templates_path}: {str(e)}")
                    continue
            
            if not sql_templates_loaded:
                print("‚ùå All SQLTemplates direct loading attempts failed")
                print("üîÑ Falling back to re-running load_python_modules_from_path for SQLTemplates...")
                # Try reloading the specific module again
                files_to_reload = ["ingen_fab/python_libs/python/sql_templates.py"]
                load_python_modules_from_path(mount_path, files_to_reload)
                
                if 'SQLTemplates' not in globals():
                    print("‚ùå SQLTemplates still not available after fallback")
                    raise ImportError("SQLTemplates not available after all attempts")
                else:
                    print("‚úÖ SQLTemplates loaded via fallback method")
        else:
            # Local mode - should already be imported
            from ingen_fab.python_libs.python.sql_templates import SQLTemplates
    
    sql_templates = SQLTemplates()
    print("‚úÖ SQL Templates initialized successfully")
    
except Exception as e:
    print(f"‚ùå Failed to initialize SQLTemplates: {str(e)}")
    print("üîÑ DDL generation will not be available")
    sql_templates = None

{% if cells %}
# =====================================================
# Individual SQL File Execution
# =====================================================
{% for cell in cells %}
{{ cell }}
{% endfor %}
{% endif %}

{% for table_config in target_tables %}
# =====================================================
# Table: {{ table_config["name"] }}
# =====================================================

print(f"\nüóÇÔ∏è Processing Table: {{ table_config['name'] }}")
print("=" * 60)

# Check if SQL Templates are available
if sql_templates is None:
    print("‚ùå SQLTemplates not available - cannot generate DDL")
    print("üìã Skipping table {{ table_config['name'] }} due to missing SQL Templates")
    continue

# Generate DDL for {{ table_config["name"] }}
ddl_sql = sql_templates.get_ddl_warehouse(
    target_store_object={{ table_config | tojson | safe }},
    target_store="{{ table_config['name'] }}"
)

print("üìã Generated DDL:")
print("```sql")
print(ddl_sql)
print("```")

# Define the DDL execution function for run_once
def create_{{ table_config['name'].replace('-', '_').replace(' ', '_').lower() }}():
    """Create table {{ table_config['name'] }} with generated DDL."""
    
    # Create schema if needed
    {% if table_config.get("schema") %}
    if warehouse_ddl_utils:
        warehouse_ddl_utils.create_schema_if_not_exists("{{ table_config['schema'] }}")
    {% endif %}
    
    # Execute DDL
    if warehouse_ddl_utils and warehouse_ddl_utils.can_execute:
        print(f"\nüöÄ Executing DDL for {{ table_config['name'] }}...")
        success = warehouse_ddl_utils.execute_ddl(
            ddl_sql, 
            f"Create table {{ table_config['name'] }}"
        )
        
        if success:
            print(f"‚úÖ Table {{ table_config['name'] }} created successfully")
            
            # Verify table exists
            {% if table_config.get("schema") %}
            table_exists = warehouse_ddl_utils.check_if_table_exists("{{ table_config['name'] }}", "{{ table_config['schema'] }}")
            {% else %}
            table_exists = warehouse_ddl_utils.check_if_table_exists("{{ table_config['name'] }}")
            {% endif %}
            
            if table_exists:
                print(f"‚úÖ Verified: Table {{ table_config['name'] }} exists in warehouse")
            else:
                print(f"‚ö†Ô∏è Warning: Table {{ table_config['name'] }} may not have been created properly")
        else:
            raise RuntimeError(f"Failed to create table {{ table_config['name'] }}")
    else:
        print(f"üìã DDL for {{ table_config['name'] }} displayed (execution not available)")
        raise RuntimeError("Warehouse connection not available for DDL execution")

# Execute with run_once tracking (prevents duplicate execution)
if du and du.warehouse_connection.can_execute:
    # Use a deterministic GUID based on table config
    import hashlib
    table_guid = hashlib.sha256({{ table_config | tojson | safe }}.encode()).hexdigest()[:32]
    
    du.run_once(
        work_fn=create_{{ table_config['name'].replace('-', '_').replace(' ', '_').lower() }},
        object_name="{{ table_config['name'] }}",
        guid=table_guid
    )
else:
    # Fallback to direct execution if tracking not available
    create_{{ table_config['name'].replace('-', '_').replace(' ', '_').lower() }}()

print("=" * 60)

{% endfor %}

{{macros.python_cell_with_heading("## üìá Print the execution log")}}

if du:
    du.print_log()
else:
    print("üìá Execution log not available - DDL tracking not initialized")

{{macros.python_cell_with_heading("## üéØ Summary and Cleanup")}}

print("\nüéØ DDL EXECUTION SUMMARY")
print("=" * 60)

if du and du.warehouse_connection.can_execute:
    print("‚úÖ Warehouse connection was available")
    print("‚úÖ DDL commands were executed against the warehouse with run-once tracking")
    print(f"üóÇÔ∏è Target Warehouse: {target_warehouse_id}")
    print(f"üìÅ Target Workspace: {target_workspace_id}")
    print("üîÑ Run-once tracking prevents duplicate executions")
else:
    print("‚ö†Ô∏è Warehouse connection was not available")
    print("üìã DDL commands were displayed only")

print(f"\nüìä Tables Processed: {{ target_tables | length }}")
{% for table_config in target_tables %}
print(f"  - {{ table_config['name'] }}")
{% endfor %}

print("\nüéâ DDL Processing Complete!")
print("=" * 60)

# Clean up any remaining connections
try:
    if 'conn' in locals() and conn:
        conn.close()
        print("üßπ Connection cleaned up")
except:
    pass

{{macros.python_cell_with_heading("## ‚úîÔ∏è If we make it to the end return a successful result")}}

mssparkutils.notebook.exit("success")