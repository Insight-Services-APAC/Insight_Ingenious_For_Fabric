# Sample configuration data for flat file ingestion testing - Universal schema (Lakehouse version)
from pyspark.sql import Row

# Import the universal schema definition
{% include 'ddl/schemas/flat_file_config_schema_universal.py.jinja' %}

# Sample configuration records for testing - Using synthetic data generator parquet files
sample_configs = [
    Row(
        config_id="synthetic_customers_001",
        config_name="Synthetic Data - Customers (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/customers/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_customers",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="customer_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="synthetic_products_002",
        config_name="Synthetic Data - Products (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/products/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_products",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="category",
        sort_columns="product_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="synthetic_orders_003",
        config_name="Synthetic Data - Orders (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/orders/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_orders",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="order_date",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="synthetic_customers_warehouse_001",
        config_name="Synthetic Data - Customers (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/customers/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_customers",
        staging_table_name="staging_synthetic_customers",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="customer_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="synthetic_products_warehouse_002",
        config_name="Synthetic Data - Products (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/products/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_products",
        staging_table_name="staging_synthetic_products",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="product_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="synthetic_orders_warehouse_003",
        config_name="Synthetic Data - Orders (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/orders/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_orders",
        staging_table_name="staging_synthetic_orders",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="order_date",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    # Large dataset configurations with partitioning and merge mode
    Row(
        config_id="star_dim_customer_large_001",
        config_name="Star Schema Large - Customer Dimension",
        source_file_path="Files/synthetic_data/retail_star_large/dim_customer/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="star",
        target_table_name="dim_customer_large",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="customer_segment",
        sort_columns="customer_key",
        write_mode="merge",
        merge_keys="customer_key",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=3,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="star_dim_product_large_002",
        config_name="Star Schema Large - Product Dimension",
        source_file_path="Files/synthetic_data/retail_star_large/dim_product/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="star",
        target_table_name="dim_product_large",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="product_category",
        sort_columns="product_key",
        write_mode="merge",
        merge_keys="product_key",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=3,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="star_dim_store_large_003",
        config_name="Star Schema Large - Store Dimension",
        source_file_path="Files/synthetic_data/retail_star_large/dim_store/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="star",
        target_table_name="dim_store_large",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="store_region",
        sort_columns="store_key",
        write_mode="merge",
        merge_keys="store_key",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=3,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="star_dim_date_large_004",
        config_name="Star Schema Large - Date Dimension",
        source_file_path="Files/synthetic_data/retail_star_large/dim_date/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="star",
        target_table_name="dim_date_large",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="date_key",
        write_mode="merge",
        merge_keys="date_key",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=3,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="star_fact_sales_large_005",
        config_name="Star Schema Large - Sales Fact Table",
        source_file_path="Files/synthetic_data/retail_star_large/fact_sales/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="star",
        target_table_name="fact_sales_large",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="date_key,store_key",
        sort_columns="date_key,store_key,product_key",
        write_mode="merge",
        merge_keys="transaction_id",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=3,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    # Example of partition_swap mode for daily fact data refresh
    Row(
        config_id="daily_sales_partition_swap_001",
        config_name="Daily Sales Data - Partition Swap Mode",
        source_file_path="Files/synthetic_data/daily_sales/",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="staging",
        target_table_name="daily_sales_fact",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="sale_date",
        sort_columns="sale_date,store_id,product_id",
        write_mode="partition_swap",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=4,
        active_yn="N",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    # Example configurations for complex CSV files with advanced parsing
    Row(
        config_id="complex_csv_001",
        config_name="Complex CSV - Customer Comments with Newlines",
        source_file_path="Files/sample_data/complex_customer_feedback.csv",
        source_file_format="csv",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="customer_feedback_complex",
        staging_table_name=None,
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="feedback_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=5,
        active_yn="N",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        # Advanced CSV configuration fields
        quote_character='"',
        escape_character='\\',
        multiline_values=True,
        ignore_leading_whitespace=True,
        ignore_trailing_whitespace=True,
        null_value="NULL",
        empty_value="",
        comment_character="#",
        max_columns=50,
        max_chars_per_column=10000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    Row(
        config_id="complex_csv_002",
        config_name="Complex CSV - Product Descriptions with Quotes and Commas",
        source_file_path="Files/sample_data/products_with_complex_descriptions.csv",
        source_file_format="csv",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="products_complex_descriptions",
        staging_table_name=None,
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="category",
        sort_columns="product_id",
        write_mode="merge",
        merge_keys="product_id",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=5,
        active_yn="N",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None,
        # Advanced CSV configuration for handling quotes and special characters
        quote_character='"',
        escape_character='"',  # Use double quotes for escaping quotes (Excel style)
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character=None,
        max_columns=100,
        max_chars_per_column=50000,
        # New fields for incremental synthetic data import support
        import_pattern=None,
        date_partition_format=None,
        table_relationship_group=None,
        batch_import_enabled=None,
        file_discovery_pattern=None,
        import_sequence_order=None,
        date_range_start=None,
        date_range_end=None,
        skip_existing_dates=None
    ),
    # Incremental Synthetic Data Import Configurations
    # These demonstrate the new date-partitioned import capabilities
    Row(
        config_id="retail_customers_incremental",
        config_name="Retail Customers Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="customers",
        staging_table_name="customers_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="year_month",
        sort_columns="customer_id",
        write_mode="merge",
        merge_keys="customer_id",
        data_validation_rules='{"required_columns": ["customer_id", "first_name", "last_name"]}',
        error_handling_strategy="log",
        execution_group=10,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/customers/*.parquet",
        import_sequence_order=1,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=True
    ),
    Row(
        config_id="retail_products_incremental",
        config_name="Retail Products Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="products",
        staging_table_name="products_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="category",
        sort_columns="product_id",
        write_mode="merge",
        merge_keys="product_id",
        data_validation_rules='{"required_columns": ["product_id", "product_name", "category"]}',
        error_handling_strategy="log",
        execution_group=10,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/products/*.parquet",
        import_sequence_order=2,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=True
    ),
    Row(
        config_id="retail_stores_incremental",
        config_name="Retail Stores Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="stores",
        staging_table_name="stores_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="region",
        sort_columns="store_id",
        write_mode="merge",
        merge_keys="store_id",
        data_validation_rules='{"required_columns": ["store_id", "store_name", "city"]}',
        error_handling_strategy="log",
        execution_group=10,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/stores/*.parquet",
        import_sequence_order=3,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=True
    ),
    Row(
        config_id="retail_orders_incremental",
        config_name="Retail Orders Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="orders",
        staging_table_name="orders_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="year_month",
        sort_columns="order_id",
        write_mode="append",
        merge_keys=None,
        data_validation_rules='{"required_columns": ["order_id", "customer_id", "order_date"]}',
        error_handling_strategy="log",
        execution_group=11,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/orders/*.parquet",
        import_sequence_order=4,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=False
    ),
    Row(
        config_id="retail_order_items_incremental",
        config_name="Retail Order Items Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="order_items",
        staging_table_name="order_items_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="year_month",
        sort_columns="order_item_id",
        write_mode="append",
        merge_keys=None,
        data_validation_rules='{"required_columns": ["order_item_id", "order_id", "product_id"]}',
        error_handling_strategy="log",
        execution_group=11,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/order_items/*.parquet",
        import_sequence_order=5,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=False
    ),
    Row(
        config_id="retail_inventory_incremental",
        config_name="Retail Inventory Incremental Import",
        source_file_path="Files/synthetic_data/retail_oltp_incremental",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="bronze",
        target_table_name="inventory",
        staging_table_name="inventory_staging",
        file_delimiter=",",
        has_header=True,
        encoding="utf-8",
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="year_month",
        sort_columns="inventory_id",
        write_mode="merge",
        merge_keys="store_id,product_id,date",
        data_validation_rules='{"required_columns": ["store_id", "product_id", "quantity_on_hand"]}',
        error_handling_strategy="log",
        execution_group=12,
        active_yn="Y",
        created_date="2024-01-01",
        modified_date=None,
        created_by="admin",
        modified_by=None,
        quote_character='"',
        escape_character='"',
        multiline_values=True,
        ignore_leading_whitespace=False,
        ignore_trailing_whitespace=False,
        null_value="",
        empty_value="",
        comment_character="#",
        max_columns=100,
        max_chars_per_column=50000,
        import_pattern="date_partitioned",
        date_partition_format="YYYY/MM/DD",
        table_relationship_group="retail_oltp",
        batch_import_enabled=True,
        file_discovery_pattern="**/inventory/*.parquet",
        import_sequence_order=6,
        date_range_start="2024-01-01",
        date_range_end="2024-01-30",
        skip_existing_dates=True
    )
]

# Create DataFrame and insert records
df = target_lakehouse.get_connection.createDataFrame(sample_configs, schema)
target_lakehouse.write_to_table(
    df=df,
    table_name="config_flat_file_ingestion",
    mode="append"
)

print("✓ Inserted " + str(len(sample_configs)) + " sample configuration records using synthetic data generator parquet files")
print("✓ Includes " + str(6) + " incremental synthetic data import configurations demonstrating:")
print("  - Snapshot tables (customers, products, stores) with merge mode")
print("  - Incremental tables (orders, order_items) with append mode")
print("  - Daily snapshot tables (inventory) with composite key merge")
print("  - Date-partitioned processing with execution groups 10, 11, 12")