# Sample configuration data for flat file ingestion testing - Universal schema (Lakehouse version)
from pyspark.sql import Row

# Import the universal schema definition
{% include 'ddl/schemas/flat_file_config_schema_universal.py.jinja' %}

# Sample configuration records for testing - Using synthetic data generator parquet files
sample_configs = [
    Row(
        config_id="synthetic_customers_001",
        config_name="Synthetic Data - Customers (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/customers.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_customers",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="customer_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="fail",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_products_002",
        config_name="Synthetic Data - Products (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/products.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_products",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="category",
        sort_columns="product_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_orders_003",
        config_name="Synthetic Data - Orders (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/orders.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_orders",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="order_date",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="fail",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_order_items_004",
        config_name="Synthetic Data - Order Items (Retail OLTP Small)",
        source_file_path="Files/synthetic_data/retail_oltp_small/order_items.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_lakehouse_id}}{% endraw %}",
        target_datastore_type="lakehouse",
        target_schema_name="raw",
        target_table_name="synthetic_order_items",
        staging_table_name=None,
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="order_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=1,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_customers_warehouse_001",
        config_name="Synthetic Data - Customers (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/customers.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_customers",
        staging_table_name="staging_synthetic_customers",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="customer_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="fail",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_products_warehouse_002",
        config_name="Synthetic Data - Products (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/products.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_products",
        staging_table_name="staging_synthetic_products",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="product_id",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="log",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    ),
    Row(
        config_id="synthetic_orders_warehouse_003",
        config_name="Synthetic Data - Orders (Warehouse)",
        source_file_path="Files/synthetic_data/retail_oltp_small/orders.parquet",
        source_file_format="parquet",
        target_workspace_id="{% raw %}{{varlib:config_workspace_id}}{% endraw %}",
        target_datastore_id="{% raw %}{{varlib:config_wh_warehouse_id}}{% endraw %}",
        target_datastore_type="warehouse",
        target_schema_name="raw",
        target_table_name="synthetic_orders",
        staging_table_name="staging_synthetic_orders",
        file_delimiter=None,
        has_header=None,
        encoding=None,
        date_format="yyyy-MM-dd",
        timestamp_format="yyyy-MM-dd HH:mm:ss",
        schema_inference=True,
        custom_schema_json=None,
        partition_columns="",
        sort_columns="order_date",
        write_mode="overwrite",
        merge_keys="",
        data_validation_rules=None,
        error_handling_strategy="fail",
        execution_group=2,
        active_yn="Y",
        created_date="2024-01-15",
        modified_date=None,
        created_by="system",
        modified_by=None
    )
]

# Create DataFrame and insert records
df = target_lakehouse.get_connection.createDataFrame(sample_configs, schema)
target_lakehouse.write_to_table(
    df=df,
    table_name="config_flat_file_ingestion",
    mode="append"
)

print("âœ“ Inserted " + str(len(sample_configs)) + " sample configuration records using synthetic data generator parquet files")