# Sample data for synapse_extract_objects - Lakehouse version

from datetime import datetime

# Sample data
data = []

obj_set_b = [
    {
        "synapse_connection_name": "EIMUATG2LAKE",
        "source_schema_name": "EDW",
        "source_table_name": "HANA_FCT_INVENTORYOPN_CODEDATE_INT",
        "export_base_dir": "exports_ingen_fab",
        "extract_mode": "snapshot",
        "single_date_filter": None,
        "date_range_filter": None,
        "custom_select_sql": None,
        "execution_group": 1,
        "active_yn": "Y",
        "synapse_sync_fabric_pipeline_id": None,
        "synapse_datasource_name": None,
        "synapse_datasource_location": None
    },
    {
        "synapse_connection_name": "EIMUATG2LAKE",
        "source_schema_name": "EDL",
        "source_table_name": "HANA_FCT_PURCHASE_ORDER_LINE",
        "export_base_dir": "exports_ingen_fab",
        "extract_mode": "incremental",
        "single_date_filter": "WHERE CREATED_DT >= '@date' AND CREATED_DT < DATEADD(DAY, 1, '@date')",
        "date_range_filter": "WHERE CREATED_DT >= '@start_date' AND CREATED_DT < DATEADD(DAY, 1, '@end_date')",
        "custom_select_sql": None,
        "execution_group": 2,
        "active_yn": "Y",
        "synapse_sync_fabric_pipeline_id": None,
        "synapse_datasource_name": None,
        "synapse_datasource_location": None
    },
    {
        "synapse_connection_name": "EIMUATG2LAKE",
        "source_schema_name": "EDL",
        "source_table_name": "HANA_FCT_INVENTORY_FIN",
        "export_base_dir": "exports_ingen_fab",
        "extract_mode": "incremental",
        "single_date_filter": "WHERE UPDATED_DT >= '@date' AND UPDATED_DT < DATEADD(DAY, 1, '@date')",
        "date_range_filter": "WHERE UPDATED_DT >= '@start_date' AND UPDATED_DT < DATEADD(DAY, 1, '@end_date')",
        "custom_select_sql": None,
        "execution_group": 2,
        "active_yn": "Y",
        "synapse_sync_fabric_pipeline_id": None,
        "synapse_datasource_name": None,
        "synapse_datasource_location": None
    },
    {
        "synapse_connection_name": "EIMUATG2LAKE",
        "source_schema_name": "EDL",
        "source_table_name": "HANA_FCT_OPERATIONAL_EVENT",
        "export_base_dir": "exports_ingen_fab",
        "extract_mode": "incremental",
        "single_date_filter": "WHERE UPDATED_DT >= '@date' AND UPDATED_DT < DATEADD(DAY, 1, '@date')",
        "date_range_filter": "WHERE UPDATED_DT >= '@start_date' AND UPDATED_DT < DATEADD(DAY, 1, '@end_date')",
        "custom_select_sql": None,
        "execution_group": 2,
        "active_yn": "Y",
        "synapse_sync_fabric_pipeline_id": None,
        "synapse_datasource_name": None,
        "synapse_datasource_location": None
    },
    {
        "synapse_connection_name": "EIMUATG2LAKE",
        "source_schema_name": "EDL",
        "source_table_name": "HANA_FCT_YARD_APPOINTMENT",
        "export_base_dir": "exports_ingen_fab",
        "extract_mode": "incremental",
        "single_date_filter": "WHERE UPDATED_DT >= '@date' AND UPDATED_DT < DATEADD(DAY, 1, '@date')",
        "date_range_filter": "WHERE UPDATED_DT >= '@start_date' AND UPDATED_DT < DATEADD(DAY, 1, '@end_date')",
        "custom_select_sql": None,
        "execution_group": 2,
        "active_yn": "Y",
        "synapse_sync_fabric_pipeline_id": None,
        "synapse_datasource_name": None,
        "synapse_datasource_location": None
    }
]

# Combine with existing sample data
data.extend(obj_set_b)

# Updated schema to match enhanced configuration table structure
schema = StructType([
    StructField("synapse_connection_name", StringType(), False),
    StructField("source_schema_name", StringType(), False),
    StructField("source_table_name", StringType(), False),
    StructField("export_base_dir", StringType(), True),
    StructField("extract_mode", StringType(), False),
    StructField("single_date_filter", StringType(), True),
    StructField("date_range_filter", StringType(), True),
    StructField("custom_select_sql", StringType(), True),
    StructField("execution_group", IntegerType(), False),
    StructField("active_yn", StringType(), False),
    StructField("synapse_sync_fabric_pipeline_id", StringType(), True),
    StructField("synapse_datasource_name", StringType(), True),
    StructField("synapse_datasource_location", StringType(), True)
])

# Convert list to DataFrame using target_lakehouse
df = target_lakehouse.spark.createDataFrame(data, schema)

target_lakehouse.write_to_table(
    df=df,
    table_name="synapse_extract_objects",
    mode="append"
)
